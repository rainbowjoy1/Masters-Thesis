{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#need 1.4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_agency = r\"C:\\Users\\danie\\Documents\\GitHub\\Masters-Thesis\\Sap et al. -Connotation Frames of Agency and Power.csv\"\n",
    "#power_agency = r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis/Sap et al. -Connotation Frames of Agency and Power.csv\"\n",
    "\n",
    "power_agency = pd.read_csv(power_agency)\n",
    "power_agency[[\"agency_1\",\"agency_classifier\"]]= power_agency[\"agency\"].str.split(\"_\",expand=True)\n",
    "power_agency[[\"power_1\",\"power_classifier\"]]= power_agency[\"power\"].str.split(\"_\",expand=True)\n",
    "power_agency = power_agency.drop(power_agency[[\"agency\",\"power\", \"agency_1\", \"power_1\"]], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communality = r\"C:\\Users\\danie\\Documents\\GitHub\\Masters-Thesis\\Lawson et al. - Communality.csv\"\n",
    "#communality = r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis/Lason et al. - Communality.csv\"\n",
    "communality = pd.read_csv(communality)\n",
    "\n",
    "agency = r\"C:\\Users\\danie\\Documents\\GitHub\\Masters-Thesis\\Lawson et al. - Agency Words.csv\"\n",
    "#agency = r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis/Lawson et al. - Agency.csv\"\n",
    "agency = pd.read_csv(agency)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sent, list of words, sentiment, scores, avg for not null of P, A, C\n",
    "\n",
    "word, count, coeff, P, A, C \n",
    "\n",
    "male count total weighted scores\n",
    "female count total weighted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_2009= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis/RESULTS09_coef_high.pickle\")\n",
    "lc_2009= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis/RESULTS09_coef_low.pickle\")\n",
    "hc_2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2009\n",
    "df_09 = pd.read_pickle(\"RESULTS09_coef_high.pickle\")\n",
    "df_09.rename(columns = {'coef':'2009_c'}, inplace = True)\n",
    "#df_09 = df_09.drop(columns=['coef_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2010\n",
    "df_10 = pd.read_pickle(\"RESULTS10_coef_high.pickle\")\n",
    "df_10.rename(columns = {'coef':'2010_c'}, inplace = True)\n",
    "#df_10 = df_10.drop(columns=['coef_type'])\n",
    "#2011\n",
    "df_11 = pd.read_pickle(\"RESULTS11_coef_high.pickle\")\n",
    "df_11.rename(columns = {'coef':'2011_c'}, inplace = True)\n",
    "#2012\n",
    "df_12 = pd.read_pickle(\"RESULTS12_coef_high.pickle\")\n",
    "df_12.rename(columns = {'coef':'2012_c'}, inplace = True)\n",
    "#2013\n",
    "df_13 = pd.read_pickle(\"RESULTS13_coef_high.pickle\")\n",
    "df_13.rename(columns = {'coef':'2013_c'}, inplace = True)\n",
    "#2014\n",
    "#df_14 = pd.read_pickle(\"RESULTS14_coef_high.pickle\")\n",
    "#df_14.rename(columns = {'coef':'2014_c'}, inplace = True)\n",
    "#2015\n",
    "df_15 = pd.read_pickle(\"RESULTS15_coef_high.pickle\")\n",
    "df_15.rename(columns = {'coef':'2015_c'}, inplace = True)\n",
    "#2016\n",
    "df_16 = pd.read_pickle(\"RESULTS16_coef_high.pickle\")\n",
    "df_16.rename(columns = {'coef':'2016_c'}, inplace = True)\n",
    "#2017\n",
    "df_17 = pd.read_pickle(\"RESULTS17_coef_high.pickle\")\n",
    "df_17.rename(columns = {'coef':'2017_c'}, inplace = True)\n",
    "#2018\n",
    "df_18 = pd.read_pickle(\"RESULTS18_coef_high.pickle\")\n",
    "df_18.rename(columns = {'coef':'2018_c'}, inplace = True)\n",
    "#2019\n",
    "df_19 = pd.read_pickle(\"RESULTS19_coef_high.pickle\")\n",
    "df_19.rename(columns = {'coef':'2019_c'}, inplace = True)\n",
    "#2020\n",
    "df_20 = pd.read_pickle(\"RESULTS20_coef_high.pickle\")\n",
    "df_20.rename(columns = {'coef':'2020_c'}, inplace = True)\n",
    "#2021\n",
    "df_21 = pd.read_pickle(\"RESULTS21_coef_high.pickle\")\n",
    "df_21.rename(columns = {'coef':'2021_c'}, inplace = True)\n",
    "#2022\n",
    "df_22 = pd.read_pickle(\"RESULTS22_coef_high.pickle\")\n",
    "df_22.rename(columns = {'coef':'2022_c'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-2c80a8559a3f>:4: FutureWarning: Passing 'suffixes' which cause duplicate columns {'coef_type_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['feature'],how='outer'), df_list)\n"
     ]
    }
   ],
   "source": [
    "df_list = [df_09, df_10, df_11, df_12, df_13, df_15, df_16, df_17, df_18, df_19, df_20, df_21, df_22]\n",
    "#df = pd.merge(df_list, right on='feature', how='outer')\n",
    "\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['feature'],how='outer'), df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>2010_c</th>\n",
       "      <th>2011_c</th>\n",
       "      <th>2012_c</th>\n",
       "      <th>2013_c</th>\n",
       "      <th>2015_c</th>\n",
       "      <th>2016_c</th>\n",
       "      <th>2017_c</th>\n",
       "      <th>2018_c</th>\n",
       "      <th>coef_type_x</th>\n",
       "      <th>2019_c</th>\n",
       "      <th>coef_type_y</th>\n",
       "      <th>2020_c</th>\n",
       "      <th>coef_type_x</th>\n",
       "      <th>2021_c</th>\n",
       "      <th>coef_type_y</th>\n",
       "      <th>2022_c</th>\n",
       "      <th>coef_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jade</td>\n",
       "      <td>13.845370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boyfriend</td>\n",
       "      <td>12.797718</td>\n",
       "      <td>9.864651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.722136</td>\n",
       "      <td>2.970981</td>\n",
       "      <td>5.542121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.636499</td>\n",
       "      <td>highest</td>\n",
       "      <td>6.335546</td>\n",
       "      <td>highest</td>\n",
       "      <td>5.640018</td>\n",
       "      <td>highest</td>\n",
       "      <td>5.286002</td>\n",
       "      <td>highest</td>\n",
       "      <td>4.818898</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>creative</td>\n",
       "      <td>12.640788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mime</td>\n",
       "      <td>12.602833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>french</td>\n",
       "      <td>12.060647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>pony</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.783478</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>tearfully</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.782416</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>budding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.777225</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>arizona</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.776941</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>greville</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.767179</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1936 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature       coef    2010_c  2011_c    2012_c    2013_c    2015_c  \\\n",
       "0          jade  13.845370       NaN     NaN       NaN       NaN       NaN   \n",
       "1     boyfriend  12.797718  9.864651     NaN  2.722136  2.970981  5.542121   \n",
       "2      creative  12.640788       NaN     NaN       NaN       NaN       NaN   \n",
       "3          mime  12.602833       NaN     NaN       NaN       NaN       NaN   \n",
       "4        french  12.060647       NaN     NaN       NaN       NaN       NaN   \n",
       "...         ...        ...       ...     ...       ...       ...       ...   \n",
       "1931       pony        NaN       NaN     NaN       NaN       NaN       NaN   \n",
       "1932  tearfully        NaN       NaN     NaN       NaN       NaN       NaN   \n",
       "1933    budding        NaN       NaN     NaN       NaN       NaN       NaN   \n",
       "1934    arizona        NaN       NaN     NaN       NaN       NaN       NaN   \n",
       "1935   greville        NaN       NaN     NaN       NaN       NaN       NaN   \n",
       "\n",
       "      2016_c  2017_c    2018_c coef_type_x    2019_c coef_type_y    2020_c  \\\n",
       "0        NaN     NaN       NaN         NaN       NaN         NaN       NaN   \n",
       "1        NaN     NaN  6.636499     highest  6.335546     highest  5.640018   \n",
       "2        NaN     NaN       NaN         NaN       NaN         NaN       NaN   \n",
       "3        NaN     NaN       NaN         NaN       NaN         NaN       NaN   \n",
       "4        NaN     NaN       NaN         NaN       NaN         NaN       NaN   \n",
       "...      ...     ...       ...         ...       ...         ...       ...   \n",
       "1931     NaN     NaN       NaN         NaN       NaN         NaN       NaN   \n",
       "1932     NaN     NaN       NaN         NaN       NaN         NaN       NaN   \n",
       "1933     NaN     NaN       NaN         NaN       NaN         NaN       NaN   \n",
       "1934     NaN     NaN       NaN         NaN       NaN         NaN       NaN   \n",
       "1935     NaN     NaN       NaN         NaN       NaN         NaN       NaN   \n",
       "\n",
       "     coef_type_x    2021_c coef_type_y    2022_c coef_type  \n",
       "0            NaN       NaN         NaN       NaN       NaN  \n",
       "1        highest  5.286002     highest  4.818898   highest  \n",
       "2            NaN       NaN         NaN       NaN       NaN  \n",
       "3            NaN       NaN         NaN       NaN       NaN  \n",
       "4            NaN       NaN         NaN       NaN       NaN  \n",
       "...          ...       ...         ...       ...       ...  \n",
       "1931         NaN       NaN         NaN  1.783478   highest  \n",
       "1932         NaN       NaN         NaN  1.782416   highest  \n",
       "1933         NaN       NaN         NaN  1.777225   highest  \n",
       "1934         NaN       NaN         NaN  1.776941   highest  \n",
       "1935         NaN       NaN         NaN  1.767179   highest  \n",
       "\n",
       "[1936 rows x 19 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv('merged.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something is seriouly messed up in my code. We need to compare pickle and pandas versions. Mine is incompatible\n",
    "\n",
    "Here are my ideas:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- See if we can save ALL coefficients. the scanning of the results section isn't very useful. there are a lot of nouns and very few verbs. not so great\n",
    "- If we cannot save the whole list my next idea is to create a new list with the PAC words and then save the coefficiants for those. \n",
    "- More importantly I think we need to do like top and bottom 500 and then hand fucking sort. I'm thinking append each file, export to excel, remove duplicates, and mark each one. a lot of womens names are showing up. ugh\n",
    "\n",
    "open all the files, rename the coefficents as the year_c, full outer join (i think) on each one into a new DF. \n",
    "I think that will make the data we need \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
