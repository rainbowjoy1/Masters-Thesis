{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#warnings \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#for RNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "\n",
    "import pickle\n",
    "\n",
    "import ast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Sentences for testing RNNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2012_RNN\"\n",
    "path = \"C:/Users/danie/Desktop/Masters Thesis/RNN Models Colab/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.read_pickle(r\"C:\\Users\\danie\\Documents\\GitHub\\Masters-Thesis\\Word Databases\\pos_tag_word_list\")\n",
    "sent_df = pd.read_csv(r\"C:\\Users\\danie\\Documents\\GitHub\\Masters-Thesis\\RNN Sentences\\sample sent idea.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_string(sents):\n",
    "    list_of_strings = []\n",
    "\n",
    "    for word_list in sents:\n",
    "        list_of_strings.append(' '.join(word_list))\n",
    "    return list_of_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df['list'] = sent_df['list'].apply(ast.literal_eval)\n",
    "benchmark_sentences = sent_df['list'].tolist()\n",
    "all_benchmarks = benchmark_string(benchmark_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(path+year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = all_benchmarks\n",
    "x_arrayb = np.asarray(X_b)\n",
    "y_predb = loaded_model.predict(X_b)\n",
    "Yb = pd.DataFrame(y_predb)\n",
    "Yb.reset_index(inplace=True, drop=True)\n",
    "Yb.set_axis(['0 Class Benchamark', '1 Class Benchmark'], axis='columns', inplace=True)\n",
    "sent_df = pd.concat([sent_df, Yb], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test RNN model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NOUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df['replacement string'] = sent_df['replacement string'].apply(ast.literal_eval)\n",
    "\n",
    "\n",
    "noun_list = word_df[(word_df.pos_tag_short == \"N\")][\"feature\"].values.tolist()\n",
    "verb_list = word_df[(word_df.pos_tag_short == \"V\")][\"feature\"].values.tolist()\n",
    "#adverb_list = word_df[(word_df.pos_tag_short == \"R\")][\"feature\"].values.tolist()\n",
    "adjective_list = word_df[(word_df.pos_tag_short == \"J\")][\"feature\"].values.tolist()\n",
    "\n",
    "noun_sent = sent_df[(sent_df['POS tag'] == \"Noun\")][\"replacement string\"].values.tolist()\n",
    "verb_sent = sent_df[(sent_df['POS tag'] == \"Verb\")][\"replacement string\"].values.tolist()\n",
    "adjective_sent = sent_df[(sent_df['POS tag'] == \"Adjective\")][\"replacement string\"].values.tolist()\n",
    "#adverb_sent = sent_df[(sent_df['POS tag'] == \"Adverb\")][\"replacement string\"].values.tolist()\n",
    "\n",
    "#adverb_len = len(adverb_sent)\n",
    "adjective_len = len(adjective_sent)\n",
    "noun_len = len(noun_sent)\n",
    "verb_len = len(verb_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_list(sublist, sentences):\n",
    "    output=[]\n",
    "    for sentence in sentences:\n",
    "        index=sentence.index('UNK')\n",
    "        sentence_copy = sentence.copy()\n",
    "        for sub in sublist:\n",
    "            sentence_copy[index]=sub\n",
    "            output.append([' '.join(sentence_copy.copy()),sentence])\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "sent_n = pd.DataFrame(word_list(noun_list, noun_sent))\n",
    "sent_j = pd.DataFrame(word_list(adjective_list, adjective_sent))\n",
    "#sent_a = pd.DataFrame(word_list(adverb_list, adverb_sent))\n",
    "sent_v = pd.DataFrame(word_list(verb_list, verb_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array_n = np.asarray(sent_n[0])\n",
    "x_array_j = np.asarray(sent_j[0])\n",
    "x_array_v = np.asarray(sent_v[0])\n",
    "#x_array_a = np.asarray(sent_a[0])\n",
    "\n",
    "\n",
    "y_pred_n = loaded_model.predict(x_array_n)\n",
    "y_pred_j = loaded_model.predict(x_array_j)\n",
    "y_pred_v = loaded_model.predict(x_array_v)\n",
    "#y_pred_a = loaded_model.predict(x_array_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You need to change the num_repititons to the number of sentences in the function\n",
    "\n",
    "def labels(word_list, word_len):\n",
    "    num_repetitions = word_len\n",
    "    repeated_words = []\n",
    "    repeated_words = np.tile(word_list, word_len)\n",
    "    return repeated_words\n",
    "\n",
    "noun_labels = pd.DataFrame(labels(noun_list, noun_len))\n",
    "adjective_labels = pd.DataFrame(labels(adjective_list, adjective_len))\n",
    "verb_labels = pd.DataFrame(labels(verb_list, verb_len))\n",
    "#adverb_labels = pd.DataFrame(labels(adverb_list, adverb_len))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_n = pd.DataFrame(y_pred_n)\n",
    "Y_j = pd.DataFrame(y_pred_j)\n",
    "Y_v = pd.DataFrame(y_pred_v)\n",
    "#Y_a = pd.DataFrame(y_pred_a)\n",
    "\n",
    "result_n = pd.concat([noun_labels, Y_n,sent_n], axis=1)\n",
    "result_j = pd.concat([adjective_labels, Y_j,sent_j], axis=1)\n",
    "result_v = pd.concat([verb_labels, Y_v,sent_v], axis=1)\n",
    "#result_a = pd.concat([adverb_labels, Y_a, sent_a], axis=1)\n",
    "\n",
    "result_n.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "result_j.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "result_v.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "#result_a.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([result_v, result_j, result_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_with_source = pd.merge(result, word_df, on='feature', how='left')\n",
    "#verb problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_with_source = result_with_source.dropna()\n",
    "result_with_source['replacement string'] = result_with_source['replacement string'].apply(tuple)\n",
    "sent_df['replacement string'] = sent_df['replacement string'].apply(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(result_with_source, sent_df, on='replacement string', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class 0 Differential'] = df['0 Class'] - df['0 Class Benchamark']\n",
    "df['Class 1 Differential'] = df['1 Class'] - df['1 Class Benchmark']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a section that labels the columns for the year and drops the uneeded oned. \n",
    "df = df.drop(['list','sent','pos_tag','pos_tag_short','replacement string', 'word num','identified word'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_axis( ['feature',year + '_0_class', year + '_1_Class','RNN Sentences', 'source', 'sent_id','POS tag', year + '_0_Class_Benchamark',year + '_1_Class_Benchmark', year + '_Class_0_Differential', year + '_Class_1_Differential'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"RNN_Test_Sentences_\"+year\n",
    "\n",
    "with open(file_name, 'wb') as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
