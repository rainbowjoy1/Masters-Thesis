{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_agency = \"Sap et al. -Connotation Frames of Agency and Power.csv\"\n",
    "\n",
    "power_agency = pd.read_csv(power_agency)\n",
    "power_agency[[\"agency_1\",\"agency_classifier\"]]= power_agency[\"agency\"].str.split(\"_\",expand=True)\n",
    "power_agency[[\"power_1\",\"power_classifier\"]]= power_agency[\"power\"].str.split(\"_\",expand=True)\n",
    "power_agency = power_agency.drop(power_agency[[\"agency\",\"power\", \"agency_1\", \"power_1\"]], axis= 1)\n",
    "power_agency=power_agency.drop(columns='agency_classifier')\n",
    "power_agency = power_agency[power_agency['power_classifier'].isin(['agent','equal']) != True]\n",
    "power_agency = power_agency.dropna()\n",
    "power_agency['source']='power'\n",
    "power_agency.set_axis(['feature', 'weight', 'source'], axis='columns', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communality = \"Lawson et al. - Communality.csv\"\n",
    "communality = pd.read_csv(communality)\n",
    "communality = communality.drop(columns=['Valence Mean', 'Valence SD','Communality SD'])\n",
    "communality['source']='communality'\n",
    "communality.set_axis(['feature', 'weight', 'source'], axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "agency = \"Lawson et al. - Agency Words.csv\"\n",
    "agency = pd.read_csv(agency)\n",
    "agency = agency.drop(agency.columns[[2,3,4]], axis=1)\n",
    "agency = agency.rename(columns={'Word':'feature','Agency Mean':'weight'})\n",
    "agency['source']='agency'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apperance = \"Garg_apperance_words.csv\"\n",
    "\n",
    "apperance = pd.read_csv(apperance)\n",
    "\n",
    "violence = \"Violence_Grievence_Dicitonary.csv\"\n",
    "violence = pd.read_csv(violence)\n",
    "violence = violence.rename(columns={'weights':'weight'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAC_words = [power_agency, communality, agency, violence, apperance]\n",
    "df_attempt = reduce(lambda  left,right: pd.merge(left,right,on=['feature'],how='outer'), PAC_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAC_words = [power_agency, communality, agency, violence, apperance]\n",
    "result = pd.concat(PAC_words)\n",
    "result = result.drop(columns='weight')\n",
    "result = result.drop(columns='weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"full_word_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag, pos_tag_sents\n",
    "import pandas as pd\n",
    "df = result\n",
    "texts = df['feature'].tolist()\n",
    "tagged_texts = pos_tag_sents(map(word_tokenize, texts))\n",
    "df['POS'] = tagged_texts\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.POS.apply(pd.Series)\n",
    "df3.columns = ['1']\n",
    "df3['a'] = df3['1'].str[1]\n",
    "df3['b'] = df3['1'].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = pd.merge(df, df3, left_on = df3['b'], right_on= df['feature'])\n",
    "new_col = new_col.rename(columns = {'a': 'pos_tag'})\n",
    "new_col = new_col.drop(columns=['POS','1','b','key_0'])\n",
    "left = new_col['pos_tag'].str[:1]\n",
    "left = pd.DataFrame(left)\n",
    "left = left.rename(columns={'pos_tag':'pos_tag_short'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = new_col.join(left, on=new_col.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags['pos_tag_short'] = pos_tags['pos_tag_short'].replace({'R':'J', 'I':'N'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file_name =\"pos_tag_word_list\"\n",
    "\n",
    "with open(new_file_name, 'wb') as handle:\n",
    "    pickle.dump(pos_tags, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags['pos_tag_short'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine LogReg High results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2010\n",
    "df_10 = pd.read_pickle(\"RESULTS10_coef_high.pickle\")\n",
    "df_10.rename(columns = {'coef':'2010_c'}, inplace = True)\n",
    "df_10 = df_10.drop(columns=['coef_type','year'])\n",
    "#2011\n",
    "df_11 = pd.read_pickle(\"RESULTS11_coef_high.pickle\")\n",
    "df_11.rename(columns = {'coef':'2011_c'}, inplace = True)\n",
    "df_11 = df_11.drop(columns=['coef_type','year'])\n",
    "#2012\n",
    "df_12 = pd.read_pickle(\"RESULTS12_coef_high.pickle\")\n",
    "df_12.rename(columns = {'coef':'2012_c'}, inplace = True)\n",
    "df_12 = df_12.drop(columns=['coef_type','year'])\n",
    "#2013\n",
    "df_13 = pd.read_pickle(\"RESULTS13_coef_low.pickle\")\n",
    "df_13.rename(columns = {'coef':'2013_c'}, inplace = True)\n",
    "df_13 = df_13.drop(columns=['coef_type','year'])\n",
    "#2014\n",
    "df_14 = pd.read_pickle(\"RESULTS14_coef_high.pickle\")\n",
    "df_14.rename(columns = {'coef':'2014_c'}, inplace = True)\n",
    "df_14 = df_14.drop(columns=['coef_type','year'])\n",
    "#2015\n",
    "df_15 = pd.read_pickle(\"RESULTS15_coef_high.pickle\")\n",
    "df_15.rename(columns = {'coef':'2015_c'}, inplace = True)\n",
    "df_15 = df_15.drop(columns=['coef_type','year'])\n",
    "#2016\n",
    "df_16 = pd.read_pickle(\"RESULTS16_coef_high.pickle\")\n",
    "df_16.rename(columns = {'coef':'2016_c'}, inplace = True)\n",
    "df_16 = df_16.drop(columns=['coef_type','year'])\n",
    "#2017\n",
    "df_17 = pd.read_pickle(\"RESULTS17_coef_high.pickle\")\n",
    "df_17.rename(columns = {'coef':'2017_c'}, inplace = True)\n",
    "df_17 = df_17.drop(columns=['coef_type','year'])\n",
    "#2018\n",
    "df_18 = pd.read_pickle(\"RESULTS18_coef_high.pickle\")\n",
    "df_18.rename(columns = {'coef':'2018_c'}, inplace = True)\n",
    "df_18 = df_18.drop(columns=['coef_type','year'])\n",
    "#2019\n",
    "df_19 = pd.read_pickle(\"RESULTS19_coef_high.pickle\")\n",
    "df_19.rename(columns = {'coef':'2019_c'}, inplace = True)\n",
    "df_19 = df_19.drop(columns=['coef_type','year'])\n",
    "#2020\n",
    "df_20 = pd.read_pickle(\"RESULTS20_coef_high.pickle\")\n",
    "df_20.rename(columns = {'coef':'2020_c'}, inplace = True)\n",
    "df_20 = df_20.drop(columns=['coef_type','year'])\n",
    "#2021\n",
    "df_21 = pd.read_pickle(\"RESULTS21_coef_high.pickle\")\n",
    "df_21.rename(columns = {'coef':'2021_c'}, inplace = True)\n",
    "df_21 = df_21.drop(columns=['coef_type','year'])\n",
    "#2022\n",
    "df_22 = pd.read_pickle(\"RESULTS22_coef_high.pickle\")\n",
    "df_22.rename(columns = {'coef':'2022_c'}, inplace = True)\n",
    "df_22 = df_22.drop(columns=['coef_type','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df_10, df_11, df_12, df_13, df_15, df_16, df_17, df_18, df_19, df_20, df_21, df_22]\n",
    "#df = pd.merge(df_list, right on='feature', how='outer')\n",
    "\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['feature'],how='outer'), df_list)\n",
    "df_high = pd.merge(df_merged, new_col, on='feature', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2010\n",
    "df_10 = pd.read_pickle(\"RESULTS10_coef_low.pickle\")\n",
    "df_10.rename(columns = {'coef':'2010_c'}, inplace = True)\n",
    "df_10 = df_10.drop(columns=['coef_type','year'])\n",
    "#2011\n",
    "df_11 = pd.read_pickle(\"RESULTS11_coef_low.pickle\")\n",
    "df_11.rename(columns = {'coef':'2011_c'}, inplace = True)\n",
    "df_11 = df_11.drop(columns=['coef_type','year'])\n",
    "#2012\n",
    "df_12 = pd.read_pickle(\"RESULTS12_coef_low.pickle\")\n",
    "df_12.rename(columns = {'coef':'2012_c'}, inplace = True)\n",
    "df_12 = df_12.drop(columns=['coef_type','year'])\n",
    "#2013\n",
    "df_13 = pd.read_pickle(\"RESULTS13_coef_low.pickle\")\n",
    "df_13.rename(columns = {'coef':'2013_c'}, inplace = True)\n",
    "df_13 = df_13.drop(columns=['coef_type','year'])\n",
    "#2014\n",
    "df_14 = pd.read_pickle(\"RESULTS14_coef_low.pickle\")\n",
    "df_14.rename(columns = {'coef':'2014_c'}, inplace = True)\n",
    "df_14 = df_14.drop(columns=['coef_type','year'])\n",
    "#2015\n",
    "df_15 = pd.read_pickle(\"RESULTS15_coef_low.pickle\")\n",
    "df_15.rename(columns = {'coef':'2015_c'}, inplace = True)\n",
    "df_15 = df_15.drop(columns=['coef_type','year'])\n",
    "#2016\n",
    "df_16 = pd.read_pickle(\"RESULTS16_coef_low.pickle\")\n",
    "df_16.rename(columns = {'coef':'2016_c'}, inplace = True)\n",
    "df_16 = df_16.drop(columns=['coef_type','year'])\n",
    "#2017\n",
    "df_17 = pd.read_pickle(\"RESULTS17_coef_low.pickle\")\n",
    "df_17.rename(columns = {'coef':'2017_c'}, inplace = True)\n",
    "df_17 = df_17.drop(columns=['coef_type','year'])\n",
    "#2018\n",
    "df_18 = pd.read_pickle(\"RESULTS18_coef_low.pickle\")\n",
    "df_18.rename(columns = {'coef':'2018_c'}, inplace = True)\n",
    "df_18 = df_18.drop(columns=['coef_type','year'])\n",
    "#2019\n",
    "df_19 = pd.read_pickle(\"RESULTS19_coef_low.pickle\")\n",
    "df_19.rename(columns = {'coef':'2019_c'}, inplace = True)\n",
    "df_19 = df_19.drop(columns=['coef_type','year'])\n",
    "#2020\n",
    "df_20 = pd.read_pickle(\"RESULTS20_coef_low.pickle\")\n",
    "df_20.rename(columns = {'coef':'2020_c'}, inplace = True)\n",
    "df_20 = df_20.drop(columns=['coef_type','year'])\n",
    "#2021\n",
    "df_21 = pd.read_pickle(\"RESULTS21_coef_low.pickle\")\n",
    "df_21.rename(columns = {'coef':'2021_c'}, inplace = True)\n",
    "df_21 = df_21.drop(columns=['coef_type','year'])\n",
    "#2022\n",
    "df_22 = pd.read_pickle(\"RESULTS22_coef_low.pickle\")\n",
    "df_22.rename(columns = {'coef':'2022_c'}, inplace = True)\n",
    "df_22 = df_22.drop(columns=['coef_type','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df_10, df_11, df_12, df_13, df_15, df_16, df_17, df_18, df_19, df_20, df_21, df_22]\n",
    "#df = pd.merge(df_list, right on='feature', how='outer')\n",
    "\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['feature'],how='outer'), df_list)\n",
    "df_low = pd.merge(df_merged, new_col, on='feature', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high.groupby(by=['source']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_low.groupby(by=['source']).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
