{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import pickle\n",
    "import numpy as np\n",
    "#pandas 1.4.4\n",
    "#python version\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/DanielleDuncan/Pictures/Camera Roll/Masters-Thesis/Word Databases/\"\n",
    "result = pd.read_pickle(file_path + \"1--Complete Word List\")\n",
    "words = result[\"feature\"].tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the Coefficients out of Log Reg**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_path = \"C:/Users/DanielleDuncan/Desktop/THESIS/logreg results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_year = '2010'\n",
    "\n",
    "with open(open_path + model_year +'_results.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "vocabu = results['tfidf'].vocabulary_\n",
    "\n",
    "word_vector = np.zeros(len(vocabu))\n",
    "for word in words:\n",
    "    if word in vocabu:\n",
    "        index = vocabu[word]\n",
    "        word_vector[index] = 1\n",
    "\n",
    "coefficients = results['model'].coef_[0]\n",
    "word_coefficients = {word: coefficient for word, coefficient in zip(vocabu.keys(), coefficients)}\n",
    "\n",
    "coef_store = []\n",
    "\n",
    "for word in words:\n",
    "    if word in word_coefficients:\n",
    "        coef_store.append((f\"{word}, {word_coefficients[word]}\"))\n",
    "\n",
    "results_coef = pd.DataFrame(coef_store)\n",
    "results_coef = pd.concat([results_coef[[0]], results_coef[0].str.split(', ', expand=True)], axis=1)\n",
    "results_coef.set_axis(['drop', 'feature', model_year + '_coef'], axis='columns', inplace=True)\n",
    "merged_left = pd.merge(left=result, right=results_coef, how='left', left_on='feature', right_on='feature')\n",
    "merged_left = merged_left.drop(['drop'], axis=1)\n",
    "\n",
    "df = merged_left\n",
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = ['2011', '2012', '2013', '2014', '2015',\"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in year_list:\n",
    "\n",
    "    with open(open_path + year +'_results.pkl', 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "\n",
    "    vocabu = results['tfidf'].vocabulary_\n",
    "\n",
    "    word_vector = np.zeros(len(vocabu))\n",
    "    for word in words:\n",
    "        if word in vocabu:\n",
    "            index = vocabu[word]\n",
    "            word_vector[index] = 1\n",
    "\n",
    "    coefficients = results['model'].coef_[0]\n",
    "    word_coefficients = {word: coefficient for word, coefficient in zip(vocabu.keys(), coefficients)}\n",
    "\n",
    "    coef_store = []\n",
    "\n",
    "    for word in words:\n",
    "        if word in word_coefficients:\n",
    "            coef_store.append((f\"{word}, {word_coefficients[word]}\"))\n",
    "\n",
    "    results_coef = pd.DataFrame(coef_store)\n",
    "    results_coef = pd.concat([results_coef[[0]], results_coef[0].str.split(', ', expand=True)], axis=1)\n",
    "    results_coef.set_axis(['drop', 'feature', year + '_coef'], axis='columns', inplace=True)\n",
    "    merged_left = pd.merge(left=result, right=results_coef, how='left', left_on='feature', right_on='feature')\n",
    "    merged_left = merged_left.drop(['drop'], axis=1)\n",
    "\n",
    "    df = pd.merge(left = df, right = merged_left, how= 'inner', left_on=['feature','source'], right_on=['feature', 'source'])\n",
    "    df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"LogReg CSV PAC Yearly Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"LogReg--Pickle PAC Yearly Results\"\n",
    "\n",
    "with open(file_name, 'wb') as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
