{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#warnings \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#for RNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "\n",
    "import pickle\n",
    "\n",
    "import ast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Sentences for testing RNNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2019\"\n",
    "path = \"C:/Users/danie/Desktop/RNN_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.read_pickle(\"pos_tag_word_list\")\n",
    "sent_df = pd.read_csv(\"sample sent idea.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_string(sents):\n",
    "    list_of_strings = []\n",
    "\n",
    "    for word_list in sents:\n",
    "        list_of_strings.append(' '.join(word_list))\n",
    "    return list_of_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df['list'] = sent_df['list'].apply(ast.literal_eval)\n",
    "benchmark_sentences = sent_df['list'].tolist()\n",
    "all_benchmarks = benchmark_string(benchmark_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(path+year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 4s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "X_b = all_benchmarks\n",
    "x_arrayb = np.asarray(X_b)\n",
    "y_predb = loaded_model.predict(X_b)\n",
    "Yb = pd.DataFrame(y_predb)\n",
    "Yb.reset_index(inplace=True, drop=True)\n",
    "Yb.set_axis(['0 Class Benchamark', '1 Class Benchmark'], axis='columns', inplace=True)\n",
    "sent_df = pd.concat([sent_df, Yb], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test RNN model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NOUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df['replacement string'] = sent_df['replacement string'].apply(ast.literal_eval)\n",
    "\n",
    "\n",
    "noun_list = word_df[(word_df.pos_tag_short == \"N\")][\"feature\"].values.tolist()\n",
    "verb_list = word_df[(word_df.pos_tag_short == \"V\")][\"feature\"].values.tolist()\n",
    "#adverb_list = word_df[(word_df.pos_tag_short == \"R\")][\"feature\"].values.tolist()\n",
    "adjective_list = word_df[(word_df.pos_tag_short == \"J\")][\"feature\"].values.tolist()\n",
    "\n",
    "noun_sent = sent_df[(sent_df['POS tag'] == \"Noun\")][\"replacement string\"].values.tolist()\n",
    "verb_sent = sent_df[(sent_df['POS tag'] == \"Verb\")][\"replacement string\"].values.tolist()\n",
    "adjective_sent = sent_df[(sent_df['POS tag'] == \"Adjective\")][\"replacement string\"].values.tolist()\n",
    "#adverb_sent = sent_df[(sent_df['POS tag'] == \"Adverb\")][\"replacement string\"].values.tolist()\n",
    "\n",
    "#adverb_len = len(adverb_sent)\n",
    "adjective_len = len(adjective_sent)\n",
    "noun_len = len(noun_sent)\n",
    "verb_len = len(verb_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_list(sublist, sentences):\n",
    "    output=[]\n",
    "    for sentence in sentences:\n",
    "        index=sentence.index('UNK')\n",
    "        sentence_copy = sentence.copy()\n",
    "        for sub in sublist:\n",
    "            sentence_copy[index]=sub\n",
    "            output.append([' '.join(sentence_copy.copy()),sentence])\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "sent_n = pd.DataFrame(word_list(noun_list, noun_sent))\n",
    "sent_j = pd.DataFrame(word_list(adjective_list, adjective_sent))\n",
    "#sent_a = pd.DataFrame(word_list(adverb_list, adverb_sent))\n",
    "sent_v = pd.DataFrame(word_list(verb_list, verb_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1394/1394 [==============================] - 13s 9ms/step\n",
      "164/164 [==============================] - 2s 10ms/step\n",
      "81/81 [==============================] - 1s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "x_array_n = np.asarray(sent_n[0])\n",
    "x_array_j = np.asarray(sent_j[0])\n",
    "x_array_v = np.asarray(sent_v[0])\n",
    "#x_array_a = np.asarray(sent_a[0])\n",
    "\n",
    "\n",
    "y_pred_n = loaded_model.predict(x_array_n)\n",
    "y_pred_j = loaded_model.predict(x_array_j)\n",
    "y_pred_v = loaded_model.predict(x_array_v)\n",
    "#y_pred_a = loaded_model.predict(x_array_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You need to change the num_repititons to the number of sentences in the function\n",
    "\n",
    "def labels(word_list, word_len):\n",
    "    num_repetitions = word_len\n",
    "    repeated_words = []\n",
    "    repeated_words = np.tile(word_list, word_len)\n",
    "    return repeated_words\n",
    "\n",
    "noun_labels = pd.DataFrame(labels(noun_list, noun_len))\n",
    "adjective_labels = pd.DataFrame(labels(adjective_list, adjective_len))\n",
    "verb_labels = pd.DataFrame(labels(verb_list, verb_len))\n",
    "#adverb_labels = pd.DataFrame(labels(adverb_list, adverb_len))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_n = pd.DataFrame(y_pred_n)\n",
    "Y_j = pd.DataFrame(y_pred_j)\n",
    "Y_v = pd.DataFrame(y_pred_v)\n",
    "#Y_a = pd.DataFrame(y_pred_a)\n",
    "\n",
    "result_n = pd.concat([noun_labels, Y_n,sent_n], axis=1)\n",
    "result_j = pd.concat([adjective_labels, Y_j,sent_j], axis=1)\n",
    "result_v = pd.concat([verb_labels, Y_v,sent_v], axis=1)\n",
    "#result_a = pd.concat([adverb_labels, Y_a, sent_a], axis=1)\n",
    "\n",
    "result_n.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "result_j.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "result_v.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "#result_a.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([result_v, result_j, result_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_with_source = pd.merge(result, word_df, on='feature', how='left')\n",
    "#verb problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_with_source = result_with_source.dropna()\n",
    "result_with_source['replacement string'] = result_with_source['replacement string'].apply(tuple)\n",
    "sent_df['replacement string'] = sent_df['replacement string'].apply(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(result_with_source, sent_df, on='replacement string', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class 0 Differential'] = df['0 Class'] - df['0 Class Benchamark']\n",
    "df['Class 1 Differential'] = df['1 Class'] - df['1 Class Benchmark']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>0 Class</th>\n",
       "      <th>1 Class</th>\n",
       "      <th>RNN Sentences</th>\n",
       "      <th>replacement string</th>\n",
       "      <th>source</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>pos_tag_short</th>\n",
       "      <th>snet id</th>\n",
       "      <th>list</th>\n",
       "      <th>sent</th>\n",
       "      <th>POS tag</th>\n",
       "      <th>word num</th>\n",
       "      <th>identified word</th>\n",
       "      <th>0 Class Benchamark</th>\n",
       "      <th>1 Class Benchmark</th>\n",
       "      <th>Class 0 Differential</th>\n",
       "      <th>Class 1 Differential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apologize</td>\n",
       "      <td>1.852032</td>\n",
       "      <td>-2.166067</td>\n",
       "      <td>apologize owner irresponsible</td>\n",
       "      <td>(UNK, owner, irresponsible)</td>\n",
       "      <td>power</td>\n",
       "      <td>VB</td>\n",
       "      <td>V</td>\n",
       "      <td>11405</td>\n",
       "      <td>[add, owner, irresponsible]</td>\n",
       "      <td>She added: \"These owners are irresponsible...</td>\n",
       "      <td>Verb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>add</td>\n",
       "      <td>1.605247</td>\n",
       "      <td>-1.932908</td>\n",
       "      <td>0.246785</td>\n",
       "      <td>-0.233159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recognize</td>\n",
       "      <td>1.703485</td>\n",
       "      <td>-2.013770</td>\n",
       "      <td>recognize owner irresponsible</td>\n",
       "      <td>(UNK, owner, irresponsible)</td>\n",
       "      <td>power</td>\n",
       "      <td>VB</td>\n",
       "      <td>V</td>\n",
       "      <td>11405</td>\n",
       "      <td>[add, owner, irresponsible]</td>\n",
       "      <td>She added: \"These owners are irresponsible...</td>\n",
       "      <td>Verb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>add</td>\n",
       "      <td>1.605247</td>\n",
       "      <td>-1.932908</td>\n",
       "      <td>0.098238</td>\n",
       "      <td>-0.080862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recognize</td>\n",
       "      <td>1.703485</td>\n",
       "      <td>-2.013770</td>\n",
       "      <td>recognize owner irresponsible</td>\n",
       "      <td>(UNK, owner, irresponsible)</td>\n",
       "      <td>power</td>\n",
       "      <td>VB</td>\n",
       "      <td>V</td>\n",
       "      <td>11405</td>\n",
       "      <td>[add, owner, irresponsible]</td>\n",
       "      <td>She added: \"These owners are irresponsible...</td>\n",
       "      <td>Verb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>add</td>\n",
       "      <td>1.605247</td>\n",
       "      <td>-1.932908</td>\n",
       "      <td>0.098238</td>\n",
       "      <td>-0.080862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recognize</td>\n",
       "      <td>1.703485</td>\n",
       "      <td>-2.013770</td>\n",
       "      <td>recognize owner irresponsible</td>\n",
       "      <td>(UNK, owner, irresponsible)</td>\n",
       "      <td>power</td>\n",
       "      <td>VB</td>\n",
       "      <td>V</td>\n",
       "      <td>11405</td>\n",
       "      <td>[add, owner, irresponsible]</td>\n",
       "      <td>She added: \"These owners are irresponsible...</td>\n",
       "      <td>Verb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>add</td>\n",
       "      <td>1.605247</td>\n",
       "      <td>-1.932908</td>\n",
       "      <td>0.098238</td>\n",
       "      <td>-0.080862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recognize</td>\n",
       "      <td>1.703485</td>\n",
       "      <td>-2.013770</td>\n",
       "      <td>recognize owner irresponsible</td>\n",
       "      <td>(UNK, owner, irresponsible)</td>\n",
       "      <td>power</td>\n",
       "      <td>VB</td>\n",
       "      <td>V</td>\n",
       "      <td>11405</td>\n",
       "      <td>[add, owner, irresponsible]</td>\n",
       "      <td>She added: \"These owners are irresponsible...</td>\n",
       "      <td>Verb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>add</td>\n",
       "      <td>1.605247</td>\n",
       "      <td>-1.932908</td>\n",
       "      <td>0.098238</td>\n",
       "      <td>-0.080862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76332</th>\n",
       "      <td>slender</td>\n",
       "      <td>2.685966</td>\n",
       "      <td>-3.199537</td>\n",
       "      <td>zoom past slender moped afghan</td>\n",
       "      <td>(zoom, past, UNK, moped, afghan)</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9365</td>\n",
       "      <td>[zoom, past, marine, moped, afghan]</td>\n",
       "      <td>An Afghan man zooms past the marines on his mo...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>2.0</td>\n",
       "      <td>marine</td>\n",
       "      <td>2.873104</td>\n",
       "      <td>-3.364557</td>\n",
       "      <td>-0.187139</td>\n",
       "      <td>0.165020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76333</th>\n",
       "      <td>handsome</td>\n",
       "      <td>3.793753</td>\n",
       "      <td>-4.515001</td>\n",
       "      <td>zoom past handsome moped afghan</td>\n",
       "      <td>(zoom, past, UNK, moped, afghan)</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9365</td>\n",
       "      <td>[zoom, past, marine, moped, afghan]</td>\n",
       "      <td>An Afghan man zooms past the marines on his mo...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>2.0</td>\n",
       "      <td>marine</td>\n",
       "      <td>2.873104</td>\n",
       "      <td>-3.364557</td>\n",
       "      <td>0.920649</td>\n",
       "      <td>-1.150444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76334</th>\n",
       "      <td>fat</td>\n",
       "      <td>1.458814</td>\n",
       "      <td>-1.820174</td>\n",
       "      <td>zoom past fat moped afghan</td>\n",
       "      <td>(zoom, past, UNK, moped, afghan)</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9365</td>\n",
       "      <td>[zoom, past, marine, moped, afghan]</td>\n",
       "      <td>An Afghan man zooms past the marines on his mo...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>2.0</td>\n",
       "      <td>marine</td>\n",
       "      <td>2.873104</td>\n",
       "      <td>-3.364557</td>\n",
       "      <td>-1.414291</td>\n",
       "      <td>1.544384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76335</th>\n",
       "      <td>thin</td>\n",
       "      <td>1.883442</td>\n",
       "      <td>-2.319654</td>\n",
       "      <td>zoom past thin moped afghan</td>\n",
       "      <td>(zoom, past, UNK, moped, afghan)</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9365</td>\n",
       "      <td>[zoom, past, marine, moped, afghan]</td>\n",
       "      <td>An Afghan man zooms past the marines on his mo...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>2.0</td>\n",
       "      <td>marine</td>\n",
       "      <td>2.873104</td>\n",
       "      <td>-3.364557</td>\n",
       "      <td>-0.989662</td>\n",
       "      <td>1.044904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76336</th>\n",
       "      <td>beautiful</td>\n",
       "      <td>2.153596</td>\n",
       "      <td>-2.528536</td>\n",
       "      <td>zoom past beautiful moped afghan</td>\n",
       "      <td>(zoom, past, UNK, moped, afghan)</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9365</td>\n",
       "      <td>[zoom, past, marine, moped, afghan]</td>\n",
       "      <td>An Afghan man zooms past the marines on his mo...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>2.0</td>\n",
       "      <td>marine</td>\n",
       "      <td>2.873104</td>\n",
       "      <td>-3.364557</td>\n",
       "      <td>-0.719509</td>\n",
       "      <td>0.836021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76337 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature   0 Class   1 Class                     RNN Sentences  \\\n",
       "0      apologize  1.852032 -2.166067     apologize owner irresponsible   \n",
       "1      recognize  1.703485 -2.013770     recognize owner irresponsible   \n",
       "2      recognize  1.703485 -2.013770     recognize owner irresponsible   \n",
       "3      recognize  1.703485 -2.013770     recognize owner irresponsible   \n",
       "4      recognize  1.703485 -2.013770     recognize owner irresponsible   \n",
       "...          ...       ...       ...                               ...   \n",
       "76332    slender  2.685966 -3.199537    zoom past slender moped afghan   \n",
       "76333   handsome  3.793753 -4.515001   zoom past handsome moped afghan   \n",
       "76334        fat  1.458814 -1.820174        zoom past fat moped afghan   \n",
       "76335       thin  1.883442 -2.319654       zoom past thin moped afghan   \n",
       "76336  beautiful  2.153596 -2.528536  zoom past beautiful moped afghan   \n",
       "\n",
       "                     replacement string     source pos_tag pos_tag_short  \\\n",
       "0           (UNK, owner, irresponsible)      power      VB             V   \n",
       "1           (UNK, owner, irresponsible)      power      VB             V   \n",
       "2           (UNK, owner, irresponsible)      power      VB             V   \n",
       "3           (UNK, owner, irresponsible)      power      VB             V   \n",
       "4           (UNK, owner, irresponsible)      power      VB             V   \n",
       "...                                 ...        ...     ...           ...   \n",
       "76332  (zoom, past, UNK, moped, afghan)  Apperance      NN             N   \n",
       "76333  (zoom, past, UNK, moped, afghan)  Apperance      NN             N   \n",
       "76334  (zoom, past, UNK, moped, afghan)  Apperance      NN             N   \n",
       "76335  (zoom, past, UNK, moped, afghan)  Apperance      NN             N   \n",
       "76336  (zoom, past, UNK, moped, afghan)  Apperance      NN             N   \n",
       "\n",
       "       snet id                                 list  \\\n",
       "0        11405          [add, owner, irresponsible]   \n",
       "1        11405          [add, owner, irresponsible]   \n",
       "2        11405          [add, owner, irresponsible]   \n",
       "3        11405          [add, owner, irresponsible]   \n",
       "4        11405          [add, owner, irresponsible]   \n",
       "...        ...                                  ...   \n",
       "76332     9365  [zoom, past, marine, moped, afghan]   \n",
       "76333     9365  [zoom, past, marine, moped, afghan]   \n",
       "76334     9365  [zoom, past, marine, moped, afghan]   \n",
       "76335     9365  [zoom, past, marine, moped, afghan]   \n",
       "76336     9365  [zoom, past, marine, moped, afghan]   \n",
       "\n",
       "                                                    sent POS tag  word num  \\\n",
       "0          She added: \"These owners are irresponsible...    Verb       0.0   \n",
       "1          She added: \"These owners are irresponsible...    Verb       0.0   \n",
       "2          She added: \"These owners are irresponsible...    Verb       0.0   \n",
       "3          She added: \"These owners are irresponsible...    Verb       0.0   \n",
       "4          She added: \"These owners are irresponsible...    Verb       0.0   \n",
       "...                                                  ...     ...       ...   \n",
       "76332  An Afghan man zooms past the marines on his mo...    Noun       2.0   \n",
       "76333  An Afghan man zooms past the marines on his mo...    Noun       2.0   \n",
       "76334  An Afghan man zooms past the marines on his mo...    Noun       2.0   \n",
       "76335  An Afghan man zooms past the marines on his mo...    Noun       2.0   \n",
       "76336  An Afghan man zooms past the marines on his mo...    Noun       2.0   \n",
       "\n",
       "      identified word  0 Class Benchamark  1 Class Benchmark  \\\n",
       "0                 add            1.605247          -1.932908   \n",
       "1                 add            1.605247          -1.932908   \n",
       "2                 add            1.605247          -1.932908   \n",
       "3                 add            1.605247          -1.932908   \n",
       "4                 add            1.605247          -1.932908   \n",
       "...               ...                 ...                ...   \n",
       "76332          marine            2.873104          -3.364557   \n",
       "76333          marine            2.873104          -3.364557   \n",
       "76334          marine            2.873104          -3.364557   \n",
       "76335          marine            2.873104          -3.364557   \n",
       "76336          marine            2.873104          -3.364557   \n",
       "\n",
       "       Class 0 Differential  Class 1 Differential  \n",
       "0                  0.246785             -0.233159  \n",
       "1                  0.098238             -0.080862  \n",
       "2                  0.098238             -0.080862  \n",
       "3                  0.098238             -0.080862  \n",
       "4                  0.098238             -0.080862  \n",
       "...                     ...                   ...  \n",
       "76332             -0.187139              0.165020  \n",
       "76333              0.920649             -1.150444  \n",
       "76334             -1.414291              1.544384  \n",
       "76335             -0.989662              1.044904  \n",
       "76336             -0.719509              0.836021  \n",
       "\n",
       "[76337 rows x 18 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a section that labels the columns for the year and drops the uneeded oned. \n",
    "df = df.drop(['list','sent','pos_tag','pos_tag_short','replacement string', 'word num','identified word'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_axis( ['feature',year + '_0_class', year + '_1_Class','RNN Sentences', 'source', 'sent_id','POS tag', year + '_0_Class_Benchamark',year + '_1_Class_Benchmark', year + '_Class_0_Differential', year + '_Class_1_Differential'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"RNN_Test_Sentences_\"+year\n",
    "\n",
    "with open(file_name, 'wb') as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
