{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nytimes-scraper\n",
    "import datetime as dt\n",
    "from nytimes_scraper.nyt_api import NytApi\n",
    "#from nytimes_scraper.articles import fetch_articles_by_month, articles_to_df\n",
    "from nytimes_scraper import run_scraper, scrape_month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = NytApi('FwXEDbsh0gDgF94OHOU4d9aJRjfXdyCv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Githubs with code: \n",
    "https://github.com/ietz/nytimes-scraper (implemented above)\n",
    "\n",
    "https://github.com/suewoon/nyt-api-wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching articles for 2020-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 1642/4240 [04:50<06:32,  6.62Article/s]"
     ]
    }
   ],
   "source": [
    "# scrape february of 2020\n",
    "article_df = scrape_month('FwXEDbsh0gDgF94OHOU4d9aJRjfXdyCv', date=dt.date(2020, 2, 1))\n",
    "\n",
    "# scrape all articles month by month\n",
    "run_scraper('FwXEDbsh0gDgF94OHOU4d9aJRjfXdyCv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMMENTS**\n",
    "I tried running the above with the api variable but it prefers the full length string for some reason. The pieces of code fully run and after loading 100% of the articles for the month it gives an error. Not sure why. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/brainyrobo/nyt-scraper/notebook (other scraper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export NYT_API_TOKEN='FwXEDbsh0gDgF94OHOU4d9aJRjfXdyCv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/brainyrobo/nyt-scraper/notebook?scriptVersionId=50372330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting console-progressbar\n",
      "  Downloading console_progressbar-1.1.2.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: console-progressbar\n",
      "  Building wheel for console-progressbar (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for console-progressbar: filename=console_progressbar-1.1.2-py3-none-any.whl size=4139 sha256=1c1e9f4c333b11fbde1a815683b9f5dc4d000d6c203eea93a2a4b4180c00a076\n",
      "  Stored in directory: /Users/yolandaferreirofranchi/Library/Caches/pip/wheels/3a/63/bd/ef864ce125cac534f907d89983080597a83492c8a5cee04091\n",
      "Successfully built console-progressbar\n",
      "Installing collected packages: console-progressbar\n",
      "Successfully installed console-progressbar-1.1.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install console-progressbar\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "from console_progressbar import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 100.000% End\n",
      "Start |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 100.000% End\n",
      "Start |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 100.000% End\n",
      "Start |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 100.000% End\n",
      "Start |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 100.000% End\n",
      "Start |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 100.000% End\n",
      "Start |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 100.000% End\n",
      "Start |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 100.000% End\n",
      "Start |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 100.000% End\n",
      "Start |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 100.000% End\n"
     ]
    }
   ],
   "source": [
    "YEAR = 2010\n",
    "MONTH = 1\n",
    "BASE_URL = \"https://api.nytimes.com/svc/archive/v1/{y}/{m}.json?api-key=FwXEDbsh0gDgF94OHOU4d9aJRjfXdyCv\".format(y = YEAR,m = MONTH)\n",
    "temp_data = []\n",
    "count = 0\n",
    "\n",
    "# Pick how many articles you want per month\n",
    "DATA_PER_MONTH = 5\n",
    "## Go through the years\n",
    "for y in range(2010,2011):\n",
    "\n",
    "  # in every month of that year\n",
    "  for m in range(1,11):\n",
    "    BASE_URL = \"https://api.nytimes.com/svc/archive/v1/{y}/{m}.json?api-key=FwXEDbsh0gDgF94OHOU4d9aJRjfXdyCv\".format(y = y,m = m)\n",
    "    # get all moth news data\n",
    "    all_data = requests.get(BASE_URL).json()\n",
    "    # extract the article from each news URL\n",
    "    count = 0\n",
    "    pb = ProgressBar(total=len(all_data[\"response\"][\"docs\"][:DATA_PER_MONTH]),prefix='Start', suffix='End', decimals=3, length=50, fill='X', zfill='-')\n",
    "    for temp_news in all_data[\"response\"][\"docs\"][:DATA_PER_MONTH]:\n",
    "      count += 1\n",
    "      pb.print_progress_bar(count)\n",
    "      news_body = requests.get(temp_news[\"web_url\"]).text\n",
    "      body = BeautifulSoup(news_body, 'html.parser').find(attrs={\"name\": \"articleBody\"})\n",
    "      if body != None:\n",
    "        temp_data.append({\"headline\":temp_news[\"headline\"][\"main\"],\"body\":body.get_text()})\n",
    "    temp_data = json.dumps(temp_data)\n",
    "    f = open(\"{y}-{m}.json\".format(y=y,m=m),\"w\")\n",
    "    f.write(temp_data)\n",
    "    f.close()\n",
    "    temp_data = []\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('2010-1.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Use the data\n",
    "print(data)\n",
    "\n",
    "#string ends up empty? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ashleychampagne/Web-Scraping-Toolkit/blob/master/NYT-Collection-Workflow.md"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last-resorts** \n",
    "https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset\n",
    "\n",
    "This kaggle dataset has 1M articles from multiple news sources across the topics of business, world news, science, and sports and was developed by a researcher at NYU\n",
    "\n",
    "https://crawlfeeds.com/datasets/news-category-dataset-from-huffpost - $350 for 500K articles from the Huffpost from 2015-2022. \n",
    "\n",
    "https://crawlfeeds.com/datasets/15 - $225 for 1.1M articles from the BBC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading sample snippet (15,000 articles)\n",
    "import pandas as pd\n",
    "df = pd.read_json('https://query.data.world/s/omsfbhhnkn66z77ixelbrbpd43w343')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>news_post_date</th>\n",
       "      <th>raw_content</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>language</th>\n",
       "      <th>_id</th>\n",
       "      <th>region</th>\n",
       "      <th>short_description</th>\n",
       "      <th>category</th>\n",
       "      <th>crawled_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Why quitting heroin substitute methadone is 'v...</td>\n",
       "      <td>2010-08-06T02:46:40.000Z</td>\n",
       "      <td>&lt;div data-component=\"text-block\" class=\"ssrcss...</td>\n",
       "      <td>The heroin substitute methadone can be used as...</td>\n",
       "      <td>https://www.bbc.co.uk/news/health-10869329</td>\n",
       "      <td>By Linda Pressly</td>\n",
       "      <td>en_GB</td>\n",
       "      <td>45cbcb62-840b-5a1d-9b59-d7f57f3ab7f6</td>\n",
       "      <td>Health</td>\n",
       "      <td>Heroin substitute methadone is used to wean ad...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>2021-05-02 17:19:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North Korea, Kim Jong-un, Kim Jong-il, Kim Jon...</td>\n",
       "      <td>North Korea leader's eldest son 'opposes dynasty'</td>\n",
       "      <td>2010-10-12T08:54:42.000Z</td>\n",
       "      <td>&lt;div data-component=\"text-block\" class=\"ssrcss...</td>\n",
       "      <td>The eldest son of North Korean leader Kim Jong...</td>\n",
       "      <td>https://www.bbc.co.uk/news/world-asia-pacific-...</td>\n",
       "      <td></td>\n",
       "      <td>en_GB</td>\n",
       "      <td>771b9c0d-88e1-589f-bf56-8ef80ce161a2</td>\n",
       "      <td>Asia-Pacific</td>\n",
       "      <td>The eldest son of North Korean leader Kim Jong...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>2021-05-02 17:19:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Paintings by gangster Reggie Kray go on sale i...</td>\n",
       "      <td>2010-10-27T17:35:24.000Z</td>\n",
       "      <td>&lt;div data-component=\"text-block\" class=\"ssrcss...</td>\n",
       "      <td>Seven oil paintings created by notorious gangs...</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-england-lincolns...</td>\n",
       "      <td></td>\n",
       "      <td>en_GB</td>\n",
       "      <td>768e3fc6-c406-5570-8328-2e6fb75abd1b</td>\n",
       "      <td>Lincolnshire</td>\n",
       "      <td>A series of oil painting produced by gangster ...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>2021-05-02 17:19:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Bracklinn Falls Bridge hauled over gorge by hand</td>\n",
       "      <td>2010-10-08T13:21:50.000Z</td>\n",
       "      <td>&lt;div data-component=\"text-block\" class=\"ssrcss...</td>\n",
       "      <td>A 20-tonne bridge is being hauled into place b...</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-scotland-tayside...</td>\n",
       "      <td></td>\n",
       "      <td>en_GB</td>\n",
       "      <td>a6e26396-70ec-501c-8ebc-1d600ddf6aab</td>\n",
       "      <td>Tayside and Central Scotland</td>\n",
       "      <td>A 20-tonne bridge is having to be hauled into ...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>2021-05-02 17:19:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Manchester soldier's last words become song</td>\n",
       "      <td>2010-09-22T17:35:34.000Z</td>\n",
       "      <td>&lt;div data-component=\"text-block\" class=\"ssrcss...</td>\n",
       "      <td>The final words written by a guardsman killed ...</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-england-manchest...</td>\n",
       "      <td></td>\n",
       "      <td>en_GB</td>\n",
       "      <td>e8a150a5-b6e0-5315-9c04-fc639dee196f</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>The final words written by a guardsman from Ma...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>2021-05-02 17:19:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15820</th>\n",
       "      <td></td>\n",
       "      <td>Police hands over garage death inquiry to HSE</td>\n",
       "      <td>2010-07-20T00:45:18.000Z</td>\n",
       "      <td>&lt;div data-component=\"text-block\" class=\"ssrcss...</td>\n",
       "      <td>An investigation into the death of a young mec...</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-scotland-north-e...</td>\n",
       "      <td></td>\n",
       "      <td>en_GB</td>\n",
       "      <td>ac717def-725f-5a4d-a19f-77ac6bb95771</td>\n",
       "      <td>NE Scotland, Orkney &amp; Shetland</td>\n",
       "      <td>An investigation into the death of a young mec...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>2021-05-02 18:08:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15821</th>\n",
       "      <td></td>\n",
       "      <td>Pringle appeals for help to create archive</td>\n",
       "      <td>2010-07-20T00:43:18.000Z</td>\n",
       "      <td>&lt;div data-component=\"text-block\" class=\"ssrcss...</td>\n",
       "      <td>One of the Borders' best known textile compani...</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-scotland-south-s...</td>\n",
       "      <td></td>\n",
       "      <td>en_GB</td>\n",
       "      <td>0f761bbe-3b28-5d40-b40c-fe112260e8f1</td>\n",
       "      <td>South Scotland</td>\n",
       "      <td>Borders-based knitwear firm Pringle of Scotlan...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>2021-05-02 18:08:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15822</th>\n",
       "      <td></td>\n",
       "      <td>Voice technology 'could help detect autism'</td>\n",
       "      <td>2010-07-19T23:09:28.000Z</td>\n",
       "      <td>&lt;div data-component=\"text-block\" class=\"ssrcss...</td>\n",
       "      <td>Young children with autism can be identified b...</td>\n",
       "      <td>https://www.bbc.co.uk/news/health-10686912</td>\n",
       "      <td></td>\n",
       "      <td>en_GB</td>\n",
       "      <td>4631fe89-97cd-5d1d-b69b-6f16896bb242</td>\n",
       "      <td>Health</td>\n",
       "      <td>A new vocal analysis tool could help screen fo...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>2021-05-02 18:08:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15823</th>\n",
       "      <td></td>\n",
       "      <td>New homes target for Bristol and North Somerse...</td>\n",
       "      <td>2010-07-19T15:37:11.000Z</td>\n",
       "      <td>&lt;div data-component=\"text-block\" class=\"ssrcss...</td>\n",
       "      <td>Thousands of homes planned to be built in Bris...</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-england-bristol-...</td>\n",
       "      <td></td>\n",
       "      <td>en_GB</td>\n",
       "      <td>f04abfa4-36b1-5a1c-8ee3-8cbc8921e609</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>Thousands of homes planned for Bristol and Nor...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>2021-05-02 18:08:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15824</th>\n",
       "      <td></td>\n",
       "      <td>Newspaper review: 'Big society' under microscope</td>\n",
       "      <td>2010-07-20T05:03:43.000Z</td>\n",
       "      <td>&lt;div data-component=\"text-block\" class=\"ssrcss...</td>\n",
       "      <td>David Cameron's flagship policy, the \"big soci...</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-10693549</td>\n",
       "      <td></td>\n",
       "      <td>en_GB</td>\n",
       "      <td>0490ad7e-96ce-5090-a137-e95aa2e14d70</td>\n",
       "      <td>UK</td>\n",
       "      <td>David Cameron's flagship policy, the \"big soci...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>2021-05-02 18:08:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15825 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tags  \\\n",
       "0                                                          \n",
       "1      North Korea, Kim Jong-un, Kim Jong-il, Kim Jon...   \n",
       "2                                                          \n",
       "3                                                          \n",
       "4                                                          \n",
       "...                                                  ...   \n",
       "15820                                                      \n",
       "15821                                                      \n",
       "15822                                                      \n",
       "15823                                                      \n",
       "15824                                                      \n",
       "\n",
       "                                                   title  \\\n",
       "0      Why quitting heroin substitute methadone is 'v...   \n",
       "1      North Korea leader's eldest son 'opposes dynasty'   \n",
       "2      Paintings by gangster Reggie Kray go on sale i...   \n",
       "3       Bracklinn Falls Bridge hauled over gorge by hand   \n",
       "4            Manchester soldier's last words become song   \n",
       "...                                                  ...   \n",
       "15820      Police hands over garage death inquiry to HSE   \n",
       "15821         Pringle appeals for help to create archive   \n",
       "15822        Voice technology 'could help detect autism'   \n",
       "15823  New homes target for Bristol and North Somerse...   \n",
       "15824   Newspaper review: 'Big society' under microscope   \n",
       "\n",
       "                 news_post_date  \\\n",
       "0      2010-08-06T02:46:40.000Z   \n",
       "1      2010-10-12T08:54:42.000Z   \n",
       "2      2010-10-27T17:35:24.000Z   \n",
       "3      2010-10-08T13:21:50.000Z   \n",
       "4      2010-09-22T17:35:34.000Z   \n",
       "...                         ...   \n",
       "15820  2010-07-20T00:45:18.000Z   \n",
       "15821  2010-07-20T00:43:18.000Z   \n",
       "15822  2010-07-19T23:09:28.000Z   \n",
       "15823  2010-07-19T15:37:11.000Z   \n",
       "15824  2010-07-20T05:03:43.000Z   \n",
       "\n",
       "                                             raw_content  \\\n",
       "0      <div data-component=\"text-block\" class=\"ssrcss...   \n",
       "1      <div data-component=\"text-block\" class=\"ssrcss...   \n",
       "2      <div data-component=\"text-block\" class=\"ssrcss...   \n",
       "3      <div data-component=\"text-block\" class=\"ssrcss...   \n",
       "4      <div data-component=\"text-block\" class=\"ssrcss...   \n",
       "...                                                  ...   \n",
       "15820  <div data-component=\"text-block\" class=\"ssrcss...   \n",
       "15821  <div data-component=\"text-block\" class=\"ssrcss...   \n",
       "15822  <div data-component=\"text-block\" class=\"ssrcss...   \n",
       "15823  <div data-component=\"text-block\" class=\"ssrcss...   \n",
       "15824  <div data-component=\"text-block\" class=\"ssrcss...   \n",
       "\n",
       "                                                 content  \\\n",
       "0      The heroin substitute methadone can be used as...   \n",
       "1      The eldest son of North Korean leader Kim Jong...   \n",
       "2      Seven oil paintings created by notorious gangs...   \n",
       "3      A 20-tonne bridge is being hauled into place b...   \n",
       "4      The final words written by a guardsman killed ...   \n",
       "...                                                  ...   \n",
       "15820  An investigation into the death of a young mec...   \n",
       "15821  One of the Borders' best known textile compani...   \n",
       "15822  Young children with autism can be identified b...   \n",
       "15823  Thousands of homes planned to be built in Bris...   \n",
       "15824  David Cameron's flagship policy, the \"big soci...   \n",
       "\n",
       "                                                     url            author  \\\n",
       "0             https://www.bbc.co.uk/news/health-10869329  By Linda Pressly   \n",
       "1      https://www.bbc.co.uk/news/world-asia-pacific-...                     \n",
       "2      https://www.bbc.co.uk/news/uk-england-lincolns...                     \n",
       "3      https://www.bbc.co.uk/news/uk-scotland-tayside...                     \n",
       "4      https://www.bbc.co.uk/news/uk-england-manchest...                     \n",
       "...                                                  ...               ...   \n",
       "15820  https://www.bbc.co.uk/news/uk-scotland-north-e...                     \n",
       "15821  https://www.bbc.co.uk/news/uk-scotland-south-s...                     \n",
       "15822         https://www.bbc.co.uk/news/health-10686912                     \n",
       "15823  https://www.bbc.co.uk/news/uk-england-bristol-...                     \n",
       "15824             https://www.bbc.co.uk/news/uk-10693549                     \n",
       "\n",
       "      language                                   _id  \\\n",
       "0        en_GB  45cbcb62-840b-5a1d-9b59-d7f57f3ab7f6   \n",
       "1        en_GB  771b9c0d-88e1-589f-bf56-8ef80ce161a2   \n",
       "2        en_GB  768e3fc6-c406-5570-8328-2e6fb75abd1b   \n",
       "3        en_GB  a6e26396-70ec-501c-8ebc-1d600ddf6aab   \n",
       "4        en_GB  e8a150a5-b6e0-5315-9c04-fc639dee196f   \n",
       "...        ...                                   ...   \n",
       "15820    en_GB  ac717def-725f-5a4d-a19f-77ac6bb95771   \n",
       "15821    en_GB  0f761bbe-3b28-5d40-b40c-fe112260e8f1   \n",
       "15822    en_GB  4631fe89-97cd-5d1d-b69b-6f16896bb242   \n",
       "15823    en_GB  f04abfa4-36b1-5a1c-8ee3-8cbc8921e609   \n",
       "15824    en_GB  0490ad7e-96ce-5090-a137-e95aa2e14d70   \n",
       "\n",
       "                               region  \\\n",
       "0                              Health   \n",
       "1                        Asia-Pacific   \n",
       "2                        Lincolnshire   \n",
       "3        Tayside and Central Scotland   \n",
       "4                          Manchester   \n",
       "...                               ...   \n",
       "15820  NE Scotland, Orkney & Shetland   \n",
       "15821                  South Scotland   \n",
       "15822                          Health   \n",
       "15823                         Bristol   \n",
       "15824                              UK   \n",
       "\n",
       "                                       short_description  category  \\\n",
       "0      Heroin substitute methadone is used to wean ad...  BBC News   \n",
       "1      The eldest son of North Korean leader Kim Jong...  BBC News   \n",
       "2      A series of oil painting produced by gangster ...  BBC News   \n",
       "3      A 20-tonne bridge is having to be hauled into ...  BBC News   \n",
       "4      The final words written by a guardsman from Ma...  BBC News   \n",
       "...                                                  ...       ...   \n",
       "15820  An investigation into the death of a young mec...  BBC News   \n",
       "15821  Borders-based knitwear firm Pringle of Scotlan...  BBC News   \n",
       "15822  A new vocal analysis tool could help screen fo...  BBC News   \n",
       "15823  Thousands of homes planned for Bristol and Nor...  BBC News   \n",
       "15824  David Cameron's flagship policy, the \"big soci...  BBC News   \n",
       "\n",
       "               crawled_at  \n",
       "0     2021-05-02 17:19:39  \n",
       "1     2021-05-02 17:19:39  \n",
       "2     2021-05-02 17:19:39  \n",
       "3     2021-05-02 17:19:39  \n",
       "4     2021-05-02 17:19:39  \n",
       "...                   ...  \n",
       "15820 2021-05-02 18:08:38  \n",
       "15821 2021-05-02 18:08:38  \n",
       "15822 2021-05-02 18:08:38  \n",
       "15823 2021-05-02 18:08:39  \n",
       "15824 2021-05-02 18:08:39  \n",
       "\n",
       "[15825 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ir_datasets\n",
      "  Downloading ir_datasets-0.5.4-py3-none-any.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.5/311.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting warc3-wet>=0.2.3\n",
      "  Downloading warc3_wet-0.2.3-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: requests>=2.22.0 in /Users/yolandaferreirofranchi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets) (2.28.1)\n",
      "Collecting zlib-state>=0.1.3\n",
      "  Downloading zlib-state-0.1.5.tar.gz (9.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting unlzw3>=0.2.1\n",
      "  Downloading unlzw3-0.2.2-py3-none-any.whl (6.1 kB)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /Users/yolandaferreirofranchi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets) (1.21.5)\n",
      "Requirement already satisfied: tqdm>=4.38.0 in /Users/yolandaferreirofranchi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets) (4.64.1)\n",
      "Collecting trec-car-tools>=2.5.4\n",
      "  Downloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
      "Collecting ijson>=3.1.3\n",
      "  Downloading ijson-3.2.0.post0-cp39-cp39-macosx_10_9_x86_64.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: lxml>=4.5.2 in /Users/yolandaferreirofranchi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets) (4.9.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Users/yolandaferreirofranchi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets) (4.11.1)\n",
      "Collecting warc3-wet-clueweb09>=0.2.5\n",
      "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.3.1 in /Users/yolandaferreirofranchi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets) (6.0)\n",
      "Requirement already satisfied: lz4>=3.1.1 in /Users/yolandaferreirofranchi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets) (3.1.3)\n",
      "Collecting pyautocorpus>=0.1.1\n",
      "  Downloading pyautocorpus-0.1.9-cp39-cp39-macosx_10_15_x86_64.whl (24 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/yolandaferreirofranchi/opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4>=4.4.1->ir_datasets) (2.3.2.post1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yolandaferreirofranchi/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.22.0->ir_datasets) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/yolandaferreirofranchi/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.22.0->ir_datasets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yolandaferreirofranchi/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.22.0->ir_datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yolandaferreirofranchi/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.22.0->ir_datasets) (2022.12.7)\n",
      "Collecting cbor>=1.0.0\n",
      "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: warc3-wet-clueweb09, zlib-state, cbor\n",
      "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18920 sha256=c1e90e0d38d727455c1dbc02b44d04d024eb160c5956d3b86d69399d3ae90911\n",
      "  Stored in directory: /Users/yolandaferreirofranchi/Library/Caches/pip/wheels/bd/25/ee/7d267137cc06823c28646176e2d3ee59dcf578a7dbac8424ce\n",
      "  Building wheel for zlib-state (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for zlib-state: filename=zlib_state-0.1.5-cp39-cp39-macosx_10_9_x86_64.whl size=9307 sha256=604811e49de1f0a916d92f15e66a51324017cee98a406fbd6ed7ac73677c05fc\n",
      "  Stored in directory: /Users/yolandaferreirofranchi/Library/Caches/pip/wheels/58/8e/ce/3731b056e7c0e7d4708054ccb87875df3df717d6f00f83f123\n",
      "  Building wheel for cbor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cbor: filename=cbor-1.0.0-cp39-cp39-macosx_10_9_x86_64.whl size=19551 sha256=10d13768134d2328e30db5f69fa2f069923e9981257a4b45c95a6fe5d43e36b9\n",
      "  Stored in directory: /Users/yolandaferreirofranchi/Library/Caches/pip/wheels/7f/1d/5c/6aa871bab9ec585f2a93c0a056ef7156087d7f6efb9d7e2a98\n",
      "Successfully built warc3-wet-clueweb09 zlib-state cbor\n",
      "Installing collected packages: warc3-wet-clueweb09, warc3-wet, ijson, cbor, zlib-state, unlzw3, trec-car-tools, pyautocorpus, ir_datasets\n",
      "Successfully installed cbor-1.0.0 ijson-3.2.0.post0 ir_datasets-0.5.4 pyautocorpus-0.1.9 trec-car-tools-2.6 unlzw3-0.2.2 warc3-wet-0.2.3 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] The New York Times Annotated Corpus. It is available from the LDC via: <https://catalog.ldc.upenn.edu/LDC2008T19>.\n",
      "More details about the procedure can be found here: <https://ir-datasets.com/nyt.html#DataAccess>.\n",
      "To proceed, symlink the source file here: /Users/yolandaferreirofranchi/.ir_datasets/nyt/nyt.tgz\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "/Users/yolandaferreirofranchi/.ir_datasets/nyt/nyt.tgz",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g0/r571pkwj6973dlq1m_v76wp40000gn/T/ipykernel_15908/2933883931.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mir_datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mir_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nyt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocs_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# namedtuple<doc_id, headline, body, source_xml>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ir_datasets/util/__init__.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m                             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'OK'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ir_datasets/datasets/nyt.py\u001b[0m in \u001b[0;36mdocs_iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdocs_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocs_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_docs_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ir_datasets/datasets/nyt.py\u001b[0m in \u001b[0;36mdocs_store\u001b[0;34m(self, field)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdocs_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'doc_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         return PickleLz4FullStore(\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{self.docs_path()}.pklz4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0minit_iter_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_docs_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mdata_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocs_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ir_datasets/datasets/nyt.py\u001b[0m in \u001b[0;36mdocs_path\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdocs_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdocs_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ir_datasets/util/download.py\u001b[0m in \u001b[0;36mpath\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmirrors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmirrors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmirrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLocalDownload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ir_datasets/util/download.py\u001b[0m in \u001b[0;36mpath\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinialized_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                     \u001b[0;32mwith\u001b[0m \u001b[0mmirror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHashStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_md5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'md5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ir_datasets/util/download.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ir_datasets/util/download.py\u001b[0m in \u001b[0;36mpath\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: /Users/yolandaferreirofranchi/.ir_datasets/nyt/nyt.tgz"
     ]
    }
   ],
   "source": [
    "!pip install ir_datasets\n",
    "import ir_datasets\n",
    "dataset = ir_datasets.load(\"~/.ir_datasets/nyt/nyt.tgz.\")\n",
    "for doc in dataset.docs_iter():\n",
    "    print(doc) # namedtuple<doc_id, headline, body, source_xml>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '2021.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g0/r571pkwj6973dlq1m_v76wp40000gn/T/ipykernel_15908/2864272667.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2021.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# create a pandas DataFrame from the list of contents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2021.txt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "with open('2021.txt', 'r') as file:\n",
    "    contents = file.readlines()\n",
    "\n",
    "# create a pandas DataFrame from the list of contents\n",
    "df = pd.DataFrame(contents, columns=['text'])\n",
    "\n",
    "# display the DataFrame\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
