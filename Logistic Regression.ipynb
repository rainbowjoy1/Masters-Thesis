{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time \n",
    "import pickle\n",
    "import os\n",
    "#nltk.download('punkt')\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_processed_sent</th>\n",
       "      <th>string_rnn</th>\n",
       "      <th>male_count</th>\n",
       "      <th>female_count</th>\n",
       "      <th>Proper_noun_list</th>\n",
       "      <th>pn exists</th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[add, three, decade, building, extremely, prou...</td>\n",
       "      <td>add three decade building extremely proud grou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Balhousie, Care]</td>\n",
       "      <td>True</td>\n",
       "      <td>He added: \"After three decades of building Bal...</td>\n",
       "      <td>13</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hospitalise, number, facial, fracture, follow...</td>\n",
       "      <td>hospitalise number facial fracture follow seri...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>A man in his 20s has been hospitalised with a ...</td>\n",
       "      <td>24</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[victim, front, passenger, seat, vehicle, atta...</td>\n",
       "      <td>victim front passenger seat vehicle attack ano...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>The victim was in the front passenger seat of ...</td>\n",
       "      <td>24</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[involve, bitter, dispute, organisation, membe...</td>\n",
       "      <td>involve bitter dispute organisation member sta...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Baroness]</td>\n",
       "      <td>None</td>\n",
       "      <td>Baroness Scotland, Secretary General of the Co...</td>\n",
       "      <td>30</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[add, chair, regret, challenge, position, take...</td>\n",
       "      <td>add chair regret challenge position take secre...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"He adds: \"The chair regrets and challenges th...</td>\n",
       "      <td>30</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410780</th>\n",
       "      <td>[ground, hard, thaw, yet, come, experience, sh...</td>\n",
       "      <td>ground hard thaw yet come experience show u th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"The ground has been very hard, the thaw is ye...</td>\n",
       "      <td>1043999</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410781</th>\n",
       "      <td>[endeavour, get, ahead, game, best, find, situ...</td>\n",
       "      <td>endeavour get ahead game best find situation c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"What we are endeavouring to do here is get ah...</td>\n",
       "      <td>1043999</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410782</th>\n",
       "      <td>[die, hit, garage, forecourt]</td>\n",
       "      <td>die hit garage forecourt</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>A man has died after being hit by a 4x4 on a g...</td>\n",
       "      <td>1044006</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410783</th>\n",
       "      <td>[north, say, incident, garage, happen, area, t...</td>\n",
       "      <td>north say incident garage happen area take hos...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Wales, Chester]</td>\n",
       "      <td>True</td>\n",
       "      <td>North Wales Police said the incident at the Pr...</td>\n",
       "      <td>1044006</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410784</th>\n",
       "      <td>[next, kin, inform]</td>\n",
       "      <td>next kin inform</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>His next of kin have been informed.</td>\n",
       "      <td>1044006</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410785 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       pre_processed_sent  \\\n",
       "0       [add, three, decade, building, extremely, prou...   \n",
       "1       [hospitalise, number, facial, fracture, follow...   \n",
       "2       [victim, front, passenger, seat, vehicle, atta...   \n",
       "3       [involve, bitter, dispute, organisation, membe...   \n",
       "4       [add, chair, regret, challenge, position, take...   \n",
       "...                                                   ...   \n",
       "410780  [ground, hard, thaw, yet, come, experience, sh...   \n",
       "410781  [endeavour, get, ahead, game, best, find, situ...   \n",
       "410782                      [die, hit, garage, forecourt]   \n",
       "410783  [north, say, incident, garage, happen, area, t...   \n",
       "410784                                [next, kin, inform]   \n",
       "\n",
       "                                               string_rnn  male_count  \\\n",
       "0       add three decade building extremely proud grou...           1   \n",
       "1       hospitalise number facial fracture follow seri...           2   \n",
       "2       victim front passenger seat vehicle attack ano...           5   \n",
       "3       involve bitter dispute organisation member sta...           0   \n",
       "4       add chair regret challenge position take secre...           1   \n",
       "...                                                   ...         ...   \n",
       "410780  ground hard thaw yet come experience show u th...           1   \n",
       "410781  endeavour get ahead game best find situation c...           1   \n",
       "410782                           die hit garage forecourt           1   \n",
       "410783  north say incident garage happen area take hos...           2   \n",
       "410784                                    next kin inform           1   \n",
       "\n",
       "        female_count   Proper_noun_list pn exists  \\\n",
       "0                  0  [Balhousie, Care]      True   \n",
       "1                  0                 []      None   \n",
       "2                  0                 []      None   \n",
       "3                  1         [Baroness]      None   \n",
       "4                  0                 []      None   \n",
       "...              ...                ...       ...   \n",
       "410780             0                 []      None   \n",
       "410781             0                 []      None   \n",
       "410782             0                 []      None   \n",
       "410783             0   [Wales, Chester]      True   \n",
       "410784             0                 []      None   \n",
       "\n",
       "                                                sentences  article_id  year  \\\n",
       "0       He added: \"After three decades of building Bal...          13  2022   \n",
       "1       A man in his 20s has been hospitalised with a ...          24  2022   \n",
       "2       The victim was in the front passenger seat of ...          24  2022   \n",
       "3       Baroness Scotland, Secretary General of the Co...          30  2022   \n",
       "4       \"He adds: \"The chair regrets and challenges th...          30  2022   \n",
       "...                                                   ...         ...   ...   \n",
       "410780  \"The ground has been very hard, the thaw is ye...     1043999  2022   \n",
       "410781  \"What we are endeavouring to do here is get ah...     1043999  2022   \n",
       "410782  A man has died after being hit by a 4x4 on a g...     1044006  2022   \n",
       "410783  North Wales Police said the incident at the Pr...     1044006  2022   \n",
       "410784                His next of kin have been informed.     1044006  2022   \n",
       "\n",
       "       col_type  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  \n",
       "...         ...  \n",
       "410780        0  \n",
       "410781        0  \n",
       "410782        0  \n",
       "410783        0  \n",
       "410784        0  \n",
       "\n",
       "[410785 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = \"2022\"\n",
    "file_path = \"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/\"\n",
    "file_path_2 = \"_final_rnn.pickle\"\n",
    "\n",
    "df_22= pd.read_pickle(file_path + year + file_path_2)\n",
    "df_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_count(male_col, female_col):\n",
    "    if female_col > male_col and male_col == 0:\n",
    "        return 1\n",
    "    elif male_col> female_col and female_col ==0: \n",
    "        return 0\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    250053\n",
       "1.0    138572\n",
       "Name: col_type, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply function to only get rows with an absolute count \n",
    "df_22['col_type'] = df_22.apply(lambda row: absolute_count(row['male_count'], row['female_count']),axis=1)\n",
    "\n",
    "#remove nulls \n",
    "df_22 = df_22[df_22[\"col_type\"].notnull()]\n",
    "\n",
    "#DOC: number of male and female columns\n",
    "df_22[\"col_type\"].value_counts()  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define TFIDF Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf vectorizer\n",
    "def fake(token):\n",
    "    return token\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=fake,\n",
    "    preprocessor=fake,\n",
    "    token_pattern=None)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Classifier**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What the LR model does-* LR estimates the probability of an instance belonging to the positive class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_year(df, target_col, text_col):\n",
    "    #start timer \n",
    "    start_time = time.time()\n",
    "    \n",
    "    #split data \n",
    "    X = df[text_col].apply(lambda x: str(x))\n",
    "    y = df[target_col]\n",
    "\n",
    "    #train test split\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_transformed = tfidf.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # define the hyperparameters to search over\n",
    "    param_grid = {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'solver': ['lbfgs', 'newton-cg', 'sag' 'saga'], #removed liblinear as it is for small + medium datasets & NOT for sparse data\n",
    "        'class_weight': ['balanced', {0: 0.3, 1: 0.7}],\n",
    "        'random_state': [42]\n",
    "    }\n",
    "\n",
    "    #the classifier \n",
    "    clf = LogisticRegression()\n",
    "\n",
    "    #create a GridsearchCV object \n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_clf = LogisticRegression(**grid_search.best_params_)\n",
    "\n",
    "    #run the classifier \n",
    "    best_clf.fit(X_train, y_train)\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "\n",
    "    #performance \n",
    "    accuracy = best_clf.score(X_test, y_test) #evaluate on test set\n",
    "    class_report = classification_report(y_test, y_pred, zero_division = 0)\n",
    "    #results = {'accuracy': accuracy, 'classification_report': class_report}\n",
    "    #print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    #print(f\"Classification Report:\\n{class_report}\")\n",
    "\n",
    "    #coefficients\n",
    "    coefs = best_clf.coef_[0]\n",
    "    sorted_coef = sorted((zip(tfidf.get_feature_names_out(), coefs)), key = lambda x: x[1], reverse=True)\n",
    "    high_coef = sorted_coef[:1000]\n",
    "    low_coef = sorted_coef[-1000:]\n",
    "    \n",
    "    df_high_coef = pd.DataFrame(high_coef, columns=['feature', 'coef'])\n",
    "    df_low_coef = pd.DataFrame(low_coef, columns=['feature', 'coef'])\n",
    "\n",
    "    #save model \n",
    "    with open('results.pkl', 'wb') as f:\n",
    "        pickle.dump({'model': best_clf, 'tfidf': tfidf, 'accuracy': accuracy, 'report': class_report}, f)\n",
    "\n",
    "    #end timer \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nExecution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return df_high_coef, df_low_coef, best_clf, class_report #df_probs_top"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coefficient Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution time: 327.76 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(       feature      coef\n",
       " 0     pregnant  6.768437\n",
       " 1    pregnancy  5.119749\n",
       " 2        hijab  4.834458\n",
       " 3    boyfriend  4.825778\n",
       " 4    maternity  4.799544\n",
       " ..         ...       ...\n",
       " 995   royalist  1.034272\n",
       " 996     detest  1.034228\n",
       " 997    residue  1.033310\n",
       " 998      hyper  1.033004\n",
       " 999     jemima  1.032871\n",
       " \n",
       " [1000 rows x 2 columns],\n",
       "       feature      coef\n",
       " 0        boar -1.033652\n",
       " 1     graphic -1.033753\n",
       " 2         toÃ¢ -1.034010\n",
       " 3    pipeline -1.034017\n",
       " 4      connor -1.034986\n",
       " ..        ...       ...\n",
       " 995       gay -2.647956\n",
       " 996    arrest -2.734533\n",
       " 997   cocaine -3.258467\n",
       " 998       iii -3.583065\n",
       " 999  prostate -3.645832\n",
       " \n",
       " [1000 rows x 2 columns],\n",
       " LogisticRegression(C=1, class_weight='balanced', random_state=42,\n",
       "                    solver='newton-cg'),\n",
       " '              precision    recall  f1-score   support\\n\\n         0.0       0.76      0.65      0.70     49956\\n         1.0       0.50      0.63      0.55     27769\\n\\n    accuracy                           0.64     77725\\n   macro avg       0.63      0.64      0.63     77725\\nweighted avg       0.66      0.64      0.65     77725\\n')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_probs_22 = logistic_regression_year(df_22, 'col_type', 'pre_processed_sent')\n",
    "df_probs_22"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpreting Performance*\n",
    "\n",
    "The LR model is WAY better in terms of precision, recall, and f1-score at predicting the negative class - i.e. male. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.64\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.65      0.70     49956\n",
      "         1.0       0.50      0.63      0.55     27769\n",
      "\n",
      "    accuracy                           0.64     77725\n",
      "   macro avg       0.63      0.64      0.63     77725\n",
      "weighted avg       0.66      0.64      0.65     77725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#open model performance metrics \n",
    "with open('results_22.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "accuracy = results['accuracy']\n",
    "report = results['report']\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Classification report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create DF of highest coef\n",
    "highest_coef_22 = pd.DataFrame(df_probs_22[0])\n",
    "highest_coef_22[\"coef_type\"] = \"highest\"\n",
    "highest_coef_22[\"year\"] = year\n",
    "\n",
    "#create DF of lowest lowest coef manipulation \n",
    "lowest_coef_22 = pd.DataFrame(df_probs_22[1]) \n",
    "lowest_coef_22 = lowest_coef_22.sort_values(by = [\"coef\"], ascending = True).reset_index(drop = True) #absolute lowest value \n",
    "lowest_coef_22[\"coef_type\"] = \"lowest\" #coef type\n",
    "lowest_coef_22[\"year\"] = year #year \n",
    "highest_coef_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save DF as pickle file per year \n",
    "lowest_coef_22.to_pickle('RESULTS22_coef_low.pickle')\n",
    "highest_coef_22.to_pickle('RESULTS22_coef_high.pickle')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of coefficient results**\n",
    "\"winner\" is one of the independent variables in the model and its coefficient value is 1.2865737872946597. This means that a one unit increase in the value of the \"winner\" variable will increase the log-odds of the positive class (e.g. \"female\" if the logistic regression model is binary and predicting gender) by the corresponding coefficient value, while holding all other variables constant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of the predicted probabilities in LR:** \n",
    "The predicted probabilities of the logistic regression model tell us the probability that the input data belongs to the positive class - in this case the female class as we attributed it a value = 1 in binary log reg. Hence, for each word, we get a list of a word/feature and the probability that it is female. \n",
    "\n",
    "These predicted probabilities can be interpreted as the confidence level of the model in its prediction. For example, a predicted probability of 0.8 for a positive class means that the model is 80% confident that the sample belongs to the positive class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_files_low(directory):\n",
    "    objects = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"low.pickle\"):\n",
    "            with open(os.path.join(directory, filename), 'rb') as file:\n",
    "                obj = pickle.load(file)\n",
    "                objects.append(obj)\n",
    "    return objects\n",
    "\n",
    "def load_pickle_files_high(directory):\n",
    "    objects = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"high.pickle\"):\n",
    "            with open(os.path.join(directory, filename), 'rb') as file:\n",
    "                obj = pickle.load(file)\n",
    "                objects.append(obj)\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack dfs together for low and high coefs \n",
    "df_low = load_pickle_files_low(r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis\")\n",
    "df_high = load_pickle_files_high(r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis\")\n",
    "df_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
