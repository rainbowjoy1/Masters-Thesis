{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time \n",
    "import pickle\n",
    "import os\n",
    "#nltk.download('punkt')\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_processed_sent</th>\n",
       "      <th>string_rnn</th>\n",
       "      <th>male_count</th>\n",
       "      <th>female_count</th>\n",
       "      <th>Proper_noun_list</th>\n",
       "      <th>pn exists</th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[offer, help, university, budget, help, find, ...</td>\n",
       "      <td>offer help university budget help find per stu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>He offered to help both universities with thei...</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[die, knock, car, name, police]</td>\n",
       "      <td>die knock car name police</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>A man who died after being knocked down by a c...</td>\n",
       "      <td>43</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[three, age, arrest, suspicion, murder, releas...</td>\n",
       "      <td>three age arrest suspicion murder release bail</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Harlow]</td>\n",
       "      <td>None</td>\n",
       "      <td>Three men from Harlow, aged 35, 34 and 25, hav...</td>\n",
       "      <td>43</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[touch, plane, one, land, airbase, refuel, stop]</td>\n",
       "      <td>touch plane one land airbase refuel stop</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Donald, Trump]</td>\n",
       "      <td>True</td>\n",
       "      <td>Donald Trump touched down in the UK when his p...</td>\n",
       "      <td>51</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[post, say, refuel, stop]</td>\n",
       "      <td>post say refuel stop</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>In her post, Ms Sanders said: \"Got off AF1 for...</td>\n",
       "      <td>51</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817190</th>\n",
       "      <td>[sat, bed, north, indie, rock, frontman, refle...</td>\n",
       "      <td>sat bed north indie rock frontman reflect busi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>Sat on his bed in north London, the indie-rock...</td>\n",
       "      <td>2175805</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817191</th>\n",
       "      <td>[idea, go, hard, time, two, year, sigh]</td>\n",
       "      <td>idea go hard time two year sigh</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"But I had no idea I was going to have such a ...</td>\n",
       "      <td>2175805</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817192</th>\n",
       "      <td>[think, idea, building, show, around, audience...</td>\n",
       "      <td>think idea building show around audience phone...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"She thinks the idea of building a show around...</td>\n",
       "      <td>2175906</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817193</th>\n",
       "      <td>[friend, like, always, film, everything, gig, ...</td>\n",
       "      <td>friend like always film everything gig say imp...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Her friend Liam, who likes to \"always film ev...</td>\n",
       "      <td>2175906</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817194</th>\n",
       "      <td>[original, tweet, say, best, gig, keep, phone,...</td>\n",
       "      <td>original tweet say best gig keep phone bag twi...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[View]</td>\n",
       "      <td>None</td>\n",
       "      <td>View original tweet on TwitterChloe says some ...</td>\n",
       "      <td>2175906</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>817195 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       pre_processed_sent  \\\n",
       "0       [offer, help, university, budget, help, find, ...   \n",
       "1                         [die, knock, car, name, police]   \n",
       "2       [three, age, arrest, suspicion, murder, releas...   \n",
       "3        [touch, plane, one, land, airbase, refuel, stop]   \n",
       "4                               [post, say, refuel, stop]   \n",
       "...                                                   ...   \n",
       "817190  [sat, bed, north, indie, rock, frontman, refle...   \n",
       "817191            [idea, go, hard, time, two, year, sigh]   \n",
       "817192  [think, idea, building, show, around, audience...   \n",
       "817193  [friend, like, always, film, everything, gig, ...   \n",
       "817194  [original, tweet, say, best, gig, keep, phone,...   \n",
       "\n",
       "                                               string_rnn  male_count  \\\n",
       "0       offer help university budget help find per stu...           1   \n",
       "1                               die knock car name police           1   \n",
       "2          three age arrest suspicion murder release bail           1   \n",
       "3                touch plane one land airbase refuel stop           1   \n",
       "4                                    post say refuel stop           0   \n",
       "...                                                   ...         ...   \n",
       "817190  sat bed north indie rock frontman reflect busi...           1   \n",
       "817191                    idea go hard time two year sigh           1   \n",
       "817192  think idea building show around audience phone...           0   \n",
       "817193  friend like always film everything gig say imp...           0   \n",
       "817194  original tweet say best gig keep phone bag twi...           0   \n",
       "\n",
       "        female_count Proper_noun_list pn exists  \\\n",
       "0                  0               []      None   \n",
       "1                  0               []      None   \n",
       "2                  0         [Harlow]      None   \n",
       "3                  0  [Donald, Trump]      True   \n",
       "4                  1               []      None   \n",
       "...              ...              ...       ...   \n",
       "817190             0               []      None   \n",
       "817191             0               []      None   \n",
       "817192             1               []      None   \n",
       "817193             1               []      None   \n",
       "817194             4           [View]      None   \n",
       "\n",
       "                                                sentences  article_id  year  \\\n",
       "0       He offered to help both universities with thei...           8  2019   \n",
       "1       A man who died after being knocked down by a c...          43  2019   \n",
       "2       Three men from Harlow, aged 35, 34 and 25, hav...          43  2019   \n",
       "3       Donald Trump touched down in the UK when his p...          51  2019   \n",
       "4       In her post, Ms Sanders said: \"Got off AF1 for...          51  2019   \n",
       "...                                                   ...         ...   ...   \n",
       "817190  Sat on his bed in north London, the indie-rock...     2175805  2019   \n",
       "817191  \"But I had no idea I was going to have such a ...     2175805  2019   \n",
       "817192  \"She thinks the idea of building a show around...     2175906  2019   \n",
       "817193  \"Her friend Liam, who likes to \"always film ev...     2175906  2019   \n",
       "817194  View original tweet on TwitterChloe says some ...     2175906  2019   \n",
       "\n",
       "       col_type  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             1  \n",
       "...         ...  \n",
       "817190        0  \n",
       "817191        0  \n",
       "817192        1  \n",
       "817193        1  \n",
       "817194        1  \n",
       "\n",
       "[817195 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = \"2019\"\n",
    "file_path = \"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/\"\n",
    "file_path_2 = \"_final_rnn.pickle\"\n",
    "\n",
    "df_19= pd.read_pickle(file_path + year + file_path_2)\n",
    "df_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_count(male_col, female_col):\n",
    "    if female_col > male_col and male_col == 0:\n",
    "        return 1\n",
    "    elif male_col> female_col and female_col ==0: \n",
    "        return 0\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    522364\n",
       "1.0    254067\n",
       "Name: col_type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply function to only get rows with an absolute count \n",
    "df_19['col_type'] = df_19.apply(lambda row: absolute_count(row['male_count'], row['female_count']),axis=1)\n",
    "\n",
    "#remove nulls \n",
    "df_19 = df_19[df_19[\"col_type\"].notnull()]\n",
    "\n",
    "#DOC: number of male and female columns\n",
    "df_19[\"col_type\"].value_counts()  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define TFIDF Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf vectorizer\n",
    "def fake(token):\n",
    "    return token\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=fake,\n",
    "    preprocessor=fake,\n",
    "    token_pattern=None)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Classifier**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What the LR model does-* LR estimates the probability of an instance belonging to the positive class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_year(df, target_col, text_col):\n",
    "    #start timer \n",
    "    start_time = time.time()\n",
    "    \n",
    "    #split data \n",
    "    X = df[text_col].apply(lambda x: str(x))\n",
    "    y = df[target_col]\n",
    "\n",
    "    #train test split\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_transformed = tfidf.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # define the hyperparameters to search over\n",
    "    param_grid = {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'solver': ['lbfgs', 'newton-cg', 'sag' 'saga'], #removed liblinear as it is for small + medium datasets & NOT for sparse data\n",
    "        'class_weight': ['balanced', {0: 0.3, 1: 0.7}],\n",
    "        'random_state': [42]\n",
    "    }\n",
    "\n",
    "    #the classifier \n",
    "    clf = LogisticRegression()\n",
    "\n",
    "    #create a GridsearchCV object \n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_clf = LogisticRegression(**grid_search.best_params_)\n",
    "\n",
    "    #run the classifier \n",
    "    best_clf.fit(X_train, y_train)\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "\n",
    "    #performance \n",
    "    accuracy = best_clf.score(X_test, y_test) #evaluate on test set\n",
    "    class_report = classification_report(y_test, y_pred, zero_division = 0)\n",
    "    #results = {'accuracy': accuracy, 'classification_report': class_report}\n",
    "    #print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    #print(f\"Classification Report:\\n{class_report}\")\n",
    "\n",
    "    #coefficients\n",
    "    coefs = best_clf.coef_[0]\n",
    "    sorted_coef = sorted((zip(tfidf.get_feature_names_out(), coefs)), key = lambda x: x[1], reverse=True)\n",
    "    high_coef = sorted_coef[:1000]\n",
    "    low_coef = sorted_coef[-1000:]\n",
    "    \n",
    "    df_high_coef = pd.DataFrame(high_coef, columns=['feature', 'coef'])\n",
    "    df_low_coef = pd.DataFrame(low_coef, columns=['feature', 'coef'])\n",
    "\n",
    "    #save model \n",
    "    with open('results.pkl', 'wb') as f:\n",
    "        pickle.dump({'model': best_clf, 'tfidf': tfidf, 'accuracy': accuracy, 'report': class_report}, f)\n",
    "\n",
    "    #end timer \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nExecution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return df_high_coef, df_low_coef, best_clf, class_report #df_probs_top"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coefficient Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution time: 882.50 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        feature      coef\n",
       " 0    motherhood  8.534818\n",
       " 1     headscarf  8.127457\n",
       " 2      pregnant  8.106356\n",
       " 3     pregnancy  7.950200\n",
       " 4     menopause  7.913446\n",
       " ..          ...       ...\n",
       " 995       girly  4.061953\n",
       " 996         eds  4.061669\n",
       " 997    mbandaka  4.061367\n",
       " 998    maitland  4.061349\n",
       " 999        macy  4.061340\n",
       " \n",
       " [1000 rows x 2 columns],\n",
       "              feature       coef\n",
       " 0        unforgiving  -3.911172\n",
       " 1    cardiopulmonary  -3.912530\n",
       " 2            shimbun  -3.912889\n",
       " 3      dispassionate  -3.914104\n",
       " 4           abundant  -3.914345\n",
       " ..               ...        ...\n",
       " 995             nate  -7.247050\n",
       " 996           willie  -7.446785\n",
       " 997             pell  -7.645863\n",
       " 998       takeoverif  -8.232578\n",
       " 999         prostate -10.090317\n",
       " \n",
       " [1000 rows x 2 columns],\n",
       " LogisticRegression(C=10, class_weight='balanced', random_state=42,\n",
       "                    solver='newton-cg'),\n",
       " '              precision    recall  f1-score   support\\n\\n         0.0       0.81      0.69      0.75    104377\\n         1.0       0.51      0.68      0.59     50910\\n\\n    accuracy                           0.68    155287\\n   macro avg       0.66      0.68      0.67    155287\\nweighted avg       0.72      0.68      0.69    155287\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_probs_19 = logistic_regression_year(df_19, 'col_type', 'pre_processed_sent')\n",
    "df_probs_19"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpreting Performance*\n",
    "\n",
    "The LR model is WAY better in terms of precision, recall, and f1-score at predicting the negative class - i.e. male. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.64\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.65      0.70     49956\n",
      "         1.0       0.50      0.63      0.55     27769\n",
      "\n",
      "    accuracy                           0.64     77725\n",
      "   macro avg       0.63      0.64      0.63     77725\n",
      "weighted avg       0.66      0.64      0.65     77725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#open model performance metrics \n",
    "with open('results_22.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "accuracy = results['accuracy']\n",
    "report = results['report']\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Classification report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create DF of highest coef\n",
    "highest_coef_22 = pd.DataFrame(df_probs_22[0])\n",
    "highest_coef_22[\"coef_type\"] = \"highest\"\n",
    "highest_coef_22[\"year\"] = year\n",
    "\n",
    "#create DF of lowest lowest coef manipulation \n",
    "lowest_coef_22 = pd.DataFrame(df_probs_22[1]) \n",
    "lowest_coef_22 = lowest_coef_22.sort_values(by = [\"coef\"], ascending = True).reset_index(drop = True) #absolute lowest value \n",
    "lowest_coef_22[\"coef_type\"] = \"lowest\" #coef type\n",
    "lowest_coef_22[\"year\"] = year #year \n",
    "highest_coef_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save DF as pickle file per year \n",
    "lowest_coef_22.to_pickle('RESULTS22_coef_low.pickle')\n",
    "highest_coef_22.to_pickle('RESULTS22_coef_high.pickle')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of coefficient results**\n",
    "\"winner\" is one of the independent variables in the model and its coefficient value is 1.2865737872946597. This means that a one unit increase in the value of the \"winner\" variable will increase the log-odds of the positive class (e.g. \"female\" if the logistic regression model is binary and predicting gender) by the corresponding coefficient value, while holding all other variables constant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of the predicted probabilities in LR:** \n",
    "The predicted probabilities of the logistic regression model tell us the probability that the input data belongs to the positive class - in this case the female class as we attributed it a value = 1 in binary log reg. Hence, for each word, we get a list of a word/feature and the probability that it is female. \n",
    "\n",
    "These predicted probabilities can be interpreted as the confidence level of the model in its prediction. For example, a predicted probability of 0.8 for a positive class means that the model is 80% confident that the sample belongs to the positive class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_files_low(directory):\n",
    "    objects = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"low.pickle\"):\n",
    "            with open(os.path.join(directory, filename), 'rb') as file:\n",
    "                obj = pickle.load(file)\n",
    "                objects.append(obj)\n",
    "    return objects\n",
    "\n",
    "def load_pickle_files_high(directory):\n",
    "    objects = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"high.pickle\"):\n",
    "            with open(os.path.join(directory, filename), 'rb') as file:\n",
    "                obj = pickle.load(file)\n",
    "                objects.append(obj)\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack dfs together for low and high coefs \n",
    "df_low = load_pickle_files_low(r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis\")\n",
    "df_high = load_pickle_files_high(r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis\")\n",
    "df_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
