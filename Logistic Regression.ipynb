{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time \n",
    "import pickle\n",
    "import os\n",
    "#nltk.download('punkt')\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_processed_sent</th>\n",
       "      <th>male_count</th>\n",
       "      <th>female_count</th>\n",
       "      <th>Proper_noun_list</th>\n",
       "      <th>pn exists</th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[add, three, decade, building, extremely, prou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Balhousie, Care]</td>\n",
       "      <td>True</td>\n",
       "      <td>He added: \"After three decades of building Bal...</td>\n",
       "      <td>13</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[hospitalise, number, facial, fracture, follow...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>A man in his 20s has been hospitalised with a ...</td>\n",
       "      <td>24</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[victim, front, passenger, seat, vehicle, atta...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>The victim was in the front passenger seat of ...</td>\n",
       "      <td>24</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[involve, bitter, dispute, organisation, membe...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Baroness]</td>\n",
       "      <td>None</td>\n",
       "      <td>Baroness Scotland, Secretary General of the Co...</td>\n",
       "      <td>30</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[add, chair, regret, challenge, position, take...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"He adds: \"The chair regrets and challenges th...</td>\n",
       "      <td>30</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412503</th>\n",
       "      <td>[ground, hard, thaw, yet, come, experience, sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"The ground has been very hard, the thaw is ye...</td>\n",
       "      <td>1043999</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412507</th>\n",
       "      <td>[endeavour, get, ahead, game, best, find, situ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"What we are endeavouring to do here is get ah...</td>\n",
       "      <td>1043999</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412512</th>\n",
       "      <td>[die, hit, garage, forecourt]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>A man has died after being hit by a 4x4 on a g...</td>\n",
       "      <td>1044006</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412513</th>\n",
       "      <td>[north, say, incident, garage, happen, area, t...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Wales, Chester]</td>\n",
       "      <td>True</td>\n",
       "      <td>North Wales Police said the incident at the Pr...</td>\n",
       "      <td>1044006</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412514</th>\n",
       "      <td>[next, kin, inform]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>His next of kin have been informed.</td>\n",
       "      <td>1044006</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410785 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        pre_processed_sent  male_count  \\\n",
       "6        [add, three, decade, building, extremely, prou...           1   \n",
       "10       [hospitalise, number, facial, fracture, follow...           2   \n",
       "12       [victim, front, passenger, seat, vehicle, atta...           5   \n",
       "14       [involve, bitter, dispute, organisation, membe...           0   \n",
       "19       [add, chair, regret, challenge, position, take...           1   \n",
       "...                                                    ...         ...   \n",
       "1412503  [ground, hard, thaw, yet, come, experience, sh...           1   \n",
       "1412507  [endeavour, get, ahead, game, best, find, situ...           1   \n",
       "1412512                      [die, hit, garage, forecourt]           1   \n",
       "1412513  [north, say, incident, garage, happen, area, t...           2   \n",
       "1412514                                [next, kin, inform]           1   \n",
       "\n",
       "         female_count   Proper_noun_list pn exists  \\\n",
       "6                   0  [Balhousie, Care]      True   \n",
       "10                  0                 []      None   \n",
       "12                  0                 []      None   \n",
       "14                  1         [Baroness]      None   \n",
       "19                  0                 []      None   \n",
       "...               ...                ...       ...   \n",
       "1412503             0                 []      None   \n",
       "1412507             0                 []      None   \n",
       "1412512             0                 []      None   \n",
       "1412513             0   [Wales, Chester]      True   \n",
       "1412514             0                 []      None   \n",
       "\n",
       "                                                 sentences  article_id  year  \\\n",
       "6        He added: \"After three decades of building Bal...          13  2022   \n",
       "10       A man in his 20s has been hospitalised with a ...          24  2022   \n",
       "12       The victim was in the front passenger seat of ...          24  2022   \n",
       "14       Baroness Scotland, Secretary General of the Co...          30  2022   \n",
       "19       \"He adds: \"The chair regrets and challenges th...          30  2022   \n",
       "...                                                    ...         ...   ...   \n",
       "1412503  \"The ground has been very hard, the thaw is ye...     1043999  2022   \n",
       "1412507  \"What we are endeavouring to do here is get ah...     1043999  2022   \n",
       "1412512  A man has died after being hit by a 4x4 on a g...     1044006  2022   \n",
       "1412513  North Wales Police said the incident at the Pr...     1044006  2022   \n",
       "1412514                His next of kin have been informed.     1044006  2022   \n",
       "\n",
       "        col_type  \n",
       "6              0  \n",
       "10             0  \n",
       "12             0  \n",
       "14             1  \n",
       "19             0  \n",
       "...          ...  \n",
       "1412503        0  \n",
       "1412507        0  \n",
       "1412512        0  \n",
       "1412513        0  \n",
       "1412514        0  \n",
       "\n",
       "[410785 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pre-processed data from pickle \n",
    "#df_10= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2010_text_wo_names.pickle\")\n",
    "#df_09= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2009_text_wo_names.pickle\")\n",
    "#df_11= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2011_text_wo_names.pickle\")\n",
    "#df_12= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2012_text_wo_names.pickle\")\n",
    "#df_13= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2013_text_wo_names.pickle\")\n",
    "#df_14= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2014_text_wo_names.pickle\")\n",
    "#df_15= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2015_text_wo_names.pickle\")\n",
    "#df_16= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2016_text_wo_names.pickle\")\n",
    "#df_17= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2017_text_wo_names.pickle\")\n",
    "#df_18= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2018_text_wo_names.pickle\")\n",
    "#df_19 = pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2019_text_wo_names.pickle\")\n",
    "#df_20 = pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2020_text_wo_names.pickle\")\n",
    "#df_21 = pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2021_text_wo_names.pickle\")\n",
    "df_22 = pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2022_text_wo_names_(1).pickle\")\n",
    "df_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_count(male_col, female_col):\n",
    "    if female_col > male_col and male_col == 0:\n",
    "        return 1\n",
    "    elif male_col> female_col and female_col ==0: \n",
    "        return 0\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    250053\n",
       "1.0    138572\n",
       "Name: col_type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply function to only get rows with an absolute count \n",
    "df_22['col_type'] = df_22.apply(lambda row: absolute_count(row['male_count'], row['female_count']),axis=1)\n",
    "\n",
    "#remove nulls \n",
    "df_22 = df_22[df_22[\"col_type\"].notnull()]\n",
    "\n",
    "#DOC: number of male and female columns\n",
    "df_22[\"col_type\"].value_counts()  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define TFIDF Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf vectorizer\n",
    "def fake(token):\n",
    "    return token\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=fake,\n",
    "    preprocessor=fake,\n",
    "    token_pattern=None)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Classifier**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What the LR model does-* LR estimates the probability of an instance belonging to the positive class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec to dos\n",
    "#import gensim\n",
    "#from gensim.models import Word2Vec\n",
    "#file_w2vec= (r\"/Users/yolandaferreirofranchi/Desktop/GoogleNews-vectors-negative300.bin\") #yolanda's path \n",
    "#model_w2v = gensim.models.KeyedVectors.load_word2vec_format(file_w2vec, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_year(df, target_col, text_col):\n",
    "    #start timer \n",
    "    start_time = time.time()\n",
    "    \n",
    "    #split data \n",
    "    X = df[text_col].apply(lambda x: str(x))\n",
    "    y = df[target_col]\n",
    "\n",
    "    #train test split\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_transformed = tfidf.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # define the hyperparameters to search over\n",
    "    param_grid = {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'solver': ['lbfgs', 'newton-cg', 'sag' 'saga'], #removed liblinear as it is for small + medium datasets & NOT for sparse data\n",
    "        'class_weight': ['balanced', {0: 0.3, 1: 0.7}],\n",
    "        'random_state': [42]\n",
    "    }\n",
    "\n",
    "    #the classifier \n",
    "    clf = LogisticRegression()\n",
    "\n",
    "    #create a GridsearchCV object \n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_clf = LogisticRegression(**grid_search.best_params_)\n",
    "\n",
    "    #run the classifier \n",
    "    best_clf.fit(X_train, y_train)\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "\n",
    "    #performance \n",
    "    accuracy = best_clf.score(X_test, y_test) #evaluate on test set\n",
    "    class_report = classification_report(y_test, y_pred, zero_division = 0)\n",
    "    #results = {'accuracy': accuracy, 'classification_report': class_report}\n",
    "    #print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    #print(f\"Classification Report:\\n{class_report}\")\n",
    "\n",
    "    #coefficients\n",
    "    coefs = best_clf.coef_[0]\n",
    "    sorted_coef = sorted((zip(tfidf.get_feature_names_out(), coefs)), key = lambda x: x[1], reverse=True)\n",
    "    high_coef = sorted_coef[:200]\n",
    "    low_coef = sorted_coef[-200:]\n",
    "    \n",
    "    df_high_coef = pd.DataFrame(high_coef, columns=['feature', 'coef'])\n",
    "    df_low_coef = pd.DataFrame(low_coef, columns=['feature', 'coef'])\n",
    "\n",
    "\n",
    "    #write word probability list\n",
    "    #feature_indices = {feature: idx for idx, feature in enumerate(tfidf.get_feature_names_out())}\n",
    "    #probas = best_clf.predict_proba(X_transformed)  # predict probabilities of positive class\n",
    "    #positive_probas = probas[:, 1]\n",
    "    #probabilities = [None] * len(feature_indices)\n",
    "    #for feature, index in feature_indices.items():\n",
    "        #probabilities[index] = f\"{feature}: {(X_transformed[:, index].toarray() * positive_probas).mean()}\"\n",
    "\n",
    "    #save model \n",
    "    with open('results.pkl', 'wb') as f:\n",
    "        pickle.dump({'accuracy': accuracy, 'report': class_report}, f)\n",
    "\n",
    "    #end timer \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nExecution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return df_high_coef, df_low_coef, best_clf, class_report #df_probs_top"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coefficient Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution time: 359.07 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(           feature      coef\n",
       " 0         pregnant  6.744265\n",
       " 1        pregnancy  5.094695\n",
       " 2            hijab  4.824436\n",
       " 3        boyfriend  4.818898\n",
       " 4        maternity  4.793203\n",
       " ..             ...       ...\n",
       " 195     menstruate  1.772014\n",
       " 196       greville  1.767179\n",
       " 197  congresswoman  1.762240\n",
       " 198          adele  1.761328\n",
       " 199           lipa  1.755909\n",
       " \n",
       " [200 rows x 2 columns],\n",
       "          feature      coef\n",
       " 0           dems -1.616377\n",
       " 1      monastery -1.617422\n",
       " 2          shirt -1.617750\n",
       " 3        feather -1.618123\n",
       " 4         thomas -1.618988\n",
       " ..           ...       ...\n",
       " 195     chairman -3.416181\n",
       " 196          iii -3.600857\n",
       " 197     prostate -3.642648\n",
       " 198  businessman -3.645008\n",
       " 199           tÃ¯ -5.968579\n",
       " \n",
       " [200 rows x 2 columns],\n",
       " LogisticRegression(C=1, class_weight='balanced', random_state=42,\n",
       "                    solver='newton-cg'),\n",
       " '              precision    recall  f1-score   support\\n\\n         0.0       0.76      0.65      0.70     49956\\n         1.0       0.50      0.63      0.56     27769\\n\\n    accuracy                           0.64     77725\\n   macro avg       0.63      0.64      0.63     77725\\nweighted avg       0.67      0.64      0.65     77725\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_probs_22 = logistic_regression_year(df_22, 'col_type', 'pre_processed_sent')\n",
    "df_probs_22"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpreting Performance*\n",
    "\n",
    "The LR model is WAY better in terms of precision, recall, and f1-score at predicting the negative class - i.e. male. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.64\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.65      0.70     49956\n",
      "         1.0       0.50      0.63      0.56     27769\n",
      "\n",
      "    accuracy                           0.64     77725\n",
      "   macro avg       0.63      0.64      0.63     77725\n",
      "weighted avg       0.67      0.64      0.65     77725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#open model performance metrics \n",
    "with open('results_22.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "accuracy = results['accuracy']\n",
    "report = results['report']\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Classification report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>coef_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pregnant</td>\n",
       "      <td>6.744265</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pregnancy</td>\n",
       "      <td>5.094695</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hijab</td>\n",
       "      <td>4.824436</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boyfriend</td>\n",
       "      <td>4.818898</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maternity</td>\n",
       "      <td>4.793203</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reign</td>\n",
       "      <td>4.662568</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abortion</td>\n",
       "      <td>4.530159</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>headscarf</td>\n",
       "      <td>4.475117</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female</td>\n",
       "      <td>4.244700</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>midwife</td>\n",
       "      <td>4.191776</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>truss</td>\n",
       "      <td>4.091148</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>menopause</td>\n",
       "      <td>4.009705</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>olivia</td>\n",
       "      <td>3.861634</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rap</td>\n",
       "      <td>3.708729</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cressida</td>\n",
       "      <td>3.696846</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mcgarry</td>\n",
       "      <td>3.669446</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>baby</td>\n",
       "      <td>3.558119</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>handbag</td>\n",
       "      <td>3.455609</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>breast</td>\n",
       "      <td>3.439610</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gender</td>\n",
       "      <td>3.317828</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>emma</td>\n",
       "      <td>3.278226</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>beauty</td>\n",
       "      <td>3.163054</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>trans</td>\n",
       "      <td>3.071766</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>kate</td>\n",
       "      <td>3.060326</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>breastfeed</td>\n",
       "      <td>3.046318</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>birth</td>\n",
       "      <td>3.023303</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>zara</td>\n",
       "      <td>3.015268</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sturgeon</td>\n",
       "      <td>2.977052</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>katie</td>\n",
       "      <td>2.926236</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lily</td>\n",
       "      <td>2.916616</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>abuser</td>\n",
       "      <td>2.899014</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sophie</td>\n",
       "      <td>2.862459</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>morality</td>\n",
       "      <td>2.819816</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>salon</td>\n",
       "      <td>2.810607</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>molly</td>\n",
       "      <td>2.790591</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>harrier</td>\n",
       "      <td>2.766224</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>majesty</td>\n",
       "      <td>2.724341</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>emily</td>\n",
       "      <td>2.696031</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>chloe</td>\n",
       "      <td>2.671191</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>feminist</td>\n",
       "      <td>2.664294</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>lucy</td>\n",
       "      <td>2.649513</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>claire</td>\n",
       "      <td>2.635951</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>women</td>\n",
       "      <td>2.635685</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>taliban</td>\n",
       "      <td>2.633955</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>corgi</td>\n",
       "      <td>2.620119</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>dread</td>\n",
       "      <td>2.607918</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>nurse</td>\n",
       "      <td>2.583530</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>sew</td>\n",
       "      <td>2.563833</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>misogyny</td>\n",
       "      <td>2.533456</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>eilish</td>\n",
       "      <td>2.512256</td>\n",
       "      <td>highest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature      coef coef_type\n",
       "0     pregnant  6.744265   highest\n",
       "1    pregnancy  5.094695   highest\n",
       "2        hijab  4.824436   highest\n",
       "3    boyfriend  4.818898   highest\n",
       "4    maternity  4.793203   highest\n",
       "5        reign  4.662568   highest\n",
       "6     abortion  4.530159   highest\n",
       "7    headscarf  4.475117   highest\n",
       "8       female  4.244700   highest\n",
       "9      midwife  4.191776   highest\n",
       "10       truss  4.091148   highest\n",
       "11   menopause  4.009705   highest\n",
       "12      olivia  3.861634   highest\n",
       "13         rap  3.708729   highest\n",
       "14    cressida  3.696846   highest\n",
       "15     mcgarry  3.669446   highest\n",
       "16        baby  3.558119   highest\n",
       "17     handbag  3.455609   highest\n",
       "18      breast  3.439610   highest\n",
       "19      gender  3.317828   highest\n",
       "20        emma  3.278226   highest\n",
       "21      beauty  3.163054   highest\n",
       "22       trans  3.071766   highest\n",
       "23        kate  3.060326   highest\n",
       "24  breastfeed  3.046318   highest\n",
       "25       birth  3.023303   highest\n",
       "26        zara  3.015268   highest\n",
       "27    sturgeon  2.977052   highest\n",
       "28       katie  2.926236   highest\n",
       "29        lily  2.916616   highest\n",
       "30      abuser  2.899014   highest\n",
       "31      sophie  2.862459   highest\n",
       "32    morality  2.819816   highest\n",
       "33       salon  2.810607   highest\n",
       "34       molly  2.790591   highest\n",
       "35     harrier  2.766224   highest\n",
       "36     majesty  2.724341   highest\n",
       "37       emily  2.696031   highest\n",
       "38       chloe  2.671191   highest\n",
       "39    feminist  2.664294   highest\n",
       "40        lucy  2.649513   highest\n",
       "41      claire  2.635951   highest\n",
       "42       women  2.635685   highest\n",
       "43     taliban  2.633955   highest\n",
       "44       corgi  2.620119   highest\n",
       "45       dread  2.607918   highest\n",
       "46       nurse  2.583530   highest\n",
       "47         sew  2.563833   highest\n",
       "48    misogyny  2.533456   highest\n",
       "49      eilish  2.512256   highest"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create DF of highest coef\n",
    "highest_coef_22 = pd.DataFrame(df_probs_22[0])\n",
    "highest_coef_22[\"coef_type\"] = \"highest\"\n",
    "highest_coef_22[\"year\"] = 2022\n",
    "\n",
    "#create DF of lowest lowest coef manipulation \n",
    "lowest_coef_22 = pd.DataFrame(df_probs_22[1]) \n",
    "lowest_coef_22 = lowest_coef_22.sort_values(by = [\"coef\"], ascending = True).reset_index(drop = True) #absolute lowest value \n",
    "lowest_coef_22[\"coef_type\"] = \"lowest\" #coef type\n",
    "lowest_coef_22[\"year\"] = 2022 #year \n",
    "highest_coef_22.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save DF as pickle file per year \n",
    "lowest_coef_22.to_pickle('RESULTS22_coef_low.pickle')\n",
    "highest_coef_22.to_pickle('RESULTS22_coef_high.pickle')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of coefficient results**\n",
    "\"winner\" is one of the independent variables in the model and its coefficient value is 1.2865737872946597. This means that a one unit increase in the value of the \"winner\" variable will increase the log-odds of the positive class (e.g. \"female\" if the logistic regression model is binary and predicting gender) by the corresponding coefficient value, while holding all other variables constant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Probability Analysis** \n",
    "\n",
    "#make sure to un-comment the last two lines of the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access list of top words \n",
    "#word_prob_10 = pd.DataFrame(df_probs_10[3]) \n",
    "#word_prob_10 = word_prob_10.sort_values([\"probability\"], ascending= False)\n",
    "\n",
    "#save list of words (highest to lowest probability of being female) for year: \n",
    "#word_prob_10.to_pickle('RESULTS09_words_prob.pickle')\n",
    "#word_prob_10.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of the predicted probabilities in LR:** \n",
    "The predicted probabilities of the logistic regression model tell us the probability that the input data belongs to the positive class - in this case the female class as we attributed it a value = 1 in binary log reg. Hence, for each word, we get a list of a word/feature and the probability that it is female. \n",
    "\n",
    "These predicted probabilities can be interpreted as the confidence level of the model in its prediction. For example, a predicted probability of 0.8 for a positive class means that the model is 80% confident that the sample belongs to the positive class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_files_low(directory):\n",
    "    objects = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"low.pickle\"):\n",
    "            with open(os.path.join(directory, filename), 'rb') as file:\n",
    "                obj = pickle.load(file)\n",
    "                objects.append(obj)\n",
    "    return objects\n",
    "\n",
    "def load_pickle_files_high(directory):\n",
    "    objects = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"high.pickle\"):\n",
    "            with open(os.path.join(directory, filename), 'rb') as file:\n",
    "                obj = pickle.load(file)\n",
    "                objects.append(obj)\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack dfs together for low and high coefs \n",
    "df_low = load_pickle_files_low(r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis\")\n",
    "df_high = load_pickle_files_high(r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis\")\n",
    "df_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.inspection import permutation_importance\n",
    "def svm_year(df, target_col, text_col):\n",
    "    #start timer \n",
    "    start_time = time.time()\n",
    "    \n",
    "    #split data \n",
    "    X = df[text_col].apply(lambda x: str(x))\n",
    "    y = df[target_col]\n",
    "\n",
    "    #train test split\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_transformed = tfidf.fit_transform(X).toarray()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # define the hyperparameters to search over\n",
    "    param_grid = {\n",
    "        'C': [.01, .1, 1, 10, 100],\n",
    "        #'kernel': default('rbf')',\n",
    "        'degree': [2,3,4],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        #'class_weight': [None],\n",
    "        #'random_state': [42]\n",
    "    }\n",
    "\n",
    "    #the classifier \n",
    "    clf = SVC()\n",
    "\n",
    "    #create a GridsearchCV object \n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_clf = SVC(**grid_search.best_params_)\n",
    "\n",
    "    #run the classifier \n",
    "    best_clf.fit(X_train, y_train)\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "\n",
    "    #performance \n",
    "    accuracy = best_clf.score(X_test, y_test) #evaluate on test set\n",
    "    class_report = classification_report(y_test, y_pred, zero_division = 0)\n",
    "    results = {'accuracy': accuracy, 'classification_report': class_report}\n",
    "    #print(f\"Year: {year}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Classification Report:\\n{class_report}\")\n",
    "\n",
    "    #get important features (equivalent of coefficients in logreg)\n",
    "    result_clf = permutation_importance(best_clf, X_test, y_test, n_repeats=10, random_state=42)\n",
    "    importance_scores = result_clf.importances_mean\n",
    "    importance_scores_df = pd.DataFrame(importance_scores, columns=['tbd'])\n",
    "\n",
    "    for i in range(len(importance_scores)):\n",
    "        print(\"Feature {}: Importance score = {:.3f}\".format(i, importance_scores[i]))\n",
    "\n",
    "\n",
    "    #end timer \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nExecution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return importance_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "svm_year(df_22, 'col_type', 'pre_processed_sent') #takes more than 1 hour to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the SVM model \n",
    "import joblib\n",
    "model, accuracy, class_report = svm_year(df_09, 'col_type', 'pre_processed_sent')\n",
    "\n",
    "# Save the model and performance metrics\n",
    "joblib.dump(model, 'model_svm.pkl')\n",
    "with open('performance_metrics.txt', 'w') as f:\n",
    "    f.write(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "    f.write(f\"Classification Report:\\n{class_report}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def rnn(df, sentence_col, label_col):\n",
    "    # Tokenize sentences\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(df[sentence_col])\n",
    "    sequences = tokenizer.texts_to_sequences(df[sentence_col])\n",
    "\n",
    "    # Define parameters\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    max_len = 100\n",
    "    embedding_dim = 50\n",
    "\n",
    "    # Pad sequences\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    # Convert label column to numeric values\n",
    "    le = LabelEncoder()\n",
    "    df[label_col] = le.fit_transform(df[label_col])\n",
    "\n",
    "# Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[sentence_col], df[label_col], test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define RNN model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len))\n",
    "    model.add(LSTM(units=64))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g0/r571pkwj6973dlq1m_v76wp40000gn/T/ipykernel_6744/3711098925.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_22\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pre_processed_sent'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'col_type'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/g0/r571pkwj6973dlq1m_v76wp40000gn/T/ipykernel_6744/512257520.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(df, sentence_col, label_col)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "rnn(df_22,'pre_processed_sent', 'col_type')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
