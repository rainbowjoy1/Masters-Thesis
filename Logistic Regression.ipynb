{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time \n",
    "import pickle\n",
    "import os\n",
    "#nltk.download('punkt')\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_processed_sent</th>\n",
       "      <th>male_count</th>\n",
       "      <th>female_count</th>\n",
       "      <th>Proper_noun_list</th>\n",
       "      <th>pn exists</th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[star, die, age]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Welsh, Roger]</td>\n",
       "      <td>True</td>\n",
       "      <td>Welsh actor Roger Rees, star of Cheers and The...</td>\n",
       "      <td>18</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[bear, win, award, title, role]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Nicholas]</td>\n",
       "      <td>None</td>\n",
       "      <td>Mr Rees, who was born in Aberystwyth, Ceredigi...</td>\n",
       "      <td>18</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[play, millionaire, comedy, cheers, political,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Robin, Colcord, John]</td>\n",
       "      <td>True</td>\n",
       "      <td>He played millionaire Robin Colcord in 1980s c...</td>\n",
       "      <td>18</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[play, love, interest, play, cheers]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Rebecca]</td>\n",
       "      <td>None</td>\n",
       "      <td>He played a love interest to Cheers' Rebecca H...</td>\n",
       "      <td>18</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[tweet, sweetest, world]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>She tweeted: \"He is the sweetest man in the wo...</td>\n",
       "      <td>18</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258196</th>\n",
       "      <td>[one, pictured, point, crossbow, camera, wear,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>In one, she is pictured pointing a crossbow at...</td>\n",
       "      <td>2187120</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258197</th>\n",
       "      <td>[chief, prosecutor, say, exchange, phone, call...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>France's chief prosecutor, Francois Molins, sa...</td>\n",
       "      <td>2187120</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258199</th>\n",
       "      <td>[say, record, show, interrogate, french, offic...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>It says the records show she was once interrog...</td>\n",
       "      <td>2187120</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258200</th>\n",
       "      <td>[friend, tell, last, saw, month, ago, dinner]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[Boumeddiene, Le]</td>\n",
       "      <td>True</td>\n",
       "      <td>A friend of Boumeddiene told Le Parisien she l...</td>\n",
       "      <td>2187120</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258201</th>\n",
       "      <td>[say, give, gift, bring, back, recent, pilgrim...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Boumeddiene]</td>\n",
       "      <td>None</td>\n",
       "      <td>She said Boumeddiene gave out gifts she had br...</td>\n",
       "      <td>2187120</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>879446 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        pre_processed_sent  male_count  \\\n",
       "0                                         [star, die, age]           1   \n",
       "1                          [bear, win, award, title, role]           1   \n",
       "2        [play, millionaire, comedy, cheers, political,...           1   \n",
       "4                     [play, love, interest, play, cheers]           1   \n",
       "5                                 [tweet, sweetest, world]           2   \n",
       "...                                                    ...         ...   \n",
       "3258196  [one, pictured, point, crossbow, camera, wear,...           0   \n",
       "3258197  [chief, prosecutor, say, exchange, phone, call...           0   \n",
       "3258199  [say, record, show, interrogate, french, offic...           0   \n",
       "3258200      [friend, tell, last, saw, month, ago, dinner]           0   \n",
       "3258201  [say, give, gift, bring, back, recent, pilgrim...           0   \n",
       "\n",
       "         female_count        Proper_noun_list pn exists  \\\n",
       "0                   0          [Welsh, Roger]      True   \n",
       "1                   0              [Nicholas]      None   \n",
       "2                   0  [Robin, Colcord, John]      True   \n",
       "4                   0               [Rebecca]      None   \n",
       "5                   1                      []      None   \n",
       "...               ...                     ...       ...   \n",
       "3258196             1                      []      None   \n",
       "3258197             1                      []      None   \n",
       "3258199             2                      []      None   \n",
       "3258200             3       [Boumeddiene, Le]      True   \n",
       "3258201             2           [Boumeddiene]      None   \n",
       "\n",
       "                                                 sentences  article_id  year  \\\n",
       "0        Welsh actor Roger Rees, star of Cheers and The...          18  2015   \n",
       "1        Mr Rees, who was born in Aberystwyth, Ceredigi...          18  2015   \n",
       "2        He played millionaire Robin Colcord in 1980s c...          18  2015   \n",
       "4        He played a love interest to Cheers' Rebecca H...          18  2015   \n",
       "5        She tweeted: \"He is the sweetest man in the wo...          18  2015   \n",
       "...                                                    ...         ...   ...   \n",
       "3258196  In one, she is pictured pointing a crossbow at...     2187120  2015   \n",
       "3258197  France's chief prosecutor, Francois Molins, sa...     2187120  2015   \n",
       "3258199  It says the records show she was once interrog...     2187120  2015   \n",
       "3258200  A friend of Boumeddiene told Le Parisien she l...     2187120  2015   \n",
       "3258201  She said Boumeddiene gave out gifts she had br...     2187120  2015   \n",
       "\n",
       "        col_type  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "4              0  \n",
       "5              0  \n",
       "...          ...  \n",
       "3258196        1  \n",
       "3258197        1  \n",
       "3258199        1  \n",
       "3258200        1  \n",
       "3258201        1  \n",
       "\n",
       "[879446 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pre-processed data from pickle \n",
    "#df_10= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2010_text_wo_names.pickle\")\n",
    "#df_09= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2009_text_wo_names.pickle\")\n",
    "#df_11= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2011_text_wo_names.pickle\")\n",
    "#df_12= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2012_text_wo_names.pickle\")\n",
    "#df_13= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2013_text_wo_names.pickle\")\n",
    "#df_14= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2014_text_wo_names.pickle\")\n",
    "df_15= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2015_text_wo_names.pickle\")\n",
    "#df_16= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2016_text_wo_names.pickle\")\n",
    "#df_17= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2017_text_wo_names.pickle\")\n",
    "#df_18= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2018_text_wo_names.pickle\")\n",
    "#df_19 = pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2019_text_wo_names.pickle\")\n",
    "#df_20 = pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2020_text_wo_names.pickle\")\n",
    "#df_21 = pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2021_text_wo_names.pickle\")\n",
    "#df_22 = pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2022_text_wo_names_(1).pickle\")\n",
    "df_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_count(male_col, female_col):\n",
    "    if female_col > male_col and male_col == 0:\n",
    "        return 1\n",
    "    elif male_col> female_col and female_col ==0: \n",
    "        return 0\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    621136\n",
       "1.0    219804\n",
       "Name: col_type, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply function to only get rows with an absolute count \n",
    "df_15['col_type'] = df_15.apply(lambda row: absolute_count(row['male_count'], row['female_count']),axis=1)\n",
    "\n",
    "#remove nulls \n",
    "df_15 = df_15[df_15[\"col_type\"].notnull()]\n",
    "\n",
    "#DOC: number of male and female columns\n",
    "df_15[\"col_type\"].value_counts()  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define TFIDF Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf vectorizer\n",
    "def fake(token):\n",
    "    return token\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=fake,\n",
    "    preprocessor=fake,\n",
    "    token_pattern=None)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Classifier**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What the LR model does-* LR estimates the probability of an instance belonging to the positive class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_year(df, target_col, text_col):\n",
    "    #start timer \n",
    "    start_time = time.time()\n",
    "    \n",
    "    #split data \n",
    "    X = df[text_col].apply(lambda x: str(x))\n",
    "    y = df[target_col]\n",
    "\n",
    "    #train test split\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_transformed = tfidf.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # define the hyperparameters to search over\n",
    "    param_grid = {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'solver': ['lbfgs', 'newton-cg', 'sag' 'saga'], #removed liblinear as it is for small + medium datasets & NOT for sparse data\n",
    "        'class_weight': ['balanced', {0: 0.3, 1: 0.7}],\n",
    "        'random_state': [42]\n",
    "    }\n",
    "\n",
    "    #the classifier \n",
    "    clf = LogisticRegression()\n",
    "\n",
    "    #create a GridsearchCV object \n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_clf = LogisticRegression(**grid_search.best_params_)\n",
    "\n",
    "    #run the classifier \n",
    "    best_clf.fit(X_train, y_train)\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "\n",
    "    #performance \n",
    "    accuracy = best_clf.score(X_test, y_test) #evaluate on test set\n",
    "    class_report = classification_report(y_test, y_pred, zero_division = 0)\n",
    "    #results = {'accuracy': accuracy, 'classification_report': class_report}\n",
    "    #print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    #print(f\"Classification Report:\\n{class_report}\")\n",
    "\n",
    "    #coefficients\n",
    "    coefs = best_clf.coef_[0]\n",
    "    sorted_coef = sorted((zip(tfidf.get_feature_names_out(), coefs)), key = lambda x: x[1], reverse=True)\n",
    "    high_coef = sorted_coef[:1000]\n",
    "    low_coef = sorted_coef[-1000:]\n",
    "    \n",
    "    df_high_coef = pd.DataFrame(high_coef, columns=['feature', 'coef'])\n",
    "    df_low_coef = pd.DataFrame(low_coef, columns=['feature', 'coef'])\n",
    "\n",
    "    #save model \n",
    "    with open('results.pkl', 'wb') as f:\n",
    "        pickle.dump({'accuracy': accuracy, 'report': class_report}, f)\n",
    "\n",
    "    #end timer \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nExecution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return df_high_coef, df_low_coef, best_clf, class_report #df_probs_top"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coefficient Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution time: 1220.47 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        feature      coef\n",
       " 0      pregnant  8.814294\n",
       " 1       harrier  7.743049\n",
       " 2         hijab  7.550609\n",
       " 3       handbag  7.538057\n",
       " 4     pregnancy  7.139974\n",
       " ..          ...       ...\n",
       " 995      gallop  2.981413\n",
       " 996  antoinette  2.981280\n",
       " 997      aiadmk  2.980665\n",
       " 998       zuhra  2.979551\n",
       " 999      titina  2.978756\n",
       " \n",
       " [1000 rows x 2 columns],\n",
       "            feature      coef\n",
       " 0            clone -2.772815\n",
       " 1               yr -2.772969\n",
       " 2            lunge -2.772971\n",
       " 3    gratification -2.773645\n",
       " 4        hungarian -2.774505\n",
       " ..             ...       ...\n",
       " 995     knighthood -5.673168\n",
       " 996       redmayne -5.690594\n",
       " 997      backbench -5.752495\n",
       " 998       gatherer -6.703643\n",
       " 999       prostate -7.600947\n",
       " \n",
       " [1000 rows x 2 columns],\n",
       " LogisticRegression(C=10, class_weight={0: 0.3, 1: 0.7}, random_state=42,\n",
       "                    solver='newton-cg'),\n",
       " '              precision    recall  f1-score   support\\n\\n         0.0       0.84      0.78      0.81    124413\\n         1.0       0.48      0.58      0.52     43775\\n\\n    accuracy                           0.73    168188\\n   macro avg       0.66      0.68      0.66    168188\\nweighted avg       0.74      0.73      0.73    168188\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_probs_15 = logistic_regression_year(df_15, 'col_type', 'pre_processed_sent')\n",
    "df_probs_15"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpreting Performance*\n",
    "\n",
    "The LR model is WAY better in terms of precision, recall, and f1-score at predicting the negative class - i.e. male. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.78      0.81    124413\n",
      "         1.0       0.48      0.58      0.52     43775\n",
      "\n",
      "    accuracy                           0.73    168188\n",
      "   macro avg       0.66      0.68      0.66    168188\n",
      "weighted avg       0.74      0.73      0.73    168188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#open model performance metrics \n",
    "with open('results_15.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "accuracy = results['accuracy']\n",
    "report = results['report']\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Classification report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>coef_type</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pregnant</td>\n",
       "      <td>8.814294</td>\n",
       "      <td>highest</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>harrier</td>\n",
       "      <td>7.743049</td>\n",
       "      <td>highest</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hijab</td>\n",
       "      <td>7.550609</td>\n",
       "      <td>highest</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>handbag</td>\n",
       "      <td>7.538057</td>\n",
       "      <td>highest</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pregnancy</td>\n",
       "      <td>7.139974</td>\n",
       "      <td>highest</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>gallop</td>\n",
       "      <td>2.981413</td>\n",
       "      <td>highest</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>antoinette</td>\n",
       "      <td>2.981280</td>\n",
       "      <td>highest</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>aiadmk</td>\n",
       "      <td>2.980665</td>\n",
       "      <td>highest</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>zuhra</td>\n",
       "      <td>2.979551</td>\n",
       "      <td>highest</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>titina</td>\n",
       "      <td>2.978756</td>\n",
       "      <td>highest</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature      coef coef_type  year\n",
       "0      pregnant  8.814294   highest  2015\n",
       "1       harrier  7.743049   highest  2015\n",
       "2         hijab  7.550609   highest  2015\n",
       "3       handbag  7.538057   highest  2015\n",
       "4     pregnancy  7.139974   highest  2015\n",
       "..          ...       ...       ...   ...\n",
       "995      gallop  2.981413   highest  2015\n",
       "996  antoinette  2.981280   highest  2015\n",
       "997      aiadmk  2.980665   highest  2015\n",
       "998       zuhra  2.979551   highest  2015\n",
       "999      titina  2.978756   highest  2015\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create DF of highest coef\n",
    "highest_coef_15 = pd.DataFrame(df_probs_15[0])\n",
    "highest_coef_15[\"coef_type\"] = \"highest\"\n",
    "highest_coef_15[\"year\"] = 2015\n",
    "\n",
    "#create DF of lowest lowest coef manipulation \n",
    "lowest_coef_15 = pd.DataFrame(df_probs_15[1]) \n",
    "lowest_coef_15 = lowest_coef_15.sort_values(by = [\"coef\"], ascending = True).reset_index(drop = True) #absolute lowest value \n",
    "lowest_coef_15[\"coef_type\"] = \"lowest\" #coef type\n",
    "lowest_coef_15[\"year\"] = 2015 #year \n",
    "highest_coef_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save DF as pickle file per year \n",
    "lowest_coef_15.to_pickle('RESULTS15_coef_low.pickle')\n",
    "highest_coef_15.to_pickle('RESULTS15_coef_high.pickle')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of coefficient results**\n",
    "\"winner\" is one of the independent variables in the model and its coefficient value is 1.2865737872946597. This means that a one unit increase in the value of the \"winner\" variable will increase the log-odds of the positive class (e.g. \"female\" if the logistic regression model is binary and predicting gender) by the corresponding coefficient value, while holding all other variables constant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of the predicted probabilities in LR:** \n",
    "The predicted probabilities of the logistic regression model tell us the probability that the input data belongs to the positive class - in this case the female class as we attributed it a value = 1 in binary log reg. Hence, for each word, we get a list of a word/feature and the probability that it is female. \n",
    "\n",
    "These predicted probabilities can be interpreted as the confidence level of the model in its prediction. For example, a predicted probability of 0.8 for a positive class means that the model is 80% confident that the sample belongs to the positive class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_files_low(directory):\n",
    "    objects = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"low.pickle\"):\n",
    "            with open(os.path.join(directory, filename), 'rb') as file:\n",
    "                obj = pickle.load(file)\n",
    "                objects.append(obj)\n",
    "    return objects\n",
    "\n",
    "def load_pickle_files_high(directory):\n",
    "    objects = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"high.pickle\"):\n",
    "            with open(os.path.join(directory, filename), 'rb') as file:\n",
    "                obj = pickle.load(file)\n",
    "                objects.append(obj)\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[           feature      coef coef_type  year\n",
       " 0         pregnant  3.693514   highest  2012\n",
       " 1             baby  3.158639   highest  2012\n",
       " 2           female  3.043889   highest  2012\n",
       " 3              rap  2.908451   highest  2012\n",
       " 4          implant  2.901732   highest  2012\n",
       " ..             ...       ...       ...   ...\n",
       " 995          sheet  0.265721   highest  2012\n",
       " 996      whitehawk  0.265642   highest  2012\n",
       " 997  heartbreaking  0.265527   highest  2012\n",
       " 998         rights  0.265453   highest  2012\n",
       " 999        winning  0.265396   highest  2012\n",
       " \n",
       " [1000 rows x 4 columns],\n",
       "             feature      coef coef_type  year\n",
       " 0          pregnant  3.947211   highest  2013\n",
       " 1               rap  3.134167   highest  2013\n",
       " 2         boyfriend  2.970981   highest  2013\n",
       " 3              baby  2.843502   highest  2013\n",
       " 4            female  2.827021   highest  2013\n",
       " ..              ...       ...       ...   ...\n",
       " 995    specifically  0.263976   highest  2013\n",
       " 996     provocation  0.263957   highest  2013\n",
       " 997            katy  0.263865   highest  2013\n",
       " 998  misinformation  0.263568   highest  2013\n",
       " 999         scratch  0.263235   highest  2013\n",
       " \n",
       " [1000 rows x 4 columns],\n",
       "        feature      coef coef_type  year\n",
       " 0     pregnant  3.190354   highest  2010\n",
       " 1         baby  3.086015   highest  2010\n",
       " 2        child  2.503928   highest  2010\n",
       " 3    boyfriend  2.470486   highest  2010\n",
       " 4          rap  2.218724   highest  2010\n",
       " ..         ...       ...       ...   ...\n",
       " 995    overdue  0.204064   highest  2010\n",
       " 996  boardroom  0.203946   highest  2010\n",
       " 997  housework  0.203856   highest  2010\n",
       " 998      fruit  0.203810   highest  2010\n",
       " 999     pelvis  0.203692   highest  2010\n",
       " \n",
       " [1000 rows x 4 columns],\n",
       "            feature      coef coef_type  year\n",
       " 0         pregnant  8.252975   highest  2014\n",
       " 1        pregnancy  7.451794   highest  2014\n",
       " 2          harrier  7.129829   highest  2014\n",
       " 3          briscoe  7.091350   highest  2014\n",
       " 4    sterilisation  7.021489   highest  2014\n",
       " ..             ...       ...       ...   ...\n",
       " 995    informatics  3.054526   highest  2014\n",
       " 996          alina  3.053517   highest  2014\n",
       " 997       arterton  3.052992   highest  2014\n",
       " 998          raped  3.052557   highest  2014\n",
       " 999        lavinia  3.052432   highest  2014\n",
       " \n",
       " [1000 rows x 4 columns],\n",
       "              feature       coef coef_type  year\n",
       " 0    manoeuvrability  18.498864   highest  2011\n",
       " 1           banerjee  17.827019   highest  2011\n",
       " 2            fortuna  17.183967   highest  2011\n",
       " 3             supple  16.971474   highest  2011\n",
       " 4            ovarian  16.832611   highest  2011\n",
       " ..               ...        ...       ...   ...\n",
       " 995          burgham   8.534699   highest  2011\n",
       " 996            leone   8.533295   highest  2011\n",
       " 997         rosenior   8.533295   highest  2011\n",
       " 998            janes   8.528300   highest  2011\n",
       " 999       mutability   8.528115   highest  2011\n",
       " \n",
       " [1000 rows x 4 columns],\n",
       "         feature      coef coef_type  year\n",
       " 0      pregnant  8.814294   highest  2015\n",
       " 1       harrier  7.743049   highest  2015\n",
       " 2         hijab  7.550609   highest  2015\n",
       " 3       handbag  7.538057   highest  2015\n",
       " 4     pregnancy  7.139974   highest  2015\n",
       " ..          ...       ...       ...   ...\n",
       " 995      gallop  2.981413   highest  2015\n",
       " 996  antoinette  2.981280   highest  2015\n",
       " 997      aiadmk  2.980665   highest  2015\n",
       " 998       zuhra  2.979551   highest  2015\n",
       " 999      titina  2.978756   highest  2015\n",
       " \n",
       " [1000 rows x 4 columns]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack dfs together for low and high coefs \n",
    "df_low = load_pickle_files_low(r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis\")\n",
    "df_high = load_pickle_files_high(r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis\")\n",
    "df_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
