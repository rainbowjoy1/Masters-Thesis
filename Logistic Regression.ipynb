{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time \n",
    "import pickle\n",
    "import os\n",
    "#nltk.download('punkt')\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2010\"\n",
    "file_path = \"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/\"\n",
    "file_path_2 = \"_final_rnn.pickle\"\n",
    "\n",
    "df_10= pd.read_pickle(file_path + year + file_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_count(male_col, female_col):\n",
    "    if female_col > male_col and male_col == 0:\n",
    "        return 1\n",
    "    elif male_col> female_col and female_col ==0: \n",
    "        return 0\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    378476\n",
       "1.0    113870\n",
       "Name: col_type, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply function to only get rows with an absolute count \n",
    "df_10['col_type'] = df_10.apply(lambda row: absolute_count(row['male_count'], row['female_count']),axis=1)\n",
    "\n",
    "#remove nulls \n",
    "df_10 = df_10[df_10[\"col_type\"].notnull()]\n",
    "\n",
    "#DOC: number of male and female columns\n",
    "df_10[\"col_type\"].value_counts()  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define TFIDF Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf vectorizer\n",
    "def fake(token):\n",
    "    return token\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=fake,\n",
    "    preprocessor=fake,\n",
    "    token_pattern=None)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Classifier**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What the LR model does-* LR estimates the probability of an instance belonging to the positive class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_year(df, target_col, text_col):\n",
    "    #start timer \n",
    "    start_time = time.time()\n",
    "    \n",
    "    #split data \n",
    "    X = df[text_col].apply(lambda x: str(x))\n",
    "    y = df[target_col]\n",
    "\n",
    "    #train test split\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_transformed = tfidf.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # define the hyperparameters to search over\n",
    "    param_grid = {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'solver': ['lbfgs', 'newton-cg', 'sag' 'saga'], #removed liblinear as it is for small + medium datasets & NOT for sparse data\n",
    "        'class_weight': ['balanced', {0: 0.3, 1: 0.7}],\n",
    "        'random_state': [42]\n",
    "    }\n",
    "\n",
    "    #the classifier \n",
    "    clf = LogisticRegression()\n",
    "\n",
    "    #create a GridsearchCV object \n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_clf = LogisticRegression(**grid_search.best_params_)\n",
    "\n",
    "    #run the classifier \n",
    "    best_clf.fit(X_train, y_train)\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "\n",
    "    #performance \n",
    "    accuracy = best_clf.score(X_test, y_test) #evaluate on test set\n",
    "    class_report = classification_report(y_test, y_pred, zero_division = 0)\n",
    "    #results = {'accuracy': accuracy, 'classification_report': class_report}\n",
    "    #print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    #print(f\"Classification Report:\\n{class_report}\")\n",
    "\n",
    "    #coefficients\n",
    "    coefs = best_clf.coef_[0]\n",
    "    sorted_coef = sorted((zip(tfidf.get_feature_names_out(), coefs)), key = lambda x: x[1], reverse=True)\n",
    "    high_coef = sorted_coef[:1000]\n",
    "    low_coef = sorted_coef[-1000:]\n",
    "    \n",
    "    df_high_coef = pd.DataFrame(high_coef, columns=['feature', 'coef'])\n",
    "    df_low_coef = pd.DataFrame(low_coef, columns=['feature', 'coef'])\n",
    "\n",
    "    #save model \n",
    "    with open('results.pkl', 'wb') as f:\n",
    "        pickle.dump({'model': best_clf, 'tfidf': tfidf, 'accuracy': accuracy, 'report': class_report}, f)\n",
    "\n",
    "    #end timer \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nExecution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return df_high_coef, df_low_coef, best_clf, class_report #df_probs_top"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coefficient Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution time: 525.98 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(       feature      coef\n",
       " 0     pregnant  3.186218\n",
       " 1         baby  3.085429\n",
       " 2        child  2.502925\n",
       " 3    boyfriend  2.471323\n",
       " 4          rap  2.215964\n",
       " ..         ...       ...\n",
       " 995     openly  0.201524\n",
       " 996     duress  0.201428\n",
       " 997   campaign  0.201339\n",
       " 998      nanny  0.200883\n",
       " 999      susan  0.200859\n",
       " \n",
       " [1000 rows x 2 columns],\n",
       "         feature      coef\n",
       " 0     reinstate -0.213403\n",
       " 1          bird -0.214428\n",
       " 2        dinghy -0.214939\n",
       " 3         evade -0.215387\n",
       " 4       embassy -0.215427\n",
       " ..          ...       ...\n",
       " 995    football -1.268172\n",
       " 996  girlfriend -1.327853\n",
       " 997       shoot -1.620356\n",
       " 998     soldier -1.622398\n",
       " 999      arrest -1.826027\n",
       " \n",
       " [1000 rows x 2 columns],\n",
       " LogisticRegression(C=0.1, class_weight={0: 0.3, 1: 0.7}, random_state=42,\n",
       "                    solver='newton-cg'),\n",
       " '              precision    recall  f1-score   support\\n\\n         0.0       0.81      0.90      0.85     75430\\n         1.0       0.48      0.30      0.37     23040\\n\\n    accuracy                           0.76     98470\\n   macro avg       0.64      0.60      0.61     98470\\nweighted avg       0.73      0.76      0.74     98470\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_probs_10 = logistic_regression_year(df_10, 'col_type', 'pre_processed_sent')\n",
    "df_probs_10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpreting Performance*\n",
    "\n",
    "The LR model is WAY better in terms of precision, recall, and f1-score at predicting the negative class - i.e. male. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.90      0.85     75430\n",
      "         1.0       0.48      0.30      0.37     23040\n",
      "\n",
      "    accuracy                           0.76     98470\n",
      "   macro avg       0.64      0.60      0.61     98470\n",
      "weighted avg       0.73      0.76      0.74     98470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#open model performance metrics \n",
    "with open('results_10.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "accuracy = results['accuracy']\n",
    "report = results['report']\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Classification report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create DF of highest coef\n",
    "highest_coef_22 = pd.DataFrame(df_probs_22[0])\n",
    "highest_coef_22[\"coef_type\"] = \"highest\"\n",
    "highest_coef_22[\"year\"] = year\n",
    "\n",
    "#create DF of lowest lowest coef manipulation \n",
    "lowest_coef_22 = pd.DataFrame(df_probs_22[1]) \n",
    "lowest_coef_22 = lowest_coef_22.sort_values(by = [\"coef\"], ascending = True).reset_index(drop = True) #absolute lowest value \n",
    "lowest_coef_22[\"coef_type\"] = \"lowest\" #coef type\n",
    "lowest_coef_22[\"year\"] = year #year \n",
    "highest_coef_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save DF as pickle file per year \n",
    "lowest_coef_22.to_pickle('RESULTS22_coef_low.pickle')\n",
    "highest_coef_22.to_pickle('RESULTS22_coef_high.pickle')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of coefficient results**\n",
    "\"winner\" is one of the independent variables in the model and its coefficient value is 1.2865737872946597. This means that a one unit increase in the value of the \"winner\" variable will increase the log-odds of the positive class (e.g. \"female\" if the logistic regression model is binary and predicting gender) by the corresponding coefficient value, while holding all other variables constant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of the predicted probabilities in LR:** \n",
    "The predicted probabilities of the logistic regression model tell us the probability that the input data belongs to the positive class - in this case the female class as we attributed it a value = 1 in binary log reg. Hence, for each word, we get a list of a word/feature and the probability that it is female. \n",
    "\n",
    "These predicted probabilities can be interpreted as the confidence level of the model in its prediction. For example, a predicted probability of 0.8 for a positive class means that the model is 80% confident that the sample belongs to the positive class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_files_low(directory):\n",
    "    objects = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"low.pickle\"):\n",
    "            with open(os.path.join(directory, filename), 'rb') as file:\n",
    "                obj = pickle.load(file)\n",
    "                objects.append(obj)\n",
    "    return objects\n",
    "\n",
    "def load_pickle_files_high(directory):\n",
    "    objects = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"high.pickle\"):\n",
    "            with open(os.path.join(directory, filename), 'rb') as file:\n",
    "                obj = pickle.load(file)\n",
    "                objects.append(obj)\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack dfs together for low and high coefs \n",
    "df_low = load_pickle_files_low(r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis\")\n",
    "df_high = load_pickle_files_high(r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis\")\n",
    "df_high"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decade Long LR Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/\"\n",
    "file_path_2 = \"_final_rnn.pickle\"\n",
    "\n",
    "df_10= pd.read_pickle(file_path + \"2010\" + file_path_2)\n",
    "df_11= pd.read_pickle(file_path + \"2011\" + file_path_2)\n",
    "df_12= pd.read_pickle(file_path + \"2012\" + file_path_2)\n",
    "df_13= pd.read_pickle(file_path + \"2013\" + file_path_2)\n",
    "df_14= pd.read_pickle(file_path + \"2014\" + file_path_2)\n",
    "df_15= pd.read_pickle(file_path + \"2015\" + file_path_2)\n",
    "df_16= pd.read_pickle(file_path + \"2016\" + file_path_2)\n",
    "df_17= pd.read_pickle(file_path + \"2017\" + file_path_2)\n",
    "df_18= pd.read_pickle(file_path + \"2018\" + file_path_2)\n",
    "df_19= pd.read_pickle(file_path + \"2019\" + file_path_2)\n",
    "df_20= pd.read_pickle(file_path + \"2020\" + file_path_2)\n",
    "df_21= pd.read_pickle(file_path + \"2021\" + file_path_2)\n",
    "df_22= pd.read_pickle(file_path + \"2022\" + file_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_10, df_11, df_12, df_13, df_14, df_15, df_16, df_17, df_18, df_19, df_20, df_21, df_22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_processed_sent</th>\n",
       "      <th>string_rnn</th>\n",
       "      <th>male_count</th>\n",
       "      <th>female_count</th>\n",
       "      <th>Proper_noun_list</th>\n",
       "      <th>pn exists</th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[say, delight, restored, bridge, back, use]</td>\n",
       "      <td>say delight restored bridge back use</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Southease]</td>\n",
       "      <td>None</td>\n",
       "      <td>Chairman of Southease Parish, Neville Harrison...</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[family, year, old, kill, house, fire, pay, tr...</td>\n",
       "      <td>family year old kill house fire pay tribute br...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>The family of a 34-year-old mother from Bristo...</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[family, say, kind, totally, dedicated]</td>\n",
       "      <td>family say kind totally dedicated</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>Her family said she was kind and a totally ded...</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[truly, tragic, love, family, everything, give...</td>\n",
       "      <td>truly tragic love family everything give famil...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[Sara]</td>\n",
       "      <td>None</td>\n",
       "      <td>'Truly tragic'\"Sara loved her family above eve...</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[everybody, know, love, miss, always]</td>\n",
       "      <td>everybody know love miss always</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Everybody who knew her will love her and miss...</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410780</th>\n",
       "      <td>[ground, hard, thaw, yet, come, experience, sh...</td>\n",
       "      <td>ground hard thaw yet come experience show u th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"The ground has been very hard, the thaw is ye...</td>\n",
       "      <td>1043999</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410781</th>\n",
       "      <td>[endeavour, get, ahead, game, best, find, situ...</td>\n",
       "      <td>endeavour get ahead game best find situation c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"What we are endeavouring to do here is get ah...</td>\n",
       "      <td>1043999</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410782</th>\n",
       "      <td>[die, hit, garage, forecourt]</td>\n",
       "      <td>die hit garage forecourt</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>A man has died after being hit by a 4x4 on a g...</td>\n",
       "      <td>1044006</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410783</th>\n",
       "      <td>[north, say, incident, garage, happen, area, t...</td>\n",
       "      <td>north say incident garage happen area take hos...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Wales, Chester]</td>\n",
       "      <td>True</td>\n",
       "      <td>North Wales Police said the incident at the Pr...</td>\n",
       "      <td>1044006</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410784</th>\n",
       "      <td>[next, kin, inform]</td>\n",
       "      <td>next kin inform</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>His next of kin have been informed.</td>\n",
       "      <td>1044006</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10141265 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       pre_processed_sent  \\\n",
       "0             [say, delight, restored, bridge, back, use]   \n",
       "1       [family, year, old, kill, house, fire, pay, tr...   \n",
       "2                 [family, say, kind, totally, dedicated]   \n",
       "3       [truly, tragic, love, family, everything, give...   \n",
       "4                   [everybody, know, love, miss, always]   \n",
       "...                                                   ...   \n",
       "410780  [ground, hard, thaw, yet, come, experience, sh...   \n",
       "410781  [endeavour, get, ahead, game, best, find, situ...   \n",
       "410782                      [die, hit, garage, forecourt]   \n",
       "410783  [north, say, incident, garage, happen, area, t...   \n",
       "410784                                [next, kin, inform]   \n",
       "\n",
       "                                               string_rnn  male_count  \\\n",
       "0                    say delight restored bridge back use           1   \n",
       "1       family year old kill house fire pay tribute br...           0   \n",
       "2                       family say kind totally dedicated           1   \n",
       "3       truly tragic love family everything give famil...           0   \n",
       "4                         everybody know love miss always           0   \n",
       "...                                                   ...         ...   \n",
       "410780  ground hard thaw yet come experience show u th...           1   \n",
       "410781  endeavour get ahead game best find situation c...           1   \n",
       "410782                           die hit garage forecourt           1   \n",
       "410783  north say incident garage happen area take hos...           2   \n",
       "410784                                    next kin inform           1   \n",
       "\n",
       "        female_count  Proper_noun_list pn exists  \\\n",
       "0                  0       [Southease]      None   \n",
       "1                  2                []      None   \n",
       "2                  4                []      None   \n",
       "3                  4            [Sara]      None   \n",
       "4                  3                []      None   \n",
       "...              ...               ...       ...   \n",
       "410780             0                []      None   \n",
       "410781             0                []      None   \n",
       "410782             0                []      None   \n",
       "410783             0  [Wales, Chester]      True   \n",
       "410784             0                []      None   \n",
       "\n",
       "                                                sentences  article_id  year  \\\n",
       "0       Chairman of Southease Parish, Neville Harrison...           1  2010   \n",
       "1       The family of a 34-year-old mother from Bristo...          21  2010   \n",
       "2       Her family said she was kind and a totally ded...          21  2010   \n",
       "3       'Truly tragic'\"Sara loved her family above eve...          21  2010   \n",
       "4       \"Everybody who knew her will love her and miss...          21  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "410780  \"The ground has been very hard, the thaw is ye...     1043999  2022   \n",
       "410781  \"What we are endeavouring to do here is get ah...     1043999  2022   \n",
       "410782  A man has died after being hit by a 4x4 on a g...     1044006  2022   \n",
       "410783  North Wales Police said the incident at the Pr...     1044006  2022   \n",
       "410784                His next of kin have been informed.     1044006  2022   \n",
       "\n",
       "       col_type  \n",
       "0             0  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "...         ...  \n",
       "410780        0  \n",
       "410781        0  \n",
       "410782        0  \n",
       "410783        0  \n",
       "410784        0  \n",
       "\n",
       "[10141265 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_count(male_col, female_col):\n",
    "    if female_col > male_col and male_col == 0:\n",
    "        return 1\n",
    "    elif male_col> female_col and female_col ==0: \n",
    "        return 0\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    6928463\n",
       "1.0    2736784\n",
       "Name: col_type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply function to only get rows with an absolute count \n",
    "df_all['col_type'] = df_all.apply(lambda row: absolute_count(row['male_count'], row['female_count']),axis=1)\n",
    "\n",
    "#remove nulls \n",
    "df_all = df_all[df_all[\"col_type\"].notnull()]\n",
    "\n",
    "#DOC: number of male and female columns\n",
    "df_all[\"col_type\"].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_processed_sent</th>\n",
       "      <th>string_rnn</th>\n",
       "      <th>male_count</th>\n",
       "      <th>female_count</th>\n",
       "      <th>Proper_noun_list</th>\n",
       "      <th>pn exists</th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[say, delight, restored, bridge, back, use]</td>\n",
       "      <td>say delight restored bridge back use</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Southease]</td>\n",
       "      <td>None</td>\n",
       "      <td>Chairman of Southease Parish, Neville Harrison...</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[family, year, old, kill, house, fire, pay, tr...</td>\n",
       "      <td>family year old kill house fire pay tribute br...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>The family of a 34-year-old mother from Bristo...</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[truly, tragic, love, family, everything, give...</td>\n",
       "      <td>truly tragic love family everything give famil...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[Sara]</td>\n",
       "      <td>None</td>\n",
       "      <td>'Truly tragic'\"Sara loved her family above eve...</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[everybody, know, love, miss, always]</td>\n",
       "      <td>everybody know love miss always</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Everybody who knew her will love her and miss...</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[truly, tragic, event, keen, determine, exactl...</td>\n",
       "      <td>truly tragic event keen determine exactly lead...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"This was a truly tragic event and we are very...</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410780</th>\n",
       "      <td>[ground, hard, thaw, yet, come, experience, sh...</td>\n",
       "      <td>ground hard thaw yet come experience show u th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"The ground has been very hard, the thaw is ye...</td>\n",
       "      <td>1043999</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410781</th>\n",
       "      <td>[endeavour, get, ahead, game, best, find, situ...</td>\n",
       "      <td>endeavour get ahead game best find situation c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"What we are endeavouring to do here is get ah...</td>\n",
       "      <td>1043999</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410782</th>\n",
       "      <td>[die, hit, garage, forecourt]</td>\n",
       "      <td>die hit garage forecourt</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>A man has died after being hit by a 4x4 on a g...</td>\n",
       "      <td>1044006</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410783</th>\n",
       "      <td>[north, say, incident, garage, happen, area, t...</td>\n",
       "      <td>north say incident garage happen area take hos...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Wales, Chester]</td>\n",
       "      <td>True</td>\n",
       "      <td>North Wales Police said the incident at the Pr...</td>\n",
       "      <td>1044006</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410784</th>\n",
       "      <td>[next, kin, inform]</td>\n",
       "      <td>next kin inform</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>His next of kin have been informed.</td>\n",
       "      <td>1044006</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9665247 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       pre_processed_sent  \\\n",
       "0             [say, delight, restored, bridge, back, use]   \n",
       "1       [family, year, old, kill, house, fire, pay, tr...   \n",
       "3       [truly, tragic, love, family, everything, give...   \n",
       "4                   [everybody, know, love, miss, always]   \n",
       "5       [truly, tragic, event, keen, determine, exactl...   \n",
       "...                                                   ...   \n",
       "410780  [ground, hard, thaw, yet, come, experience, sh...   \n",
       "410781  [endeavour, get, ahead, game, best, find, situ...   \n",
       "410782                      [die, hit, garage, forecourt]   \n",
       "410783  [north, say, incident, garage, happen, area, t...   \n",
       "410784                                [next, kin, inform]   \n",
       "\n",
       "                                               string_rnn  male_count  \\\n",
       "0                    say delight restored bridge back use           1   \n",
       "1       family year old kill house fire pay tribute br...           0   \n",
       "3       truly tragic love family everything give famil...           0   \n",
       "4                         everybody know love miss always           0   \n",
       "5       truly tragic event keen determine exactly lead...           0   \n",
       "...                                                   ...         ...   \n",
       "410780  ground hard thaw yet come experience show u th...           1   \n",
       "410781  endeavour get ahead game best find situation c...           1   \n",
       "410782                           die hit garage forecourt           1   \n",
       "410783  north say incident garage happen area take hos...           2   \n",
       "410784                                    next kin inform           1   \n",
       "\n",
       "        female_count  Proper_noun_list pn exists  \\\n",
       "0                  0       [Southease]      None   \n",
       "1                  2                []      None   \n",
       "3                  4            [Sara]      None   \n",
       "4                  3                []      None   \n",
       "5                  1                []      None   \n",
       "...              ...               ...       ...   \n",
       "410780             0                []      None   \n",
       "410781             0                []      None   \n",
       "410782             0                []      None   \n",
       "410783             0  [Wales, Chester]      True   \n",
       "410784             0                []      None   \n",
       "\n",
       "                                                sentences  article_id  year  \\\n",
       "0       Chairman of Southease Parish, Neville Harrison...           1  2010   \n",
       "1       The family of a 34-year-old mother from Bristo...          21  2010   \n",
       "3       'Truly tragic'\"Sara loved her family above eve...          21  2010   \n",
       "4       \"Everybody who knew her will love her and miss...          21  2010   \n",
       "5       \"This was a truly tragic event and we are very...          21  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "410780  \"The ground has been very hard, the thaw is ye...     1043999  2022   \n",
       "410781  \"What we are endeavouring to do here is get ah...     1043999  2022   \n",
       "410782  A man has died after being hit by a 4x4 on a g...     1044006  2022   \n",
       "410783  North Wales Police said the incident at the Pr...     1044006  2022   \n",
       "410784                His next of kin have been informed.     1044006  2022   \n",
       "\n",
       "        col_type  \n",
       "0            0.0  \n",
       "1            1.0  \n",
       "3            1.0  \n",
       "4            1.0  \n",
       "5            1.0  \n",
       "...          ...  \n",
       "410780       0.0  \n",
       "410781       0.0  \n",
       "410782       0.0  \n",
       "410783       0.0  \n",
       "410784       0.0  \n",
       "\n",
       "[9665247 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_processed_sent</th>\n",
       "      <th>col_type</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[say, delight, restored, bridge, back, use]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[family, year, old, kill, house, fire, pay, tr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[truly, tragic, love, family, everything, give...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[everybody, know, love, miss, always]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[truly, tragic, event, keen, determine, exactl...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410780</th>\n",
       "      <td>[ground, hard, thaw, yet, come, experience, sh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1043999</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410781</th>\n",
       "      <td>[endeavour, get, ahead, game, best, find, situ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1043999</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410782</th>\n",
       "      <td>[die, hit, garage, forecourt]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1044006</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410783</th>\n",
       "      <td>[north, say, incident, garage, happen, area, t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1044006</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410784</th>\n",
       "      <td>[next, kin, inform]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1044006</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9665247 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       pre_processed_sent  col_type  \\\n",
       "0             [say, delight, restored, bridge, back, use]       0.0   \n",
       "1       [family, year, old, kill, house, fire, pay, tr...       1.0   \n",
       "3       [truly, tragic, love, family, everything, give...       1.0   \n",
       "4                   [everybody, know, love, miss, always]       1.0   \n",
       "5       [truly, tragic, event, keen, determine, exactl...       1.0   \n",
       "...                                                   ...       ...   \n",
       "410780  [ground, hard, thaw, yet, come, experience, sh...       0.0   \n",
       "410781  [endeavour, get, ahead, game, best, find, situ...       0.0   \n",
       "410782                      [die, hit, garage, forecourt]       0.0   \n",
       "410783  [north, say, incident, garage, happen, area, t...       0.0   \n",
       "410784                                [next, kin, inform]       0.0   \n",
       "\n",
       "        article_id  year  \n",
       "0                1  2010  \n",
       "1               21  2010  \n",
       "3               21  2010  \n",
       "4               21  2010  \n",
       "5               21  2010  \n",
       "...            ...   ...  \n",
       "410780     1043999  2022  \n",
       "410781     1043999  2022  \n",
       "410782     1044006  2022  \n",
       "410783     1044006  2022  \n",
       "410784     1044006  2022  \n",
       "\n",
       "[9665247 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced = df_all[[\"pre_processed_sent\", \"col_type\", \"article_id\", \"year\"]]\n",
    "df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution time: 33025.36 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(       feature       coef\n",
       " 0      harrier  10.251280\n",
       " 1     pregnant   8.474120\n",
       " 2    headscarf   8.387455\n",
       " 3        hijab   8.165802\n",
       " 4       chibok   7.926305\n",
       " ..         ...        ...\n",
       " 995    sheezus   3.767088\n",
       " 996   chippies   3.767081\n",
       " 997   thunberg   3.766711\n",
       " 998   tlatlaya   3.766054\n",
       " 999  roundmoor   3.765732\n",
       " \n",
       " [1000 rows x 2 columns],\n",
       "         feature      coef\n",
       " 0          joao -3.415070\n",
       " 1    decolonise -3.417159\n",
       " 2         bosco -3.417262\n",
       " 3         tupac -3.417617\n",
       " 4         dally -3.418468\n",
       " ..          ...       ...\n",
       " 995     batsman -7.056664\n",
       " 996  crossbench -7.877373\n",
       " 997    gatherer -7.928533\n",
       " 998    prostate -8.027753\n",
       " 999  fatherhood -8.211420\n",
       " \n",
       " [1000 rows x 2 columns],\n",
       " LogisticRegression(C=10, class_weight={0: 0.3, 1: 0.7}, random_state=42,\n",
       "                    solver='newton-cg'),\n",
       " '              precision    recall  f1-score   support\\n\\n         0.0       0.82      0.71      0.76   1385268\\n         1.0       0.45      0.60      0.51    547782\\n\\n    accuracy                           0.68   1933050\\n   macro avg       0.63      0.66      0.64   1933050\\nweighted avg       0.71      0.68      0.69   1933050\\n')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_probs_all= logistic_regression_year(df_reduced, 'col_type', 'pre_processed_sent')\n",
    "df_probs_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decade Model Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.71      0.76   1385268\n",
      "         1.0       0.45      0.60      0.51    547782\n",
      "\n",
      "    accuracy                           0.68   1933050\n",
      "   macro avg       0.63      0.66      0.64   1933050\n",
      "weighted avg       0.71      0.68      0.69   1933050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#open model performance metrics \n",
    "with open('results_decade.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "accuracy = results['accuracy']\n",
    "report = results['report']\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Classification report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>coef_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fatherhood</td>\n",
       "      <td>-8.211420</td>\n",
       "      <td>lowest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prostate</td>\n",
       "      <td>-8.027753</td>\n",
       "      <td>lowest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gatherer</td>\n",
       "      <td>-7.928533</td>\n",
       "      <td>lowest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crossbench</td>\n",
       "      <td>-7.877373</td>\n",
       "      <td>lowest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batsman</td>\n",
       "      <td>-7.056664</td>\n",
       "      <td>lowest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>dally</td>\n",
       "      <td>-3.418468</td>\n",
       "      <td>lowest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>tupac</td>\n",
       "      <td>-3.417617</td>\n",
       "      <td>lowest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>bosco</td>\n",
       "      <td>-3.417262</td>\n",
       "      <td>lowest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>decolonise</td>\n",
       "      <td>-3.417159</td>\n",
       "      <td>lowest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>joao</td>\n",
       "      <td>-3.415070</td>\n",
       "      <td>lowest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature      coef coef_type\n",
       "0    fatherhood -8.211420    lowest\n",
       "1      prostate -8.027753    lowest\n",
       "2      gatherer -7.928533    lowest\n",
       "3    crossbench -7.877373    lowest\n",
       "4       batsman -7.056664    lowest\n",
       "..          ...       ...       ...\n",
       "995       dally -3.418468    lowest\n",
       "996       tupac -3.417617    lowest\n",
       "997       bosco -3.417262    lowest\n",
       "998  decolonise -3.417159    lowest\n",
       "999        joao -3.415070    lowest\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create DF of highest coef\n",
    "highest_coef_decade = pd.DataFrame(df_probs_all[0])\n",
    "highest_coef_decade[\"coef_type\"] = \"highest\"\n",
    "#highest_coef_decade[\"year\"] = year\n",
    "\n",
    "#create DF of lowest lowest coef manipulation \n",
    "lowest_coef_decade = pd.DataFrame(df_probs_all[1]) \n",
    "lowest_coef_decade = lowest_coef_decade.sort_values(by = [\"coef\"], ascending = True).reset_index(drop = True) #absolute lowest value \n",
    "lowest_coef_decade[\"coef_type\"] = \"lowest\" #coef type\n",
    "#lowest_coef_decade[\"year\"] = year #year \n",
    "lowest_coef_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save DF as pickle file per year \n",
    "lowest_coef_decade.to_pickle('RESULTSdecade_coef_low.pickle')\n",
    "highest_coef_decade.to_pickle('RESULTSdecade_coef_high.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
