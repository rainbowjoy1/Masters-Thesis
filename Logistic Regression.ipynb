{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics \n",
    "from nltk.corpus import stopwords\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df, column_name): \n",
    "    \"\"\"Split Sentences DF by the year column so that we can do the LR by year\"\"\"\n",
    "\n",
    "    #get all unique values in col\n",
    "    col_vals = df[column_name].unique()\n",
    "\n",
    "    split = [df[df[column_name] == value] for value in col_vals]\n",
    "    \n",
    "    #Return the list of split dataframes\n",
    "    return split\n",
    "\n",
    "#use the new function to split the original sentences df \n",
    "splitted_df = split_df(sentences_df, 'year')\n",
    "\n",
    "#print each of the DFs\n",
    "for df_year_data in splitted_df:\n",
    "    display(df_year_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(max_features= 1000, lowercase=False, tokenizer=False)\n",
    "def fake(token):\n",
    "    return token\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=fake,\n",
    "    preprocessor=fake,\n",
    "    token_pattern=None)  \n",
    "\n",
    "#X_train = tfidf.fit_transform(X_train)\n",
    "#X_test = tfidf.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV Packages - this still needs changing and fitting into the LR function!\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# parameter grid\n",
    "parameters = {\"penalty\": ['l1','l2'], \n",
    "              \"C\": np.logspace(-3,3,7),\n",
    "              \"solver\": ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "}\n",
    "\n",
    "#GridSearchCV\n",
    "logreg = LogisticRegression()\n",
    "clf_logreg = GridSearchCV(logreg, \n",
    "                          param_grid = parameters, \n",
    "                          scoring = \"accuracy\", \n",
    "                          cv = 10)\n",
    "\n",
    "clf_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Classifier by Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_year(df, target_col, text_col, year_col):\n",
    "    years = df[year_col].unique()\n",
    "    results = {}\n",
    "\n",
    "    #split data \n",
    "    for year in years:\n",
    "        df_year = df.loc[df[year_col]==year].copy()\n",
    "        df_year['text'] = df_year[text_col].apply(lambda x: ' '.join(map(str, x)))\n",
    "        X = df_year[text_col].apply(lambda x: str(x))\n",
    "        y = df_year[target_col]\n",
    "\n",
    "    #train test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        tfidf = TfidfVectorizer()\n",
    "        X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "        X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    #run the classifier \n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(X_train_tfidf, y_train)\n",
    "        y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "    #performance \n",
    "        accuracy = clf.score(X_test_tfidf, y_test)\n",
    "        class_report = classification_report(y_test, y_pred, zero_division = 0)\n",
    "        results[year] = {'accuracy': accuracy, 'classification_report': class_report}\n",
    "        print(f\"Year: {year}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Classification Report:\\n{class_report}\")\n",
    "\n",
    "        #coefficients\n",
    "        coefs = clf.coef_[0]\n",
    "        sorted_coef = sorted((zip(tfidf.get_feature_names_out(), coefs)), key = lambda x: x[1], reverse=True)\n",
    "        high_coef = sorted_coef[:5]\n",
    "        low_coef = sorted_coef[-5:]\n",
    "        \n",
    "\n",
    "        #print coefficient results \n",
    "        print(f\"\\n Highest coefs:\")\n",
    "        for i in high_coef: \n",
    "            print(i)\n",
    "        \n",
    "        print(f\"\\n Lowest coefs:\")\n",
    "        for i in low_coef: \n",
    "            print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_year(sentences_df, 'col_type', 'encoded_sentences', 'year')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
