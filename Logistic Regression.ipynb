{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/yolandaferreirofranchi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics \n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_processed_sent</th>\n",
       "      <th>male_count</th>\n",
       "      <th>female_count</th>\n",
       "      <th>apicall_fail</th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[break, silence, surround, break, say, band, l...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Liam Gallagher has broken the silence surround...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[however, interview, say, longer]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>However, in an interview with The Times Liam G...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[leave, band, follow, bust, say, simply, could...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Noel Gallagher left the Manchester band follow...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[launch, clothing, line, earlier, year, admit,...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Liam launched his clothing line Pretty Green ...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[people, able, buy, record]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"People will be able to buy his records.</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9706</th>\n",
       "      <td>[organisers, say, extend, programme, live, tou...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Organisers of the X Factor have said they've e...</td>\n",
       "      <td>1043733</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9707</th>\n",
       "      <td>[vote, judge, week, seven, competition]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jedward were voted off by the X Factor judges ...</td>\n",
       "      <td>1043733</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9708</th>\n",
       "      <td>[two, month, tour, begin, see, extra, date, add]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The two month tour, which begins in Liverpool ...</td>\n",
       "      <td>1043733</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9709</th>\n",
       "      <td>[artists, confirm, tour, contestant]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Artists confirmed for the tour are contestants...</td>\n",
       "      <td>1043733</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9711</th>\n",
       "      <td>[pmliverpool, pmbirmingham, pmbirmingham, pmbi...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Liverpool Arena - 15 February - 7.30pmLiverpoo...</td>\n",
       "      <td>1043733</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3327 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     pre_processed_sent  male_count  \\\n",
       "0     [break, silence, surround, break, say, band, l...           3   \n",
       "1                     [however, interview, say, longer]           2   \n",
       "9     [leave, band, follow, bust, say, simply, could...           4   \n",
       "10    [launch, clothing, line, earlier, year, admit,...           3   \n",
       "13                          [people, able, buy, record]           1   \n",
       "...                                                 ...         ...   \n",
       "9706  [organisers, say, extend, programme, live, tou...           2   \n",
       "9707            [vote, judge, week, seven, competition]           1   \n",
       "9708   [two, month, tour, begin, see, extra, date, add]           3   \n",
       "9709               [artists, confirm, tour, contestant]           2   \n",
       "9711  [pmliverpool, pmbirmingham, pmbirmingham, pmbi...           1   \n",
       "\n",
       "      female_count  apicall_fail  \\\n",
       "0                0             0   \n",
       "1                0             0   \n",
       "9                0             0   \n",
       "10               0             0   \n",
       "13               0             0   \n",
       "...            ...           ...   \n",
       "9706             0             0   \n",
       "9707             0             0   \n",
       "9708             0             0   \n",
       "9709             1             0   \n",
       "9711             4             0   \n",
       "\n",
       "                                              sentences  article_id  year  \\\n",
       "0     Liam Gallagher has broken the silence surround...        5048  2009   \n",
       "1     However, in an interview with The Times Liam G...        5048  2009   \n",
       "9     Noel Gallagher left the Manchester band follow...        5048  2009   \n",
       "10    \"Liam launched his clothing line Pretty Green ...        5048  2009   \n",
       "13             \"People will be able to buy his records.        5048  2009   \n",
       "...                                                 ...         ...   ...   \n",
       "9706  Organisers of the X Factor have said they've e...     1043733  2009   \n",
       "9707  Jedward were voted off by the X Factor judges ...     1043733  2009   \n",
       "9708  The two month tour, which begins in Liverpool ...     1043733  2009   \n",
       "9709  Artists confirmed for the tour are contestants...     1043733  2009   \n",
       "9711  Liverpool Arena - 15 February - 7.30pmLiverpoo...     1043733  2009   \n",
       "\n",
       "     col_type  \n",
       "0           0  \n",
       "1           0  \n",
       "9           0  \n",
       "10          0  \n",
       "13          0  \n",
       "...       ...  \n",
       "9706        0  \n",
       "9707        0  \n",
       "9708        0  \n",
       "9709        0  \n",
       "9711        1  \n",
       "\n",
       "[3327 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pre-processed data from pickle \n",
    "df_09= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis/sample_results_df_09.pickle\")\n",
    "df_09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO NEED FOR THIS ANYMORE GIVEN PP\n",
    "def split_df(df, column_name): \n",
    "    \"\"\"Split Sentences DF by the year column so that we can do the LR by year\"\"\"\n",
    "\n",
    "    #get all unique values in col\n",
    "    col_vals = df[column_name].unique()\n",
    "\n",
    "    split = [df[df[column_name] == value] for value in col_vals]\n",
    "    \n",
    "    #Return the list of split dataframes\n",
    "    return split\n",
    "\n",
    "#use the new function to split the original sentences df \n",
    "splitted_df = split_df(sentences_df, 'year')\n",
    "\n",
    "#print each of the DFs\n",
    "for df_year_data in splitted_df:\n",
    "    display(df_year_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(max_features= 1000, lowercase=False, tokenizer=False)\n",
    "def fake(token):\n",
    "    return token\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=fake,\n",
    "    preprocessor=fake,\n",
    "    token_pattern=None)  \n",
    "\n",
    "#X_train = tfidf.fit_transform(X_train)\n",
    "#X_test = tfidf.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV Packages - this still needs changing and fitting into the LR function!\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# parameter grid\n",
    "parameters = {\"penalty\": ['l1','l2'], \n",
    "              \"C\": np.logspace(-3,3,7),\n",
    "              \"solver\": ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "}\n",
    "\n",
    "#GridSearchCV\n",
    "logreg = LogisticRegression()\n",
    "clf_logreg = GridSearchCV(logreg, \n",
    "                          param_grid = parameters, \n",
    "                          scoring = \"accuracy\", \n",
    "                          cv = 10)\n",
    "\n",
    "clf_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Classifier by Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_year(df, target_col, text_col):\n",
    "    #split data \n",
    "    X = df[text_col].apply(lambda x: str(x))\n",
    "    y = df[target_col]\n",
    "\n",
    "    #train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    #run the classifier \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "    #performance \n",
    "    accuracy = clf.score(X_test_tfidf, y_test)\n",
    "    class_report = classification_report(y_test, y_pred, zero_division = 0)\n",
    "    results = {'accuracy': accuracy, 'classification_report': class_report}\n",
    "    #print(f\"Year: {year}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Classification Report:\\n{class_report}\")\n",
    "\n",
    "        #coefficients\n",
    "    coefs = clf.coef_[0]\n",
    "    sorted_coef = sorted((zip(tfidf.get_feature_names_out(), coefs)), key = lambda x: x[1], reverse=True)\n",
    "    high_coef = sorted_coef[:10]\n",
    "    low_coef = sorted_coef[-10:]\n",
    "        \n",
    "\n",
    "        #print coefficient results \n",
    "    print(f\"\\n Highest coefs:\")\n",
    "    for i in high_coef: \n",
    "        print(i)\n",
    "        \n",
    "    print(f\"\\n Lowest coefs:\")\n",
    "    for i in low_coef: \n",
    "        print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6801801801801802\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.91      0.78       418\n",
      "           1       0.66      0.29      0.40       248\n",
      "\n",
      "    accuracy                           0.68       666\n",
      "   macro avg       0.67      0.60      0.59       666\n",
      "weighted avg       0.68      0.68      0.64       666\n",
      "\n",
      "\n",
      " Highest coefs:\n",
      "('say', 2.7058098234812835)\n",
      "('newsbeat', 1.625300425913965)\n",
      "('really', 1.5431860499940846)\n",
      "('time', 1.4287925439957982)\n",
      "('add', 1.3693210892807677)\n",
      "('cool', 1.3223848060170107)\n",
      "('end', 1.2985914543875967)\n",
      "('winner', 1.2865737872946597)\n",
      "('pregnant', 1.2502019510388829)\n",
      "('feel', 1.225859452412414)\n",
      "\n",
      " Lowest coefs:\n",
      "('festival', -1.0237310431052795)\n",
      "('game', -1.074189310079536)\n",
      "('travel', -1.0757708610895875)\n",
      "('british', -1.09962095953621)\n",
      "('film', -1.1014707485611273)\n",
      "('forthcoming', -1.147294793064275)\n",
      "('country', -1.1637579011533543)\n",
      "('hold', -1.2145405069367237)\n",
      "('include', -1.3823713793188768)\n",
      "('band', -1.413947421737034)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_year(df_09, 'col_type', 'pre_processed_sent')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
