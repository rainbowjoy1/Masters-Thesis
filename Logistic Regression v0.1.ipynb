{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/yolandaferreirofranchi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15825 entries, 0 to 15824\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   index              15825 non-null  int64 \n",
      " 1   tags               1 non-null      object\n",
      " 2   title              15825 non-null  object\n",
      " 3   news_post_date     15825 non-null  object\n",
      " 4   raw_content        15468 non-null  object\n",
      " 5   content            15468 non-null  object\n",
      " 6   url                15825 non-null  object\n",
      " 7   author             1453 non-null   object\n",
      " 8   language           15825 non-null  object\n",
      " 9   id                 15825 non-null  object\n",
      " 10  region             15488 non-null  object\n",
      " 11  short_description  15825 non-null  object\n",
      " 12  category           15825 non-null  object\n",
      " 13  crawled_at         15825 non-null  object\n",
      " 14  Article_Number     15825 non-null  int64 \n",
      "dtypes: int64(2), object(13)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#Json file option\n",
    "#filejson = \"C:/Users/danie/Desktop/bbc_news_list_uk.json\"\n",
    "#filecsv = r\"C:\\Users\\danie\\Documents\\GitHub\\Masters-Thesis\\bbc_news_list_uk.csv\"\n",
    "filecsv = r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis/bbc_news_list_uk.csv\"\n",
    "article_df = pd.read_csv(filecsv)\n",
    "article_df = article_df.assign(Article_Number=range(len(article_df)))\n",
    "article_df = article_df.reset_index()\n",
    "article_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code assumes the first four digits are the year. can be changed for last of middle\n",
    "year = article_df['news_post_date'].str[:4]\n",
    "article_df['year']=year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'articles.pkl'\n",
    "\n",
    "#article_df = pd.read_pickle(filename)\n",
    "#article_df = article_df.assign(Article_Number=range(len(article_df)))\n",
    "#article_df = article_df.reset_index()\n",
    "#article_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize sentences in an article \n",
    "import re\n",
    "\n",
    "def split_sentences(article, article_id, year):\n",
    "    pattern = r'(?<=[a-z0-9\"]) *[.?!] *(?=[A-Z])'\n",
    "    article = re.sub(pattern, r'\\g<0> ', article)\n",
    "    sentences = nltk.sent_tokenize(article)\n",
    "    sentences_with_id = [(sentence, article_id, year) for sentence in sentences]\n",
    "    return sentences_with_id\n",
    "\n",
    "sentences_list = []\n",
    "\n",
    "# add sentences to a new DF along with article ID \n",
    "for article, article_id, year in article_df[['content','Article_Number', 'year']].values:\n",
    "    sentences = split_sentences(str(article), article_id, year)\n",
    "    sentences_list.extend(sentences)\n",
    "\n",
    "sentences_df = pd.DataFrame(sentences_list, columns= ['sentences', 'article_id', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronoun_occurances(text):\n",
    "    \"\"\" This function will count the number of female and male pronoun occurences in a given sentence.\"\"\"\n",
    "    pattern_m = r'(\\s|^)([\"\\']?)(he|his|him|he\\'s|hes)\\2\\b' #this regex will capture he/his as standalone words within a string but also at beginning of sentence\n",
    "    matches_m = re.findall(pattern_m, text, re.IGNORECASE) #IGNORECASE is necessary to make sure that it picks up the pronouns at the beginning of a sentence\n",
    "    pattern_f = r'(\\s|^)([\"\\']?)(she|her|hers|shes|she\\'s)\\2\\b'\n",
    "    matches_f = re.findall(pattern_f, text, re.IGNORECASE)\n",
    "    #pattern_n = r'(\\s|^|\")([\"\\']?)(they|them|their|theirs|their\\'s)\\2\\b' #\n",
    "    #matches_n = re.findall(pattern_n, text, re.IGNORECASE)\n",
    "    count_m = len(matches_m)\n",
    "    count_f = len(matches_f)\n",
    "    #count_n = len(matches_n)\n",
    "    #count_u = count_n + count_f + count_m\n",
    "    return count_f, count_m #, count_n, count_u"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reporting_words = [\"acknowledge\", \" add\", \" address\", \" admit\", \" announce\", \" argue\", \" believe\", \" claim\", \" conclude\", \" confirm\", \" continue\", \" declare\", \" describe\", \" ensure\", \" estimate\", \" explain\", \" find\", \" indicate\", \" inform\", \" insist\", \" note\", \" point\", \" predict\", \" provide\", \" release\", \" reply\", \" report\", \" respond\", \" say\", \" state\", \" suggest\", \" tell\", \" testify\", \" think\", \" tweet\", \" warn\", \" write\"]\n",
    "\n",
    " If sent contains a reporting word then\n",
    "    look to the word before for a name or a pronoun\n",
    "        If found and a name find gender \n",
    "            once gender is found clasify the sentence\n",
    "        if found a pronoun then classify sentence\n",
    "        else   \n",
    "            look after the word for the same and follow the same pattern\n",
    "                else follow the rest of the pattern\n",
    "Count the number of male, female, and neutral pronouns\n",
    "\n",
    "*****Look to see if the sentence contains a proper noun and add the gender to the ocunt\n",
    "    I think this should be added to the preprocessing because we are already looking up the POS tags so it will use less bullshit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>female_count</th>\n",
       "      <th>male_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The heroin substitute methadone can be used as...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earlier this year a debate broke out in Scotla...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But a group of 40 specialists, including unive...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So what do recovering addicts think?</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris used methadone for five years to help we...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225660</th>\n",
       "      <td>Similar moves in Europe have sparked cries of ...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225661</th>\n",
       "      <td>The lead in the Daily Mail is a claim that cou...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225662</th>\n",
       "      <td>It says authorities are using the information ...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225663</th>\n",
       "      <td>The Daily Express leads with a warning from US...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225664</th>\n",
       "      <td>But the paper says cancer experts in the UK ha...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225665 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentences  article_id  year  \\\n",
       "0       The heroin substitute methadone can be used as...           0  2010   \n",
       "1       Earlier this year a debate broke out in Scotla...           0  2010   \n",
       "2       But a group of 40 specialists, including unive...           0  2010   \n",
       "3                    So what do recovering addicts think?           0  2010   \n",
       "4       Chris used methadone for five years to help we...           0  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "225660  Similar moves in Europe have sparked cries of ...       15824  2010   \n",
       "225661  The lead in the Daily Mail is a claim that cou...       15824  2010   \n",
       "225662  It says authorities are using the information ...       15824  2010   \n",
       "225663  The Daily Express leads with a warning from US...       15824  2010   \n",
       "225664  But the paper says cancer experts in the UK ha...       15824  2010   \n",
       "\n",
       "        female_count  male_count  \n",
       "0                  0           0  \n",
       "1                  0           0  \n",
       "2                  0           0  \n",
       "3                  0           0  \n",
       "4                  0           3  \n",
       "...              ...         ...  \n",
       "225660             0           0  \n",
       "225661             0           0  \n",
       "225662             0           0  \n",
       "225663             0           0  \n",
       "225664             0           0  \n",
       "\n",
       "[225665 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a variable applying the function of pronoun occurence\n",
    "sent = sentences_df['sentences'].apply(pronoun_occurances)\n",
    "# Create two new columns in sentences DF from the tuple output in \"sent\"\n",
    "sentences_df['female_count'] = [x[0] for x in sent]\n",
    "sentences_df['male_count']= [x[1] for x in sent]\n",
    "#sentences_df['neutral_count']= [x[2] for x in sent]\n",
    "#sentences_df['u_count']= [x[3] for x in sent]\n",
    "\n",
    "#Bug is fixed and now it counts properly\n",
    "sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>female_count</th>\n",
       "      <th>male_count</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The heroin substitute methadone can be used as...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earlier this year a debate broke out in Scotla...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But a group of 40 specialists, including unive...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So what do recovering addicts think?</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris used methadone for five years to help we...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225660</th>\n",
       "      <td>Similar moves in Europe have sparked cries of ...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225661</th>\n",
       "      <td>The lead in the Daily Mail is a claim that cou...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225662</th>\n",
       "      <td>It says authorities are using the information ...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225663</th>\n",
       "      <td>The Daily Express leads with a warning from US...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225664</th>\n",
       "      <td>But the paper says cancer experts in the UK ha...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225665 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentences  article_id  year  \\\n",
       "0       The heroin substitute methadone can be used as...           0  2010   \n",
       "1       Earlier this year a debate broke out in Scotla...           0  2010   \n",
       "2       But a group of 40 specialists, including unive...           0  2010   \n",
       "3                    So what do recovering addicts think?           0  2010   \n",
       "4       Chris used methadone for five years to help we...           0  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "225660  Similar moves in Europe have sparked cries of ...       15824  2010   \n",
       "225661  The lead in the Daily Mail is a claim that cou...       15824  2010   \n",
       "225662  It says authorities are using the information ...       15824  2010   \n",
       "225663  The Daily Express leads with a warning from US...       15824  2010   \n",
       "225664  But the paper says cancer experts in the UK ha...       15824  2010   \n",
       "\n",
       "        female_count  male_count col_type  \n",
       "0                  0           0     None  \n",
       "1                  0           0     None  \n",
       "2                  0           0     None  \n",
       "3                  0           0     None  \n",
       "4                  0           3        1  \n",
       "...              ...         ...      ...  \n",
       "225660             0           0     None  \n",
       "225661             0           0     None  \n",
       "225662             0           0     None  \n",
       "225663             0           0     None  \n",
       "225664             0           0     None  \n",
       "\n",
       "[225665 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_count(male_col, female_col): \n",
    "    \"\"\"This function compares the count of female to male pronouns. It will output \"1\" if male count bigger\n",
    "    than female count, \"neutral\" if the count is equal, and \"female\" if there is a higher female count. \n",
    "    The function returns strings because we need categorical variables for log reg to run\"\"\"\n",
    "    if female_col > male_col:\n",
    "        return \"0\"\n",
    "    elif male_col > female_col:\n",
    "        return \"1\"\n",
    "    else: \n",
    "        return None\n",
    "sentences_df['col_type'] = sentences_df.apply(lambda row: compare_count(row['male_count'], row['female_count']),axis=1)\n",
    "sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns with \"None\" in the col_type \n",
    "sentences_df = sentences_df[sentences_df[\"col_type\"].notnull()]\n",
    "#sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>female_count</th>\n",
       "      <th>male_count</th>\n",
       "      <th>col_type</th>\n",
       "      <th>encoded_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175442</th>\n",
       "      <td>Mrs Jones previously admitted failing to notif...</td>\n",
       "      <td>12116</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[previously, admit, fail, notify, council, par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60832</th>\n",
       "      <td>She also said that she had cut her mother's na...</td>\n",
       "      <td>4004</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[She, also, say, cut, mother, nail, hospital, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23016</th>\n",
       "      <td>In her appeal, she claimed she only pleaded gu...</td>\n",
       "      <td>1339</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[In, appeal, claim, plead, guilty, former, sol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46585</th>\n",
       "      <td>\"She left her job, she left someone in her fla...</td>\n",
       "      <td>2967</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[She, leave, job, leave, someone, flat, go, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17800</th>\n",
       "      <td>I even made her do one in her bikini - which s...</td>\n",
       "      <td>971</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, even, make, one, bikini, sound, kind, dodg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86076</th>\n",
       "      <td>The Telegraph quotes PR experts who say Green ...</td>\n",
       "      <td>5777</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, quote, expert, say, capitalise, misfortu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86090</th>\n",
       "      <td>Many economists also believe that the previous...</td>\n",
       "      <td>5778</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Many, economist, also, believe, previous, cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86143</th>\n",
       "      <td>He is in a state of deep shock after his house...</td>\n",
       "      <td>5781</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[He, state, deep, shock, house, outskirt, burn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86144</th>\n",
       "      <td>Anwar doesn't know where his wife and children...</td>\n",
       "      <td>5781</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[know, wife, child, saw, neighbour, shoot, dead]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225652</th>\n",
       "      <td>For him, it is an attempt to redefine voluntar...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[For, attempt, redefine, voluntary, work, deep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49408 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentences  article_id  year  \\\n",
       "175442  Mrs Jones previously admitted failing to notif...       12116  2010   \n",
       "60832   She also said that she had cut her mother's na...        4004  2010   \n",
       "23016   In her appeal, she claimed she only pleaded gu...        1339  2010   \n",
       "46585   \"She left her job, she left someone in her fla...        2967  2010   \n",
       "17800   I even made her do one in her bikini - which s...         971  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "86076   The Telegraph quotes PR experts who say Green ...        5777  2010   \n",
       "86090   Many economists also believe that the previous...        5778  2010   \n",
       "86143   He is in a state of deep shock after his house...        5781  2010   \n",
       "86144   Anwar doesn't know where his wife and children...        5781  2010   \n",
       "225652  For him, it is an attempt to redefine voluntar...       15824  2010   \n",
       "\n",
       "        female_count  male_count col_type  \\\n",
       "175442             7           1        0   \n",
       "60832              7           0        0   \n",
       "23016              7           1        0   \n",
       "46585              7           1        0   \n",
       "17800              6           0        0   \n",
       "...              ...         ...      ...   \n",
       "86076              0           2        1   \n",
       "86090              0           1        1   \n",
       "86143              0           2        1   \n",
       "86144              0           2        1   \n",
       "225652             0           1        1   \n",
       "\n",
       "                                        encoded_sentences  \n",
       "175442  [previously, admit, fail, notify, council, par...  \n",
       "60832   [She, also, say, cut, mother, nail, hospital, ...  \n",
       "23016   [In, appeal, claim, plead, guilty, former, sol...  \n",
       "46585   [She, leave, job, leave, someone, flat, go, se...  \n",
       "17800   [I, even, make, one, bikini, sound, kind, dodg...  \n",
       "...                                                   ...  \n",
       "86076   [The, quote, expert, say, capitalise, misfortu...  \n",
       "86090   [Many, economist, also, believe, previous, cha...  \n",
       "86143     [He, state, deep, shock, house, outskirt, burn]  \n",
       "86144    [know, wife, child, saw, neighbour, shoot, dead]  \n",
       "225652  [For, attempt, redefine, voluntary, work, deep...  \n",
       "\n",
       "[49408 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df.sort_values(\"female_count\", ascending = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 - female \n",
    "1 - male"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifier Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "from genderize import Genderize\n",
    "\n",
    "#Sentence Encoding\n",
    "def tidy_text(sentence, remove_stopwords = True):\n",
    "\n",
    "    sentence = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', sentence)\n",
    "    sentence = re.sub(r'\\<a href', ' ', sentence)\n",
    "    sentence = re.sub(r'&amp;', '', sentence) \n",
    "    sentence = re.sub(\"\\d+\", \"\", sentence)\n",
    "    \n",
    "    #changed the number detection code\n",
    "    sentence = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', sentence)\n",
    "    sentence = re.sub(r'<br />', ' ', sentence)\n",
    "    sentence = re.sub(r'\\'', ' ', sentence)\n",
    "\n",
    "    # Tokenize each word\n",
    "    sentence =  nltk.WordPunctTokenizer().tokenize(sentence)\n",
    "\n",
    "    #! I think this is where the gender words detection should go, because we can do it after tokenization and then it's more efficiant\n",
    "    #we also have a bit of a plural problem. we need to take care of. Also the words need to be removed--maybe at the end? \n",
    "    #so this function here will return a male, female count \n",
    "\n",
    "    nltk.tag.pos_tag(sentence)\n",
    "    tagged_sentence = nltk.tag.pos_tag(sentence)\n",
    "    lemma = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "    pn_tags = ('NNP', 'NNPS')\n",
    "    new_words = []\n",
    "\n",
    "    for word, tag in tagged_sentence: \n",
    "        if tag not in pn_tags: \n",
    "            if tag.startswith(\"V\"):\n",
    "                lemmas = lemma.lemmatize(word, \"v\")\n",
    "            else: \n",
    "                lemmas = lemma.lemmatize(word)\n",
    "            \n",
    "            new_words.append((lemmas))\n",
    "        #!# We need to add an else statement here to process PN words, there could be some trickyness here but it should be fine. \n",
    "        #else:\n",
    "            #gender = Genderize().get(word)\n",
    "            #reteurns 'male' and 'female' \n",
    "                #if gender = 'male'\n",
    "                 #   malelistcount add 1\n",
    "                #if gender = 'female'\n",
    "                 #   femalelistcount add 1\n",
    "\n",
    "\n",
    "    sentence = new_words\n",
    "\n",
    "    # Expand contractions\n",
    "    if True:\n",
    "        new_text = []\n",
    "        for word in sentence:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "    \n",
    "    \n",
    "    # remove stopwords\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        sentence = [w for w in sentence if not w in stops]\n",
    "\n",
    "    #!  here we check for words from the gender words and we ensure they are removed from the tokens. this will ensure we have 0 leakage\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "#text = \"I ate a sandwich and it was very tasty\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/r571pkwj6973dlq1m_v76wp40000gn/T/ipykernel_3227/3263154823.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentences_df['encoded_sentences'] = sentences_df['sentences'].apply(tidy_text)\n"
     ]
    }
   ],
   "source": [
    "sentences_df['encoded_sentences'] = sentences_df['sentences'].apply(tidy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>female_count</th>\n",
       "      <th>male_count</th>\n",
       "      <th>col_type</th>\n",
       "      <th>encoded_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris used methadone for five years to help we...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[use, methadone, five, year, help, wean, heroi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"I heard about Ratho Hall, and it's given me t...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, hear, give, wake, call, I, need, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chris was prescribed methadone, a synthetic op...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[prescribe, methadone, synthetic, opiate, take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>In this, the Community Safety Minister, Fergus...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[In, explain, want, see, new, vision, drug, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chris, who started to use heroin when he was 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[start, use, heroin, talk, addiction, When, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225598</th>\n",
       "      <td>\"For Diego, it is good for him to see the norm...</td>\n",
       "      <td>15819</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[For, good, see, normal, rearing, process, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225601</th>\n",
       "      <td>The new monkey will stay at the zoo until he r...</td>\n",
       "      <td>15819</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, new, monkey, stay, zoo, reach, sexual, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225605</th>\n",
       "      <td>He died in hospital.</td>\n",
       "      <td>15820</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[He, die, hospital]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225645</th>\n",
       "      <td>He said: \"Local authorities need to recognise ...</td>\n",
       "      <td>15823</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[He, say, authority, need, recognise, regional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225652</th>\n",
       "      <td>For him, it is an attempt to redefine voluntar...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[For, attempt, redefine, voluntary, work, deep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49408 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentences  article_id  year  \\\n",
       "4       Chris used methadone for five years to help we...           0  2010   \n",
       "6       \"I heard about Ratho Hall, and it's given me t...           0  2010   \n",
       "7       Chris was prescribed methadone, a synthetic op...           0  2010   \n",
       "12      In this, the Community Safety Minister, Fergus...           0  2010   \n",
       "14      Chris, who started to use heroin when he was 1...           0  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "225598  \"For Diego, it is good for him to see the norm...       15819  2010   \n",
       "225601  The new monkey will stay at the zoo until he r...       15819  2010   \n",
       "225605                               He died in hospital.       15820  2010   \n",
       "225645  He said: \"Local authorities need to recognise ...       15823  2010   \n",
       "225652  For him, it is an attempt to redefine voluntar...       15824  2010   \n",
       "\n",
       "        female_count  male_count col_type  \\\n",
       "4                  0           3        1   \n",
       "6                  0           1        1   \n",
       "7                  0           2        1   \n",
       "12                 0           1        1   \n",
       "14                 0           2        1   \n",
       "...              ...         ...      ...   \n",
       "225598             0           2        1   \n",
       "225601             0           3        1   \n",
       "225605             0           1        1   \n",
       "225645             0           1        1   \n",
       "225652             0           1        1   \n",
       "\n",
       "                                        encoded_sentences  \n",
       "4       [use, methadone, five, year, help, wean, heroi...  \n",
       "6               [I, hear, give, wake, call, I, need, say]  \n",
       "7       [prescribe, methadone, synthetic, opiate, take...  \n",
       "12      [In, explain, want, see, new, vision, drug, tr...  \n",
       "14      [start, use, heroin, talk, addiction, When, he...  \n",
       "...                                                   ...  \n",
       "225598  [For, good, see, normal, rearing, process, wit...  \n",
       "225601  [The, new, monkey, stay, zoo, reach, sexual, m...  \n",
       "225605                                [He, die, hospital]  \n",
       "225645  [He, say, authority, need, recognise, regional...  \n",
       "225652  [For, attempt, redefine, voluntary, work, deep...  \n",
       "\n",
       "[49408 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the DF by Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>female_count</th>\n",
       "      <th>male_count</th>\n",
       "      <th>col_type</th>\n",
       "      <th>encoded_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris used methadone for five years to help we...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[use, methadone, five, year, help, wean, heroi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"I heard about Ratho Hall, and it's given me t...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, hear, give, wake, call, I, need, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chris was prescribed methadone, a synthetic op...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[prescribe, methadone, synthetic, opiate, take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>In this, the Community Safety Minister, Fergus...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[In, explain, want, see, new, vision, drug, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chris, who started to use heroin when he was 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[start, use, heroin, talk, addiction, When, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225598</th>\n",
       "      <td>\"For Diego, it is good for him to see the norm...</td>\n",
       "      <td>15819</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[For, good, see, normal, rearing, process, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225601</th>\n",
       "      <td>The new monkey will stay at the zoo until he r...</td>\n",
       "      <td>15819</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, new, monkey, stay, zoo, reach, sexual, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225605</th>\n",
       "      <td>He died in hospital.</td>\n",
       "      <td>15820</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[He, die, hospital]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225645</th>\n",
       "      <td>He said: \"Local authorities need to recognise ...</td>\n",
       "      <td>15823</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[He, say, authority, need, recognise, regional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225652</th>\n",
       "      <td>For him, it is an attempt to redefine voluntar...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[For, attempt, redefine, voluntary, work, deep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49384 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentences  article_id  year  \\\n",
       "4       Chris used methadone for five years to help we...           0  2010   \n",
       "6       \"I heard about Ratho Hall, and it's given me t...           0  2010   \n",
       "7       Chris was prescribed methadone, a synthetic op...           0  2010   \n",
       "12      In this, the Community Safety Minister, Fergus...           0  2010   \n",
       "14      Chris, who started to use heroin when he was 1...           0  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "225598  \"For Diego, it is good for him to see the norm...       15819  2010   \n",
       "225601  The new monkey will stay at the zoo until he r...       15819  2010   \n",
       "225605                               He died in hospital.       15820  2010   \n",
       "225645  He said: \"Local authorities need to recognise ...       15823  2010   \n",
       "225652  For him, it is an attempt to redefine voluntar...       15824  2010   \n",
       "\n",
       "        female_count  male_count col_type  \\\n",
       "4                  0           3        1   \n",
       "6                  0           1        1   \n",
       "7                  0           2        1   \n",
       "12                 0           1        1   \n",
       "14                 0           2        1   \n",
       "...              ...         ...      ...   \n",
       "225598             0           2        1   \n",
       "225601             0           3        1   \n",
       "225605             0           1        1   \n",
       "225645             0           1        1   \n",
       "225652             0           1        1   \n",
       "\n",
       "                                        encoded_sentences  \n",
       "4       [use, methadone, five, year, help, wean, heroi...  \n",
       "6               [I, hear, give, wake, call, I, need, say]  \n",
       "7       [prescribe, methadone, synthetic, opiate, take...  \n",
       "12      [In, explain, want, see, new, vision, drug, tr...  \n",
       "14      [start, use, heroin, talk, addiction, When, he...  \n",
       "...                                                   ...  \n",
       "225598  [For, good, see, normal, rearing, process, wit...  \n",
       "225601  [The, new, monkey, stay, zoo, reach, sexual, m...  \n",
       "225605                                [He, die, hospital]  \n",
       "225645  [He, say, authority, need, recognise, regional...  \n",
       "225652  [For, attempt, redefine, voluntary, work, deep...  \n",
       "\n",
       "[49384 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>female_count</th>\n",
       "      <th>male_count</th>\n",
       "      <th>col_type</th>\n",
       "      <th>encoded_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21436</th>\n",
       "      <td>One woman is quoted as saying the gangsters th...</td>\n",
       "      <td>1230</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[One, woman, quote, say, gangster, threaten, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21438</th>\n",
       "      <td>He has also called for the criminals to be tra...</td>\n",
       "      <td>1230</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[He, also, call, criminal, track, punish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85224</th>\n",
       "      <td>However, Mr Fico said that he would still try ...</td>\n",
       "      <td>5717</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[However, say, would, still, try, form, govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85225</th>\n",
       "      <td>Referring to his party's 63 seats, he said: \"T...</td>\n",
       "      <td>5717</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[Referring, party, seat, say, This, number, gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85232</th>\n",
       "      <td>\"The citizens of Slovakia have voted for respo...</td>\n",
       "      <td>5717</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[The, citizen, vote, responsibility, add]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85233</th>\n",
       "      <td>With partners Freedom and Solidarity, the Chri...</td>\n",
       "      <td>5717</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[With, partner, ethnic, party, party, enough, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85239</th>\n",
       "      <td>In a television address shortly before polls o...</td>\n",
       "      <td>5717</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[In, television, address, shortly, poll, open,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85241</th>\n",
       "      <td>\"Any mash-up is better than Fico,\" said SaS le...</td>\n",
       "      <td>5717</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Any, mash, better, say, leader, say, party, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85989</th>\n",
       "      <td>But President Ivan Gasparovic said he would gi...</td>\n",
       "      <td>5773</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[But, say, would, give, first, chance, form, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85990</th>\n",
       "      <td>Mr Gasparovic said he wanted to respect the tr...</td>\n",
       "      <td>5773</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[say, want, respect, tradition, give, leader, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85994</th>\n",
       "      <td>Referring to his party's 62 seats, he said: \"T...</td>\n",
       "      <td>5773</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[Referring, party, seat, say, This, number, gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86001</th>\n",
       "      <td>\"The citizens of Slovakia have voted for respo...</td>\n",
       "      <td>5773</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[The, citizen, vote, responsibility, add]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86002</th>\n",
       "      <td>With partners Freedom and Solidarity, the Chri...</td>\n",
       "      <td>5773</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[With, partner, ethnic, party, party, enough, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86007</th>\n",
       "      <td>In a television address shortly before polls o...</td>\n",
       "      <td>5773</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[In, television, address, shortly, poll, open,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86009</th>\n",
       "      <td>\"Any mash-up is better than Fico,\" said SaS le...</td>\n",
       "      <td>5773</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Any, mash, better, say, leader, say, party, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129380</th>\n",
       "      <td>Slovakia's president has asked a centre-right ...</td>\n",
       "      <td>8800</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[president, ask, centre, right, leader, form, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129385</th>\n",
       "      <td>\"I will do my best to make this a cabinet for ...</td>\n",
       "      <td>8800</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, best, make, cabinet, citizen, open, cabine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129387</th>\n",
       "      <td>If Ms Radicova succeeds in forming a governmen...</td>\n",
       "      <td>8800</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[If, succeed, form, government, would, become,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129388</th>\n",
       "      <td>Mr Fico told Mr Gasparovic that he was giving ...</td>\n",
       "      <td>8800</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[tell, give, morning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129389</th>\n",
       "      <td>\"I handed the designation back to the presiden...</td>\n",
       "      <td>8800</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, hand, designation, back, president, idea, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129391</th>\n",
       "      <td>His cabinet included anti-Hungarian nationalis...</td>\n",
       "      <td>8800</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[His, cabinet, include, anti, Hungarian, natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198173</th>\n",
       "      <td>She takes over from centre-left leader Robert ...</td>\n",
       "      <td>13733</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[She, take, centre, leave, leader, prime, mini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198175</th>\n",
       "      <td>\"We are fully aware of the fact the Slovakia, ...</td>\n",
       "      <td>13733</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[We, fully, aware, fact, like, many, state, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198178</th>\n",
       "      <td>The presence of an ethnic Hungarian politician...</td>\n",
       "      <td>13733</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, presence, ethnic, Hungarian, politician,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentences  article_id  year  \\\n",
       "21436   One woman is quoted as saying the gangsters th...        1230  2012   \n",
       "21438   He has also called for the criminals to be tra...        1230  2012   \n",
       "85224   However, Mr Fico said that he would still try ...        5717  2012   \n",
       "85225   Referring to his party's 63 seats, he said: \"T...        5717  2012   \n",
       "85232   \"The citizens of Slovakia have voted for respo...        5717  2012   \n",
       "85233   With partners Freedom and Solidarity, the Chri...        5717  2012   \n",
       "85239   In a television address shortly before polls o...        5717  2012   \n",
       "85241   \"Any mash-up is better than Fico,\" said SaS le...        5717  2012   \n",
       "85989   But President Ivan Gasparovic said he would gi...        5773  2012   \n",
       "85990   Mr Gasparovic said he wanted to respect the tr...        5773  2012   \n",
       "85994   Referring to his party's 62 seats, he said: \"T...        5773  2012   \n",
       "86001   \"The citizens of Slovakia have voted for respo...        5773  2012   \n",
       "86002   With partners Freedom and Solidarity, the Chri...        5773  2012   \n",
       "86007   In a television address shortly before polls o...        5773  2012   \n",
       "86009   \"Any mash-up is better than Fico,\" said SaS le...        5773  2012   \n",
       "129380  Slovakia's president has asked a centre-right ...        8800  2012   \n",
       "129385  \"I will do my best to make this a cabinet for ...        8800  2012   \n",
       "129387  If Ms Radicova succeeds in forming a governmen...        8800  2012   \n",
       "129388  Mr Fico told Mr Gasparovic that he was giving ...        8800  2012   \n",
       "129389  \"I handed the designation back to the presiden...        8800  2012   \n",
       "129391  His cabinet included anti-Hungarian nationalis...        8800  2012   \n",
       "198173  She takes over from centre-left leader Robert ...       13733  2012   \n",
       "198175  \"We are fully aware of the fact the Slovakia, ...       13733  2012   \n",
       "198178  The presence of an ethnic Hungarian politician...       13733  2012   \n",
       "\n",
       "        female_count  male_count col_type  \\\n",
       "21436              3           0        0   \n",
       "21438              0           1        1   \n",
       "85224              0           1        1   \n",
       "85225              0           2        1   \n",
       "85232              1           0        0   \n",
       "85233              1           0        0   \n",
       "85239              0           1        1   \n",
       "85241              0           1        1   \n",
       "85989              0           1        1   \n",
       "85990              0           1        1   \n",
       "85994              0           2        1   \n",
       "86001              1           0        0   \n",
       "86002              1           0        0   \n",
       "86007              0           1        1   \n",
       "86009              0           1        1   \n",
       "129380             0           1        1   \n",
       "129385             1           0        0   \n",
       "129387             1           0        0   \n",
       "129388             0           1        1   \n",
       "129389             0           1        1   \n",
       "129391             0           1        1   \n",
       "198173             1           0        0   \n",
       "198175             1           0        0   \n",
       "198178             0           1        1   \n",
       "\n",
       "                                        encoded_sentences  \n",
       "21436   [One, woman, quote, say, gangster, threaten, b...  \n",
       "21438           [He, also, call, criminal, track, punish]  \n",
       "85224   [However, say, would, still, try, form, govern...  \n",
       "85225   [Referring, party, seat, say, This, number, gi...  \n",
       "85232           [The, citizen, vote, responsibility, add]  \n",
       "85233   [With, partner, ethnic, party, party, enough, ...  \n",
       "85239   [In, television, address, shortly, poll, open,...  \n",
       "85241   [Any, mash, better, say, leader, say, party, w...  \n",
       "85989   [But, say, would, give, first, chance, form, g...  \n",
       "85990   [say, want, respect, tradition, give, leader, ...  \n",
       "85994   [Referring, party, seat, say, This, number, gi...  \n",
       "86001           [The, citizen, vote, responsibility, add]  \n",
       "86002   [With, partner, ethnic, party, party, enough, ...  \n",
       "86007   [In, television, address, shortly, poll, open,...  \n",
       "86009   [Any, mash, better, say, leader, say, party, w...  \n",
       "129380  [president, ask, centre, right, leader, form, ...  \n",
       "129385  [I, best, make, cabinet, citizen, open, cabine...  \n",
       "129387  [If, succeed, form, government, would, become,...  \n",
       "129388                              [tell, give, morning]  \n",
       "129389  [I, hand, designation, back, president, idea, ...  \n",
       "129391  [His, cabinet, include, anti, Hungarian, natio...  \n",
       "198173  [She, take, centre, leave, leader, prime, mini...  \n",
       "198175  [We, fully, aware, fact, like, many, state, st...  \n",
       "198178  [The, presence, ethnic, Hungarian, politician,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split_df(df, column_name): \n",
    "    \"\"\"Split Sentences DF by the year column so that we can do the LR by year\"\"\"\n",
    "\n",
    "    #get all unique values in col\n",
    "    col_vals = df[column_name].unique()\n",
    "\n",
    "    split = [df[df[column_name] == value] for value in col_vals]\n",
    "    \n",
    "    #Return the list of split dataframes\n",
    "    return split\n",
    "\n",
    "#use the new function to split the original sentences df \n",
    "splitted_df = split_df(sentences_df, 'year')\n",
    "\n",
    "#print each of the DFs\n",
    "for df_year_data in splitted_df:\n",
    "    display(df_year_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.get_dummies(sentences_df.year)\n",
    "#rated_dummies = pd.get_dummies((sentences_df).year)\n",
    "#sentences_df = pd.concat([sentences_df, rated_dummies], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(max_features= 1000, lowercase=False, tokenizer=False)\n",
    "def fake(token):\n",
    "    return token\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=fake,\n",
    "    preprocessor=fake,\n",
    "    token_pattern=None)  \n",
    "\n",
    "#X_train = tfidf.fit_transform(X_train)\n",
    "#X_test = tfidf.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV Packages - this still needs changing and fitting into the LR function!\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# parameter grid\n",
    "parameters = {\"penalty\": ['l1','l2'], \n",
    "              \"C\": np.logspace(-3,3,7),\n",
    "              \"solver\": ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "}\n",
    "\n",
    "#GridSearchCV\n",
    "logreg = LogisticRegression()\n",
    "clf_logreg = GridSearchCV(logreg, \n",
    "                          param_grid = parameters, \n",
    "                          scoring = \"accuracy\", \n",
    "                          cv = 10)\n",
    "\n",
    "clf_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Classifier by Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_year(df, target_col, text_col, year_col):\n",
    "    years = df[year_col].unique()\n",
    "    results = {}\n",
    "\n",
    "    #split data \n",
    "    for year in years:\n",
    "        df_year = df.loc[df[year_col]==year].copy()\n",
    "        df_year['text'] = df_year[text_col].apply(lambda x: ' '.join(map(str, x)))\n",
    "        X = df_year[text_col].apply(lambda x: str(x))\n",
    "        y = df_year[target_col]\n",
    "\n",
    "    #train test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        tfidf = TfidfVectorizer()\n",
    "        X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "        X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    #run the classifier \n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(X_train_tfidf, y_train)\n",
    "        y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "    #performance \n",
    "        accuracy = clf.score(X_test_tfidf, y_test)\n",
    "        class_report = classification_report(y_test, y_pred, zero_division = 0)\n",
    "        results[year] = {'accuracy': accuracy, 'classification_report': class_report}\n",
    "        print(f\"Year: {year}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Classification Report:\\n{class_report}\")\n",
    "\n",
    "        #coefficients\n",
    "        coefs = clf.coef_[0]\n",
    "        sorted_coef = sorted((zip(tfidf.get_feature_names_out(), coefs)), key = lambda x: x[1], reverse=True)\n",
    "        high_coef = sorted_coef[:5]\n",
    "        low_coef = sorted_coef[-5:]\n",
    "        \n",
    "\n",
    "        #print coefficient results \n",
    "        print(f\"\\n Highest coefs:\")\n",
    "        for i in high_coef: \n",
    "            print(i)\n",
    "        \n",
    "        print(f\"\\n Lowest coefs:\")\n",
    "        for i in low_coef: \n",
    "            print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2010\n",
      "Accuracy: 0.8566366305558368\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.40      0.55      2183\n",
      "           1       0.85      0.99      0.91      7694\n",
      "\n",
      "    accuracy                           0.86      9877\n",
      "   macro avg       0.87      0.69      0.73      9877\n",
      "weighted avg       0.86      0.86      0.83      9877\n",
      "\n",
      "\n",
      " Highest coefs:\n",
      "('he', 15.891551900218763)\n",
      "('his', 7.603456046330884)\n",
      "('man', 4.17082789968222)\n",
      "('wife', 3.5879416740474666)\n",
      "('soldier', 2.378104672128594)\n",
      "\n",
      " Lowest coefs:\n",
      "('girl', -5.560419224363694)\n",
      "('husband', -6.233141993018479)\n",
      "('woman', -7.343204828079678)\n",
      "('her', -9.555410225636514)\n",
      "('she', -18.592092822166705)\n",
      "Year: 2012\n",
      "Accuracy: 0.4\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.40         5\n",
      "   macro avg       0.20      0.50      0.29         5\n",
      "weighted avg       0.16      0.40      0.23         5\n",
      "\n",
      "\n",
      " Highest coefs:\n",
      "('say', 0.4121279131606606)\n",
      "('president', 0.24964302266496455)\n",
      "('cabinet', 0.2363522776710395)\n",
      "('right', 0.21604928573893997)\n",
      "('would', 0.2093362404217043)\n",
      "\n",
      " Lowest coefs:\n",
      "('enough', -0.3442155857271766)\n",
      "('majority', -0.3442155857271766)\n",
      "('parliamentary', -0.3442155857271766)\n",
      "('partner', -0.3442155857271766)\n",
      "('with', -0.3442155857271766)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_year(sentences_df, 'col_type', 'encoded_sentences', 'year')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary Logistics Regression (OLD VERSION)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finetuned model with best hyperparameters \n",
    "logreg1 = LogisticRegression(C=0.1, penalty = \"l2\", solver = \"liblinear\", max_iter = 5000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression(C = 0.1, penalty = \"l2\", solver = \"liblinear\", max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=5000, solver='liblinear')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_logreg = logreg1.fit(X_train, y_train)\n",
    "fitted_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = fitted_logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8390002023881805\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",fitted_logreg.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 is better to prevent overfitting than L1 because it punishes errors more (squares them as opposed to taking the absolute value). GridSearchCV said either L1 or L2 were equally as good though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest coefs\n",
      "('He', 7.497867226565254)\n",
      "('His', 2.791468567597014)\n",
      "('man', 1.7939417368758859)\n",
      "('wife', 1.2597679909365127)\n",
      "('shoot', 0.8793346468852085)\n",
      "('soldier', 0.8253443935307779)\n",
      "('security', 0.552288517084893)\n",
      "('general', 0.5360865508650358)\n",
      "('minister', 0.5225045885836616)\n",
      "('boy', 0.5212790475191019)\n",
      "lowest coefs\n",
      "('home', -0.8708266336604314)\n",
      "('actress', -1.0912651232977952)\n",
      "('child', -1.13564985240973)\n",
      "('daughter', -1.6608630837522824)\n",
      "('mother', -2.061830887374049)\n",
      "('girl', -2.2616077753072013)\n",
      "('husband', -2.5359911903913552)\n",
      "('woman', -3.8458811360803873)\n",
      "('Her', -3.9024438512883517)\n",
      "('She', -10.14035943687664)\n"
     ]
    }
   ],
   "source": [
    "coefs = fitted_logreg.coef_[0]\n",
    "\n",
    "#male is 1 and female is 0\n",
    "\n",
    "sorted_coef = sorted((zip(tfidf.get_feature_names(), coefs)), key = lambda x: x[1], reverse=True)\n",
    "\n",
    "high_coef = sorted_coef[:10]\n",
    "low_coef = sorted_coef[-10:]\n",
    "\n",
    "print(\"highest coefs\")\n",
    "for i in high_coef: \n",
    "    print(i)\n",
    "\n",
    "print(\"lowest coefs\")\n",
    "for i in low_coef: \n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, male coefficient for neutral is higher than the female. Otherwise, as expected, the coefficients for female and male each are correspondingly high for each gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8390002023881805\n",
      "[[ 559 1569]\n",
      " [  22 7732]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.26      0.41      2128\n",
      "           1       0.83      1.00      0.91      7754\n",
      "\n",
      "    accuracy                           0.84      9882\n",
      "   macro avg       0.90      0.63      0.66      9882\n",
      "weighted avg       0.86      0.84      0.80      9882\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, prediction)) #accuracy \n",
    "print(metrics.confusion_matrix(y_test, prediction)) #confusion matrix\n",
    "print(metrics.classification_report(y_test, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
