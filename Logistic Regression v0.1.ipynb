{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15825 entries, 0 to 15824\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   index              15825 non-null  int64 \n",
      " 1   tags               1 non-null      object\n",
      " 2   title              15825 non-null  object\n",
      " 3   news_post_date     15825 non-null  object\n",
      " 4   raw_content        15468 non-null  object\n",
      " 5   content            15468 non-null  object\n",
      " 6   url                15825 non-null  object\n",
      " 7   author             1453 non-null   object\n",
      " 8   language           15825 non-null  object\n",
      " 9   id                 15825 non-null  object\n",
      " 10  region             15488 non-null  object\n",
      " 11  short_description  15825 non-null  object\n",
      " 12  category           15825 non-null  object\n",
      " 13  crawled_at         15825 non-null  object\n",
      " 14  Article_Number     15825 non-null  int32 \n",
      "dtypes: int32(1), int64(1), object(13)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#Json file option\n",
    "#filejson = \"C:/Users/danie/Desktop/bbc_news_list_uk.json\"\n",
    "filecsv = r\"C:\\Users\\danie\\Documents\\GitHub\\Masters-Thesis\\bbc_news_list_uk.csv\"\n",
    "#filecsv = r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis/bbc_news_list_uk.csv\"\n",
    "article_df = pd.read_csv(filecsv)\n",
    "article_df = article_df.assign(Article_Number=range(len(article_df)))\n",
    "article_df = article_df.reset_index()\n",
    "article_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code assumes the first four digits are the year. can be changed for last of middle\n",
    "year = article_df['news_post_date'].str[:4]\n",
    "article_df['year']=year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'articles.pkl'\n",
    "\n",
    "#article_df = pd.read_pickle(filename)\n",
    "#article_df = article_df.assign(Article_Number=range(len(article_df)))\n",
    "#article_df = article_df.reset_index()\n",
    "#article_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize sentences in an article \n",
    "import re\n",
    "\n",
    "def split_sentences(article, article_id, year):\n",
    "    pattern = r'(?<=[a-z0-9\"]) *[.?!] *(?=[A-Z])'\n",
    "    article = re.sub(pattern, r'\\g<0> ', article)\n",
    "    sentences = nltk.sent_tokenize(article)\n",
    "    sentences_with_id = [(sentence, article_id, year) for sentence in sentences]\n",
    "    return sentences_with_id\n",
    "\n",
    "sentences_list = []\n",
    "\n",
    "# add sentences to a new DF along with article ID \n",
    "for article, article_id, year in article_df[['content','Article_Number', 'year']].values:\n",
    "    sentences = split_sentences(str(article), article_id, year)\n",
    "    sentences_list.extend(sentences)\n",
    "\n",
    "sentences_df = pd.DataFrame(sentences_list, columns= ['sentences', 'article_id', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronoun_occurances(text):\n",
    "    \"\"\" This function will count the number of female and male pronoun occurences in a given sentence.\"\"\"\n",
    "    pattern_m = r'(\\s|^)([\"\\']?)(he|his|him|he\\'s|hes)\\2\\b' #this regex will capture he/his as standalone words within a string but also at beginning of sentence\n",
    "    matches_m = re.findall(pattern_m, text, re.IGNORECASE) #IGNORECASE is necessary to make sure that it picks up the pronouns at the beginning of a sentence\n",
    "    pattern_f = r'(\\s|^)([\"\\']?)(she|her|hers|shes|she\\'s)\\2\\b'\n",
    "    matches_f = re.findall(pattern_f, text, re.IGNORECASE)\n",
    "    #pattern_n = r'(\\s|^|\")([\"\\']?)(they|them|their|theirs|their\\'s)\\2\\b' #\n",
    "    #matches_n = re.findall(pattern_n, text, re.IGNORECASE)\n",
    "    count_m = len(matches_m)\n",
    "    count_f = len(matches_f)\n",
    "    #count_n = len(matches_n)\n",
    "    #count_u = count_n + count_f + count_m\n",
    "    return count_f, count_m #, count_n, count_u"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reporting_words = [\"acknowledge\", \" add\", \" address\", \" admit\", \" announce\", \" argue\", \" believe\", \" claim\", \" conclude\", \" confirm\", \" continue\", \" declare\", \" describe\", \" ensure\", \" estimate\", \" explain\", \" find\", \" indicate\", \" inform\", \" insist\", \" note\", \" point\", \" predict\", \" provide\", \" release\", \" reply\", \" report\", \" respond\", \" say\", \" state\", \" suggest\", \" tell\", \" testify\", \" think\", \" tweet\", \" warn\", \" write\"]\n",
    "\n",
    " If sent contains a reporting word then\n",
    "    look to the word before for a name or a pronoun\n",
    "        If found and a name find gender \n",
    "            once gender is found clasify the sentence\n",
    "        if found a pronoun then classify sentence\n",
    "        else   \n",
    "            look after the word for the same and follow the same pattern\n",
    "                else follow the rest of the pattern\n",
    "Count the number of male, female, and neutral pronouns\n",
    "\n",
    "*****Look to see if the sentence contains a proper noun and add the gender to the ocunt\n",
    "    I think this should be added to the preprocessing because we are already looking up the POS tags so it will use less bullshit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>female_count</th>\n",
       "      <th>male_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The heroin substitute methadone can be used as...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earlier this year a debate broke out in Scotla...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But a group of 40 specialists, including unive...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So what do recovering addicts think?</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris used methadone for five years to help we...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225660</th>\n",
       "      <td>Similar moves in Europe have sparked cries of ...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225661</th>\n",
       "      <td>The lead in the Daily Mail is a claim that cou...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225662</th>\n",
       "      <td>It says authorities are using the information ...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225663</th>\n",
       "      <td>The Daily Express leads with a warning from US...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225664</th>\n",
       "      <td>But the paper says cancer experts in the UK ha...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225665 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentences  article_id  year  \\\n",
       "0       The heroin substitute methadone can be used as...           0  2010   \n",
       "1       Earlier this year a debate broke out in Scotla...           0  2010   \n",
       "2       But a group of 40 specialists, including unive...           0  2010   \n",
       "3                    So what do recovering addicts think?           0  2010   \n",
       "4       Chris used methadone for five years to help we...           0  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "225660  Similar moves in Europe have sparked cries of ...       15824  2010   \n",
       "225661  The lead in the Daily Mail is a claim that cou...       15824  2010   \n",
       "225662  It says authorities are using the information ...       15824  2010   \n",
       "225663  The Daily Express leads with a warning from US...       15824  2010   \n",
       "225664  But the paper says cancer experts in the UK ha...       15824  2010   \n",
       "\n",
       "        female_count  male_count  \n",
       "0                  0           0  \n",
       "1                  0           0  \n",
       "2                  0           0  \n",
       "3                  0           0  \n",
       "4                  0           3  \n",
       "...              ...         ...  \n",
       "225660             0           0  \n",
       "225661             0           0  \n",
       "225662             0           0  \n",
       "225663             0           0  \n",
       "225664             0           0  \n",
       "\n",
       "[225665 rows x 5 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a variable applying the function of pronoun occurence\n",
    "sent = sentences_df['sentences'].apply(pronoun_occurances)\n",
    "# Create two new columns in sentences DF from the tuple output in \"sent\"\n",
    "sentences_df['female_count'] = [x[0] for x in sent]\n",
    "sentences_df['male_count']= [x[1] for x in sent]\n",
    "#sentences_df['neutral_count']= [x[2] for x in sent]\n",
    "#sentences_df['u_count']= [x[3] for x in sent]\n",
    "\n",
    "#Bug is fixed and now it counts properly\n",
    "sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>female_count</th>\n",
       "      <th>male_count</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The heroin substitute methadone can be used as...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earlier this year a debate broke out in Scotla...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But a group of 40 specialists, including unive...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So what do recovering addicts think?</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris used methadone for five years to help we...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225660</th>\n",
       "      <td>Similar moves in Europe have sparked cries of ...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225661</th>\n",
       "      <td>The lead in the Daily Mail is a claim that cou...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225662</th>\n",
       "      <td>It says authorities are using the information ...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225663</th>\n",
       "      <td>The Daily Express leads with a warning from US...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225664</th>\n",
       "      <td>But the paper says cancer experts in the UK ha...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225665 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentences  article_id  year  \\\n",
       "0       The heroin substitute methadone can be used as...           0  2010   \n",
       "1       Earlier this year a debate broke out in Scotla...           0  2010   \n",
       "2       But a group of 40 specialists, including unive...           0  2010   \n",
       "3                    So what do recovering addicts think?           0  2010   \n",
       "4       Chris used methadone for five years to help we...           0  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "225660  Similar moves in Europe have sparked cries of ...       15824  2010   \n",
       "225661  The lead in the Daily Mail is a claim that cou...       15824  2010   \n",
       "225662  It says authorities are using the information ...       15824  2010   \n",
       "225663  The Daily Express leads with a warning from US...       15824  2010   \n",
       "225664  But the paper says cancer experts in the UK ha...       15824  2010   \n",
       "\n",
       "        female_count  male_count col_type  \n",
       "0                  0           0     None  \n",
       "1                  0           0     None  \n",
       "2                  0           0     None  \n",
       "3                  0           0     None  \n",
       "4                  0           3        1  \n",
       "...              ...         ...      ...  \n",
       "225660             0           0     None  \n",
       "225661             0           0     None  \n",
       "225662             0           0     None  \n",
       "225663             0           0     None  \n",
       "225664             0           0     None  \n",
       "\n",
       "[225665 rows x 6 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_count(male_col, female_col): \n",
    "    \"\"\"This function compares the count of female to male pronouns. It will output \"1\" if male count bigger\n",
    "    than female count, \"neutral\" if the count is equal, and \"female\" if there is a higher female count. \n",
    "    The function returns strings because we need categorical variables for log reg to run\"\"\"\n",
    "    if female_col > male_col:\n",
    "        return \"0\"\n",
    "    elif male_col > female_col:\n",
    "        return \"1\"\n",
    "    else: \n",
    "        return None\n",
    "sentences_df['col_type'] = sentences_df.apply(lambda row: compare_count(row['male_count'], row['female_count']),axis=1)\n",
    "sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns with \"None\" in the col_type \n",
    "sentences_df = sentences_df[sentences_df[\"col_type\"].notnull()]\n",
    "#sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>female_count</th>\n",
       "      <th>male_count</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175442</th>\n",
       "      <td>Mrs Jones previously admitted failing to notif...</td>\n",
       "      <td>12116</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60832</th>\n",
       "      <td>She also said that she had cut her mother's na...</td>\n",
       "      <td>4004</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23016</th>\n",
       "      <td>In her appeal, she claimed she only pleaded gu...</td>\n",
       "      <td>1339</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46585</th>\n",
       "      <td>\"She left her job, she left someone in her fla...</td>\n",
       "      <td>2967</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17800</th>\n",
       "      <td>I even made her do one in her bikini - which s...</td>\n",
       "      <td>971</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86076</th>\n",
       "      <td>The Telegraph quotes PR experts who say Green ...</td>\n",
       "      <td>5777</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86090</th>\n",
       "      <td>Many economists also believe that the previous...</td>\n",
       "      <td>5778</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86143</th>\n",
       "      <td>He is in a state of deep shock after his house...</td>\n",
       "      <td>5781</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86144</th>\n",
       "      <td>Anwar doesn't know where his wife and children...</td>\n",
       "      <td>5781</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225652</th>\n",
       "      <td>For him, it is an attempt to redefine voluntar...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49408 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentences  article_id  year  \\\n",
       "175442  Mrs Jones previously admitted failing to notif...       12116  2010   \n",
       "60832   She also said that she had cut her mother's na...        4004  2010   \n",
       "23016   In her appeal, she claimed she only pleaded gu...        1339  2010   \n",
       "46585   \"She left her job, she left someone in her fla...        2967  2010   \n",
       "17800   I even made her do one in her bikini - which s...         971  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "86076   The Telegraph quotes PR experts who say Green ...        5777  2010   \n",
       "86090   Many economists also believe that the previous...        5778  2010   \n",
       "86143   He is in a state of deep shock after his house...        5781  2010   \n",
       "86144   Anwar doesn't know where his wife and children...        5781  2010   \n",
       "225652  For him, it is an attempt to redefine voluntar...       15824  2010   \n",
       "\n",
       "        female_count  male_count col_type  \n",
       "175442             7           1        0  \n",
       "60832              7           0        0  \n",
       "23016              7           1        0  \n",
       "46585              7           1        0  \n",
       "17800              6           0        0  \n",
       "...              ...         ...      ...  \n",
       "86076              0           2        1  \n",
       "86090              0           1        1  \n",
       "86143              0           2        1  \n",
       "86144              0           2        1  \n",
       "225652             0           1        1  \n",
       "\n",
       "[49408 rows x 6 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df.sort_values(\"female_count\", ascending = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 - female \n",
    "1 - male"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifier Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}\n",
    "\n",
    "name_probability_list = {}\n",
    "#This needs to be pickled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she she's she'll he he he purple\n",
      "Ran regex in -0.0000 seconds\n",
      "Ran tokenization and tagging in -0.0038 seconds\n",
      "Ran lemmas and genderize in -0.0002 seconds\n",
      "Ran contractions in -0.0000 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['purple'], 3, 3, 0)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "from genderize import Genderize\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "#Sentence Encoding\n",
    "def tidy_text(sentence, remove_stopwords = True):\n",
    "    #!need to change all to nethods and time them\n",
    "    print(sentence)\n",
    "    regex_start = time.perf_counter()\n",
    "    Male_count = 0\n",
    "    male_list= {\"man\", \"men\", \"mister\", \"he\", \"him\", \"Mr.\", \"he\", \"his\",\"he's\", \"hes\", \"father\", \"dad\", \"daddy\", \"grandpa\", \"grandfather\", \"husband\"}\n",
    "    female_list ={\"woman\", \"women\", \"missus\", \"misses\", \"Ms.\", \"Mrs.\", \"her\", \"she\", \"hers\", \"mother\", \"mom\", \"mommy\", \"aunt\", \"grandmother\", \"grandma\", \"wife\", \"wive\"}\n",
    "    Female_count = 0\n",
    "    APIcallfail= 0\n",
    "\n",
    "    sentence = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', sentence)\n",
    "    sentence = re.sub(r'\\<a href', ' ', sentence)\n",
    "    sentence = re.sub(r'&amp;', '', sentence) \n",
    "    sentence = re.sub(\"\\d+\", \" \", sentence)\n",
    "    \n",
    "    #changed the number detection code\n",
    "    sentence = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', sentence)\n",
    "    sentence = re.sub(r'<br />', ' ', sentence)\n",
    "    regex_end = time.perf_counter()\n",
    "    print(f\"Ran regex in {regex_start - regex_end:0.4f} seconds\")\n",
    "\n",
    "    # Tokenize each word\n",
    "    sentence =  nltk.TweetTokenizer().tokenize(sentence)\n",
    "\n",
    "    nltk.tag.pos_tag(sentence)\n",
    "    tagged_sentence = nltk.tag.pos_tag(sentence)\n",
    "    lemma = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    token_ = time.perf_counter()\n",
    "    print(f\"Ran tokenization and tagging in {regex_end - token_:0.4f} seconds\")\n",
    "\n",
    "    pn_tags = {'NNP', 'NNPS'}\n",
    "    new_words = []\n",
    "\n",
    "    for word, tag in tagged_sentence: \n",
    "        if tag not in pn_tags: \n",
    "            if tag.startswith(\"V\"):\n",
    "                lemmas = lemma.lemmatize(word, \"v\")\n",
    "            else: \n",
    "                lemmas = lemma.lemmatize(word)\n",
    "            new_words.append((lemmas))\n",
    "        else:\n",
    "            try: \n",
    "                word_gender = name_probability_list.get(word)\n",
    "                if word_gender is None:\n",
    "                    word_gender = Genderize().get1(word).get('gender')\n",
    "                    #What do I do if the genderize is looking for a name that doesn't exist \n",
    "                    #Test once i have more API calls\n",
    "                    name_probability_list[word] = word_gender\n",
    "\n",
    "                if word_gender == 'male':\n",
    "                    Male_count += 1\n",
    "                if word_gender== 'female':\n",
    "                    Female_count += 1\n",
    "            except Exception as exception:\n",
    "                APIcallfail +=1\n",
    "    sentence = new_words\n",
    "\n",
    "    lemma = time.perf_counter()\n",
    "    print(f\"Ran lemmas and genderize in {token_ - lemma:0.4f} seconds\")\n",
    "\n",
    "    new_text = []\n",
    "    for word in sentence:\n",
    "        contraction = contractions.get(word)\n",
    "        if contraction is None:\n",
    "            new_text.append(word)\n",
    "        else:\n",
    "            for new_word in contraction.split():\n",
    "                new_text.append(new_word)\n",
    "    sentence = new_text\n",
    "\n",
    "    contraction_time = time.perf_counter()\n",
    "    print(f\"Ran contractions in {lemma - contraction_time:0.4f} seconds\")\n",
    "          \n",
    "    for w in sentence:\n",
    "        if w in male_list:\n",
    "            Male_count += 1\n",
    "        if w in female_list:\n",
    "            Female_count += 1\n",
    "\n",
    "    # remove stopwords\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        sentence = [w for w in sentence if not w in stops]\n",
    "\n",
    "\n",
    "    new_sent = [x for x in sentence if x not in male_list]\n",
    "    new_sent = [x for x in new_sent if x not in female_list]\n",
    "\n",
    "    sentence = new_sent\n",
    "\n",
    "    #!  here we check for words from the gender words and we ensure they are removed from the tokens. this will ensure we have 0 leakage\n",
    "    return sentence, Male_count, Female_count, APIcallfail\n",
    "\n",
    "text = \"she she's she'll he he he purple\"\n",
    "tidy_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chris used methadone for five years to help wean him off heroin but felt he had to quit the drug substitute last October\"I just thought, I've got to get a grip here, because I've been in and out of prison since I was 16 - that's half my life,\" he told The Report.\n",
      "Ran regex in -0.0001 seconds\n",
      "Ran tokenization and tagging in -0.0083 seconds\n",
      "Ran lemmas and genderize in -2.0176 seconds\n",
      "Ran contractions in -0.0008 seconds\n",
      "\"I heard about Ratho Hall, and it's given me the wake-up call that I needed,\" he said.\n",
      "Ran regex in -0.0001 seconds\n",
      "Ran tokenization and tagging in -0.0099 seconds\n",
      "Ran lemmas and genderize in -0.7995 seconds\n",
      "Ran contractions in -0.0002 seconds\n",
      "Chris was prescribed methadone, a synthetic opiate that is taken orally, to wean him off his heroin addiction but although methadone can help addicts stabilise their lives, it is also addictive.\n",
      "Ran regex in -0.0001 seconds\n",
      "Ran tokenization and tagging in -0.0119 seconds\n",
      "Ran lemmas and genderize in -0.3984 seconds\n",
      "Ran contractions in -0.0002 seconds\n",
      "In this, the Community Safety Minister, Fergus Ewing of the SNP, explained how he wants to see \"a new vision\" for Scotland \"where all drug treatment and rehabilitation services are based on the principle of recovery.\"\n",
      "Ran regex in -0.0001 seconds\n",
      "Ran tokenization and tagging in -0.0095 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-57e301509ff9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentences_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoded_sentences'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentences_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentences'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtidy_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4136\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-160-5f467e80eeba>\u001b[0m in \u001b[0;36mtidy_text\u001b[1;34m(sentence, remove_stopwords)\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[0mword_gender\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname_probability_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mword_gender\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m                     \u001b[0mword_gender\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGenderize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gender'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m                     \u001b[1;31m#What do I do if the genderize is looking for a name that doesn't exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                     \u001b[1;31m#Test once i have more API calls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\genderize\\__init__.py\u001b[0m in \u001b[0;36mget1\u001b[1;34m(self, name, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m             raise GenderizeException(\n\u001b[0;32m    162\u001b[0m                 \"get1() doesn't support the retheader option.\")\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\genderize\\__init__.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, names, country_id, language_id, retheader)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mraises\u001b[0m \u001b[0mGenderizeException\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mAPI\u001b[0m \u001b[0mserver\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mHTTP\u001b[0m \u001b[0merror\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \"\"\"\n\u001b[1;32m---> 96\u001b[1;33m         responses = [\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcountry_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mname_chunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\genderize\\__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \"\"\"\n\u001b[0;32m     96\u001b[0m         responses = [\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcountry_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mname_chunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;32min\u001b[0m \u001b[0m_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGenderize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\genderize\\__init__.py\u001b[0m in \u001b[0;36m_get_chunk\u001b[1;34m(self, name_chunk, country_id, language_id)\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'language_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         response = self.session.get(\n\u001b[0m\u001b[0;32m    129\u001b[0m             \u001b[1;34m'https://api.genderize.io/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GET'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    540\u001b[0m         }\n\u001b[0;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1008\u001b[0m         \u001b[1;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1010\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_default_certs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         self.sock = ssl_wrap_socket(\n\u001b[0m\u001b[0;32m    412\u001b[0m             \u001b[0msock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[0mkeyfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msend_sni\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         ssl_sock = _ssl_wrap_socket_impl(\n\u001b[0m\u001b[0;32m    429\u001b[0m             \u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtls_in_tls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 472\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;31m# SSLSocket class handles server_hostname encoding before it calls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;31m# ctx._wrap_socket()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         return self.sslsocket_class._create(\n\u001b[0m\u001b[0;32m    501\u001b[0m             \u001b[0msock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mserver_side\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_side\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1038\u001b[0m                         \u001b[1;31m# non-blocking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1307\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1309\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1310\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sentences_df['encoded_sentences'] = sentences_df['sentences'].apply(tidy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>female_count</th>\n",
       "      <th>male_count</th>\n",
       "      <th>col_type</th>\n",
       "      <th>encoded_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris used methadone for five years to help we...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[use, methadone, five, year, help, wean, heroi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"I heard about Ratho Hall, and it's given me t...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, hear, give, wake, call, I, need, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chris was prescribed methadone, a synthetic op...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[prescribe, methadone, synthetic, opiate, take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>In this, the Community Safety Minister, Fergus...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[In, explain, want, see, new, vision, drug, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chris, who started to use heroin when he was 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[start, use, heroin, talk, addiction, When, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225598</th>\n",
       "      <td>\"For Diego, it is good for him to see the norm...</td>\n",
       "      <td>15819</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[For, good, see, normal, rearing, process, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225601</th>\n",
       "      <td>The new monkey will stay at the zoo until he r...</td>\n",
       "      <td>15819</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, new, monkey, stay, zoo, reach, sexual, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225605</th>\n",
       "      <td>He died in hospital.</td>\n",
       "      <td>15820</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[He, die, hospital]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225645</th>\n",
       "      <td>He said: \"Local authorities need to recognise ...</td>\n",
       "      <td>15823</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[He, say, authority, need, recognise, regional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225652</th>\n",
       "      <td>For him, it is an attempt to redefine voluntar...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[For, attempt, redefine, voluntary, work, deep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49408 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentences  article_id  year  \\\n",
       "4       Chris used methadone for five years to help we...           0  2010   \n",
       "6       \"I heard about Ratho Hall, and it's given me t...           0  2010   \n",
       "7       Chris was prescribed methadone, a synthetic op...           0  2010   \n",
       "12      In this, the Community Safety Minister, Fergus...           0  2010   \n",
       "14      Chris, who started to use heroin when he was 1...           0  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "225598  \"For Diego, it is good for him to see the norm...       15819  2010   \n",
       "225601  The new monkey will stay at the zoo until he r...       15819  2010   \n",
       "225605                               He died in hospital.       15820  2010   \n",
       "225645  He said: \"Local authorities need to recognise ...       15823  2010   \n",
       "225652  For him, it is an attempt to redefine voluntar...       15824  2010   \n",
       "\n",
       "        female_count  male_count col_type  \\\n",
       "4                  0           3        1   \n",
       "6                  0           1        1   \n",
       "7                  0           2        1   \n",
       "12                 0           1        1   \n",
       "14                 0           2        1   \n",
       "...              ...         ...      ...   \n",
       "225598             0           2        1   \n",
       "225601             0           3        1   \n",
       "225605             0           1        1   \n",
       "225645             0           1        1   \n",
       "225652             0           1        1   \n",
       "\n",
       "                                        encoded_sentences  \n",
       "4       [use, methadone, five, year, help, wean, heroi...  \n",
       "6               [I, hear, give, wake, call, I, need, say]  \n",
       "7       [prescribe, methadone, synthetic, opiate, take...  \n",
       "12      [In, explain, want, see, new, vision, drug, tr...  \n",
       "14      [start, use, heroin, talk, addiction, When, he...  \n",
       "...                                                   ...  \n",
       "225598  [For, good, see, normal, rearing, process, wit...  \n",
       "225601  [The, new, monkey, stay, zoo, reach, sexual, m...  \n",
       "225605                                [He, die, hospital]  \n",
       "225645  [He, say, authority, need, recognise, regional...  \n",
       "225652  [For, attempt, redefine, voluntary, work, deep...  \n",
       "\n",
       "[49408 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the DF by Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>female_count</th>\n",
       "      <th>male_count</th>\n",
       "      <th>col_type</th>\n",
       "      <th>encoded_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris used methadone for five years to help we...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[use, methadone, five, year, help, wean, heroi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"I heard about Ratho Hall, and it's given me t...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, hear, give, wake, call, I, need, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chris was prescribed methadone, a synthetic op...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[prescribe, methadone, synthetic, opiate, take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>In this, the Community Safety Minister, Fergus...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[In, explain, want, see, new, vision, drug, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chris, who started to use heroin when he was 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[start, use, heroin, talk, addiction, When, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225598</th>\n",
       "      <td>\"For Diego, it is good for him to see the norm...</td>\n",
       "      <td>15819</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[For, good, see, normal, rearing, process, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225601</th>\n",
       "      <td>The new monkey will stay at the zoo until he r...</td>\n",
       "      <td>15819</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, new, monkey, stay, zoo, reach, sexual, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225605</th>\n",
       "      <td>He died in hospital.</td>\n",
       "      <td>15820</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[He, die, hospital]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225645</th>\n",
       "      <td>He said: \"Local authorities need to recognise ...</td>\n",
       "      <td>15823</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[He, say, authority, need, recognise, regional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225652</th>\n",
       "      <td>For him, it is an attempt to redefine voluntar...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[For, attempt, redefine, voluntary, work, deep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49384 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentences  article_id  year  \\\n",
       "4       Chris used methadone for five years to help we...           0  2010   \n",
       "6       \"I heard about Ratho Hall, and it's given me t...           0  2010   \n",
       "7       Chris was prescribed methadone, a synthetic op...           0  2010   \n",
       "12      In this, the Community Safety Minister, Fergus...           0  2010   \n",
       "14      Chris, who started to use heroin when he was 1...           0  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "225598  \"For Diego, it is good for him to see the norm...       15819  2010   \n",
       "225601  The new monkey will stay at the zoo until he r...       15819  2010   \n",
       "225605                               He died in hospital.       15820  2010   \n",
       "225645  He said: \"Local authorities need to recognise ...       15823  2010   \n",
       "225652  For him, it is an attempt to redefine voluntar...       15824  2010   \n",
       "\n",
       "        female_count  male_count col_type  \\\n",
       "4                  0           3        1   \n",
       "6                  0           1        1   \n",
       "7                  0           2        1   \n",
       "12                 0           1        1   \n",
       "14                 0           2        1   \n",
       "...              ...         ...      ...   \n",
       "225598             0           2        1   \n",
       "225601             0           3        1   \n",
       "225605             0           1        1   \n",
       "225645             0           1        1   \n",
       "225652             0           1        1   \n",
       "\n",
       "                                        encoded_sentences  \n",
       "4       [use, methadone, five, year, help, wean, heroi...  \n",
       "6               [I, hear, give, wake, call, I, need, say]  \n",
       "7       [prescribe, methadone, synthetic, opiate, take...  \n",
       "12      [In, explain, want, see, new, vision, drug, tr...  \n",
       "14      [start, use, heroin, talk, addiction, When, he...  \n",
       "...                                                   ...  \n",
       "225598  [For, good, see, normal, rearing, process, wit...  \n",
       "225601  [The, new, monkey, stay, zoo, reach, sexual, m...  \n",
       "225605                                [He, die, hospital]  \n",
       "225645  [He, say, authority, need, recognise, regional...  \n",
       "225652  [For, attempt, redefine, voluntary, work, deep...  \n",
       "\n",
       "[49384 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>female_count</th>\n",
       "      <th>male_count</th>\n",
       "      <th>col_type</th>\n",
       "      <th>encoded_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21436</th>\n",
       "      <td>One woman is quoted as saying the gangsters th...</td>\n",
       "      <td>1230</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[One, woman, quote, say, gangster, threaten, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21438</th>\n",
       "      <td>He has also called for the criminals to be tra...</td>\n",
       "      <td>1230</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[He, also, call, criminal, track, punish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85224</th>\n",
       "      <td>However, Mr Fico said that he would still try ...</td>\n",
       "      <td>5717</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[However, say, would, still, try, form, govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85225</th>\n",
       "      <td>Referring to his party's 63 seats, he said: \"T...</td>\n",
       "      <td>5717</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[Referring, party, seat, say, This, number, gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85232</th>\n",
       "      <td>\"The citizens of Slovakia have voted for respo...</td>\n",
       "      <td>5717</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[The, citizen, vote, responsibility, add]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85233</th>\n",
       "      <td>With partners Freedom and Solidarity, the Chri...</td>\n",
       "      <td>5717</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[With, partner, ethnic, party, party, enough, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85239</th>\n",
       "      <td>In a television address shortly before polls o...</td>\n",
       "      <td>5717</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[In, television, address, shortly, poll, open,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85241</th>\n",
       "      <td>\"Any mash-up is better than Fico,\" said SaS le...</td>\n",
       "      <td>5717</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Any, mash, better, say, leader, say, party, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85989</th>\n",
       "      <td>But President Ivan Gasparovic said he would gi...</td>\n",
       "      <td>5773</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[But, say, would, give, first, chance, form, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85990</th>\n",
       "      <td>Mr Gasparovic said he wanted to respect the tr...</td>\n",
       "      <td>5773</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[say, want, respect, tradition, give, leader, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85994</th>\n",
       "      <td>Referring to his party's 62 seats, he said: \"T...</td>\n",
       "      <td>5773</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[Referring, party, seat, say, This, number, gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86001</th>\n",
       "      <td>\"The citizens of Slovakia have voted for respo...</td>\n",
       "      <td>5773</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[The, citizen, vote, responsibility, add]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86002</th>\n",
       "      <td>With partners Freedom and Solidarity, the Chri...</td>\n",
       "      <td>5773</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[With, partner, ethnic, party, party, enough, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86007</th>\n",
       "      <td>In a television address shortly before polls o...</td>\n",
       "      <td>5773</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[In, television, address, shortly, poll, open,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86009</th>\n",
       "      <td>\"Any mash-up is better than Fico,\" said SaS le...</td>\n",
       "      <td>5773</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Any, mash, better, say, leader, say, party, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129380</th>\n",
       "      <td>Slovakia's president has asked a centre-right ...</td>\n",
       "      <td>8800</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[president, ask, centre, right, leader, form, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129385</th>\n",
       "      <td>\"I will do my best to make this a cabinet for ...</td>\n",
       "      <td>8800</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, best, make, cabinet, citizen, open, cabine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129387</th>\n",
       "      <td>If Ms Radicova succeeds in forming a governmen...</td>\n",
       "      <td>8800</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[If, succeed, form, government, would, become,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129388</th>\n",
       "      <td>Mr Fico told Mr Gasparovic that he was giving ...</td>\n",
       "      <td>8800</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[tell, give, morning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129389</th>\n",
       "      <td>\"I handed the designation back to the presiden...</td>\n",
       "      <td>8800</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, hand, designation, back, president, idea, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129391</th>\n",
       "      <td>His cabinet included anti-Hungarian nationalis...</td>\n",
       "      <td>8800</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[His, cabinet, include, anti, Hungarian, natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198173</th>\n",
       "      <td>She takes over from centre-left leader Robert ...</td>\n",
       "      <td>13733</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[She, take, centre, leave, leader, prime, mini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198175</th>\n",
       "      <td>\"We are fully aware of the fact the Slovakia, ...</td>\n",
       "      <td>13733</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[We, fully, aware, fact, like, many, state, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198178</th>\n",
       "      <td>The presence of an ethnic Hungarian politician...</td>\n",
       "      <td>13733</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, presence, ethnic, Hungarian, politician,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentences  article_id  year  \\\n",
       "21436   One woman is quoted as saying the gangsters th...        1230  2012   \n",
       "21438   He has also called for the criminals to be tra...        1230  2012   \n",
       "85224   However, Mr Fico said that he would still try ...        5717  2012   \n",
       "85225   Referring to his party's 63 seats, he said: \"T...        5717  2012   \n",
       "85232   \"The citizens of Slovakia have voted for respo...        5717  2012   \n",
       "85233   With partners Freedom and Solidarity, the Chri...        5717  2012   \n",
       "85239   In a television address shortly before polls o...        5717  2012   \n",
       "85241   \"Any mash-up is better than Fico,\" said SaS le...        5717  2012   \n",
       "85989   But President Ivan Gasparovic said he would gi...        5773  2012   \n",
       "85990   Mr Gasparovic said he wanted to respect the tr...        5773  2012   \n",
       "85994   Referring to his party's 62 seats, he said: \"T...        5773  2012   \n",
       "86001   \"The citizens of Slovakia have voted for respo...        5773  2012   \n",
       "86002   With partners Freedom and Solidarity, the Chri...        5773  2012   \n",
       "86007   In a television address shortly before polls o...        5773  2012   \n",
       "86009   \"Any mash-up is better than Fico,\" said SaS le...        5773  2012   \n",
       "129380  Slovakia's president has asked a centre-right ...        8800  2012   \n",
       "129385  \"I will do my best to make this a cabinet for ...        8800  2012   \n",
       "129387  If Ms Radicova succeeds in forming a governmen...        8800  2012   \n",
       "129388  Mr Fico told Mr Gasparovic that he was giving ...        8800  2012   \n",
       "129389  \"I handed the designation back to the presiden...        8800  2012   \n",
       "129391  His cabinet included anti-Hungarian nationalis...        8800  2012   \n",
       "198173  She takes over from centre-left leader Robert ...       13733  2012   \n",
       "198175  \"We are fully aware of the fact the Slovakia, ...       13733  2012   \n",
       "198178  The presence of an ethnic Hungarian politician...       13733  2012   \n",
       "\n",
       "        female_count  male_count col_type  \\\n",
       "21436              3           0        0   \n",
       "21438              0           1        1   \n",
       "85224              0           1        1   \n",
       "85225              0           2        1   \n",
       "85232              1           0        0   \n",
       "85233              1           0        0   \n",
       "85239              0           1        1   \n",
       "85241              0           1        1   \n",
       "85989              0           1        1   \n",
       "85990              0           1        1   \n",
       "85994              0           2        1   \n",
       "86001              1           0        0   \n",
       "86002              1           0        0   \n",
       "86007              0           1        1   \n",
       "86009              0           1        1   \n",
       "129380             0           1        1   \n",
       "129385             1           0        0   \n",
       "129387             1           0        0   \n",
       "129388             0           1        1   \n",
       "129389             0           1        1   \n",
       "129391             0           1        1   \n",
       "198173             1           0        0   \n",
       "198175             1           0        0   \n",
       "198178             0           1        1   \n",
       "\n",
       "                                        encoded_sentences  \n",
       "21436   [One, woman, quote, say, gangster, threaten, b...  \n",
       "21438           [He, also, call, criminal, track, punish]  \n",
       "85224   [However, say, would, still, try, form, govern...  \n",
       "85225   [Referring, party, seat, say, This, number, gi...  \n",
       "85232           [The, citizen, vote, responsibility, add]  \n",
       "85233   [With, partner, ethnic, party, party, enough, ...  \n",
       "85239   [In, television, address, shortly, poll, open,...  \n",
       "85241   [Any, mash, better, say, leader, say, party, w...  \n",
       "85989   [But, say, would, give, first, chance, form, g...  \n",
       "85990   [say, want, respect, tradition, give, leader, ...  \n",
       "85994   [Referring, party, seat, say, This, number, gi...  \n",
       "86001           [The, citizen, vote, responsibility, add]  \n",
       "86002   [With, partner, ethnic, party, party, enough, ...  \n",
       "86007   [In, television, address, shortly, poll, open,...  \n",
       "86009   [Any, mash, better, say, leader, say, party, w...  \n",
       "129380  [president, ask, centre, right, leader, form, ...  \n",
       "129385  [I, best, make, cabinet, citizen, open, cabine...  \n",
       "129387  [If, succeed, form, government, would, become,...  \n",
       "129388                              [tell, give, morning]  \n",
       "129389  [I, hand, designation, back, president, idea, ...  \n",
       "129391  [His, cabinet, include, anti, Hungarian, natio...  \n",
       "198173  [She, take, centre, leave, leader, prime, mini...  \n",
       "198175  [We, fully, aware, fact, like, many, state, st...  \n",
       "198178  [The, presence, ethnic, Hungarian, politician,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split_df(df, column_name): \n",
    "    \"\"\"Split Sentences DF by the year column so that we can do the LR by year\"\"\"\n",
    "\n",
    "    #get all unique values in col\n",
    "    col_vals = df[column_name].unique()\n",
    "\n",
    "    split = [df[df[column_name] == value] for value in col_vals]\n",
    "    \n",
    "    #Return the list of split dataframes\n",
    "    return split\n",
    "\n",
    "#use the new function to split the original sentences df \n",
    "splitted_df = split_df(sentences_df, 'year')\n",
    "\n",
    "#print each of the DFs\n",
    "for df_year_data in splitted_df:\n",
    "    display(df_year_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.get_dummies(sentences_df.year)\n",
    "#rated_dummies = pd.get_dummies((sentences_df).year)\n",
    "#sentences_df = pd.concat([sentences_df, rated_dummies], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(max_features= 1000, lowercase=False, tokenizer=False)\n",
    "def fake(token):\n",
    "    return token\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=fake,\n",
    "    preprocessor=fake,\n",
    "    token_pattern=None)  \n",
    "\n",
    "#X_train = tfidf.fit_transform(X_train)\n",
    "#X_test = tfidf.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV Packages - this still needs changing and fitting into the LR function!\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# parameter grid\n",
    "parameters = {\"penalty\": ['l1','l2'], \n",
    "              \"C\": np.logspace(-3,3,7),\n",
    "              \"solver\": ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "}\n",
    "\n",
    "#GridSearchCV\n",
    "logreg = LogisticRegression()\n",
    "clf_logreg = GridSearchCV(logreg, \n",
    "                          param_grid = parameters, \n",
    "                          scoring = \"accuracy\", \n",
    "                          cv = 10)\n",
    "\n",
    "clf_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Classifier by Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_year(df, target_col, text_col, year_col):\n",
    "    years = df[year_col].unique()\n",
    "    results = {}\n",
    "\n",
    "    #split data \n",
    "    for year in years:\n",
    "        df_year = df.loc[df[year_col]==year].copy()\n",
    "        df_year['text'] = df_year[text_col].apply(lambda x: ' '.join(map(str, x)))\n",
    "        X = df_year[text_col].apply(lambda x: str(x))\n",
    "        y = df_year[target_col]\n",
    "\n",
    "    #train test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        tfidf = TfidfVectorizer()\n",
    "        X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "        X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    #run the classifier \n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(X_train_tfidf, y_train)\n",
    "        y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "    #performance \n",
    "        accuracy = clf.score(X_test_tfidf, y_test)\n",
    "        class_report = classification_report(y_test, y_pred, zero_division = 0)\n",
    "        results[year] = {'accuracy': accuracy, 'classification_report': class_report}\n",
    "        print(f\"Year: {year}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Classification Report:\\n{class_report}\")\n",
    "\n",
    "        #coefficients\n",
    "        coefs = clf.coef_[0]\n",
    "        sorted_coef = sorted((zip(tfidf.get_feature_names_out(), coefs)), key = lambda x: x[1], reverse=True)\n",
    "        high_coef = sorted_coef[:5]\n",
    "        low_coef = sorted_coef[-5:]\n",
    "        \n",
    "\n",
    "        #print coefficient results \n",
    "        print(f\"\\n Highest coefs:\")\n",
    "        for i in high_coef: \n",
    "            print(i)\n",
    "        \n",
    "        print(f\"\\n Lowest coefs:\")\n",
    "        for i in low_coef: \n",
    "            print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2010\n",
      "Accuracy: 0.8566366305558368\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.40      0.55      2183\n",
      "           1       0.85      0.99      0.91      7694\n",
      "\n",
      "    accuracy                           0.86      9877\n",
      "   macro avg       0.87      0.69      0.73      9877\n",
      "weighted avg       0.86      0.86      0.83      9877\n",
      "\n",
      "\n",
      " Highest coefs:\n",
      "('he', 15.891551900218763)\n",
      "('his', 7.603456046330884)\n",
      "('man', 4.17082789968222)\n",
      "('wife', 3.5879416740474666)\n",
      "('soldier', 2.378104672128594)\n",
      "\n",
      " Lowest coefs:\n",
      "('girl', -5.560419224363694)\n",
      "('husband', -6.233141993018479)\n",
      "('woman', -7.343204828079678)\n",
      "('her', -9.555410225636514)\n",
      "('she', -18.592092822166705)\n",
      "Year: 2012\n",
      "Accuracy: 0.4\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.40         5\n",
      "   macro avg       0.20      0.50      0.29         5\n",
      "weighted avg       0.16      0.40      0.23         5\n",
      "\n",
      "\n",
      " Highest coefs:\n",
      "('say', 0.4121279131606606)\n",
      "('president', 0.24964302266496455)\n",
      "('cabinet', 0.2363522776710395)\n",
      "('right', 0.21604928573893997)\n",
      "('would', 0.2093362404217043)\n",
      "\n",
      " Lowest coefs:\n",
      "('enough', -0.3442155857271766)\n",
      "('majority', -0.3442155857271766)\n",
      "('parliamentary', -0.3442155857271766)\n",
      "('partner', -0.3442155857271766)\n",
      "('with', -0.3442155857271766)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_year(sentences_df, 'col_type', 'encoded_sentences', 'year')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary Logistics Regression (OLD VERSION)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finetuned model with best hyperparameters \n",
    "logreg1 = LogisticRegression(C=0.1, penalty = \"l2\", solver = \"liblinear\", max_iter = 5000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression(C = 0.1, penalty = \"l2\", solver = \"liblinear\", max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=5000, solver='liblinear')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_logreg = logreg1.fit(X_train, y_train)\n",
    "fitted_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = fitted_logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8390002023881805\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",fitted_logreg.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 is better to prevent overfitting than L1 because it punishes errors more (squares them as opposed to taking the absolute value). GridSearchCV said either L1 or L2 were equally as good though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest coefs\n",
      "('He', 7.497867226565254)\n",
      "('His', 2.791468567597014)\n",
      "('man', 1.7939417368758859)\n",
      "('wife', 1.2597679909365127)\n",
      "('shoot', 0.8793346468852085)\n",
      "('soldier', 0.8253443935307779)\n",
      "('security', 0.552288517084893)\n",
      "('general', 0.5360865508650358)\n",
      "('minister', 0.5225045885836616)\n",
      "('boy', 0.5212790475191019)\n",
      "lowest coefs\n",
      "('home', -0.8708266336604314)\n",
      "('actress', -1.0912651232977952)\n",
      "('child', -1.13564985240973)\n",
      "('daughter', -1.6608630837522824)\n",
      "('mother', -2.061830887374049)\n",
      "('girl', -2.2616077753072013)\n",
      "('husband', -2.5359911903913552)\n",
      "('woman', -3.8458811360803873)\n",
      "('Her', -3.9024438512883517)\n",
      "('She', -10.14035943687664)\n"
     ]
    }
   ],
   "source": [
    "coefs = fitted_logreg.coef_[0]\n",
    "\n",
    "#male is 1 and female is 0\n",
    "\n",
    "sorted_coef = sorted((zip(tfidf.get_feature_names(), coefs)), key = lambda x: x[1], reverse=True)\n",
    "\n",
    "high_coef = sorted_coef[:10]\n",
    "low_coef = sorted_coef[-10:]\n",
    "\n",
    "print(\"highest coefs\")\n",
    "for i in high_coef: \n",
    "    print(i)\n",
    "\n",
    "print(\"lowest coefs\")\n",
    "for i in low_coef: \n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, male coefficient for neutral is higher than the female. Otherwise, as expected, the coefficients for female and male each are correspondingly high for each gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8390002023881805\n",
      "[[ 559 1569]\n",
      " [  22 7732]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.26      0.41      2128\n",
      "           1       0.83      1.00      0.91      7754\n",
      "\n",
      "    accuracy                           0.84      9882\n",
      "   macro avg       0.90      0.63      0.66      9882\n",
      "weighted avg       0.86      0.84      0.80      9882\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, prediction)) #accuracy \n",
    "print(metrics.confusion_matrix(y_test, prediction)) #confusion matrix\n",
    "print(metrics.classification_report(y_test, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
