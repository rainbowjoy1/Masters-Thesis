{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/yolandaferreirofranchi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15825 entries, 0 to 15824\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   index              15825 non-null  int64 \n",
      " 1   tags               1 non-null      object\n",
      " 2   title              15825 non-null  object\n",
      " 3   news_post_date     15825 non-null  object\n",
      " 4   raw_content        15468 non-null  object\n",
      " 5   content            15468 non-null  object\n",
      " 6   url                15825 non-null  object\n",
      " 7   author             1453 non-null   object\n",
      " 8   language           15825 non-null  object\n",
      " 9   id                 15825 non-null  object\n",
      " 10  region             15488 non-null  object\n",
      " 11  short_description  15825 non-null  object\n",
      " 12  category           15825 non-null  object\n",
      " 13  crawled_at         15825 non-null  object\n",
      " 14  Article_Number     15825 non-null  int64 \n",
      "dtypes: int64(2), object(13)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#Json file option\n",
    "#filejson = \"C:/Users/danie/Desktop/bbc_news_list_uk.json\"\n",
    "#filecsv = r\"C:\\Users\\danie\\Documents\\GitHub\\Masters-Thesis\\bbc_news_list_uk.csv\"\n",
    "filecsv = r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis/bbc_news_list_uk.csv\"\n",
    "article_df = pd.read_csv(filecsv)\n",
    "article_df = article_df.assign(Article_Number=range(len(article_df)))\n",
    "article_df = article_df.reset_index()\n",
    "article_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code assumes the first four digits are the year. can be changed for last of middle\n",
    "year = article_df['news_post_date'].str[:4]\n",
    "article_df['year']=year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'articles.pkl'\n",
    "\n",
    "#article_df = pd.read_pickle(filename)\n",
    "#article_df = article_df.assign(Article_Number=range(len(article_df)))\n",
    "#article_df = article_df.reset_index()\n",
    "#article_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize sentences in an article \n",
    "import re\n",
    "\n",
    "def split_sentences(article, article_id, year):\n",
    "    pattern = r'(?<=[a-z0-9\"]) *[.?!] *(?=[A-Z])'\n",
    "    article = re.sub(pattern, r'\\g<0> ', article)\n",
    "    sentences = nltk.sent_tokenize(article)\n",
    "    sentences_with_id = [(sentence, article_id, year) for sentence in sentences]\n",
    "    return sentences_with_id\n",
    "\n",
    "sentences_list = []\n",
    "\n",
    "# add sentences to a new DF along with article ID \n",
    "for article, article_id, year in article_df[['content','Article_Number', 'year']].values:\n",
    "    sentences = split_sentences(str(article), article_id, year)\n",
    "    sentences_list.extend(sentences)\n",
    "\n",
    "sentences_df = pd.DataFrame(sentences_list, columns= ['sentences', 'article_id', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronoun_occurances(text):\n",
    "    \"\"\" This function will count the number of female and male pronoun occurences in a given sentence.\"\"\"\n",
    "    pattern_m = r'(\\s|^)([\"\\']?)(he|his|him|he\\'s|hes)\\2\\b' #this regex will capture he/his as standalone words within a string but also at beginning of sentence\n",
    "    matches_m = re.findall(pattern_m, text, re.IGNORECASE) #IGNORECASE is necessary to make sure that it picks up the pronouns at the beginning of a sentence\n",
    "    pattern_f = r'(\\s|^)([\"\\']?)(she|her|hers|shes|she\\'s)\\2\\b'\n",
    "    matches_f = re.findall(pattern_f, text, re.IGNORECASE)\n",
    "    #pattern_n = r'(\\s|^|\")([\"\\']?)(they|them|their|theirs|their\\'s)\\2\\b' #\n",
    "    #matches_n = re.findall(pattern_n, text, re.IGNORECASE)\n",
    "    count_m = len(matches_m)\n",
    "    count_f = len(matches_f)\n",
    "    #count_n = len(matches_n)\n",
    "    #count_u = count_n + count_f + count_m\n",
    "    return count_f, count_m #, count_n, count_u"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reporting_words = [\"acknowledge\", \" add\", \" address\", \" admit\", \" announce\", \" argue\", \" believe\", \" claim\", \" conclude\", \" confirm\", \" continue\", \" declare\", \" describe\", \" ensure\", \" estimate\", \" explain\", \" find\", \" indicate\", \" inform\", \" insist\", \" note\", \" point\", \" predict\", \" provide\", \" release\", \" reply\", \" report\", \" respond\", \" say\", \" state\", \" suggest\", \" tell\", \" testify\", \" think\", \" tweet\", \" warn\", \" write\"]\n",
    "\n",
    " If sent contains a reporting word then\n",
    "    look to the word before for a name or a pronoun\n",
    "        If found and a name find gender \n",
    "            once gender is found clasify the sentence\n",
    "        if found a pronoun then classify sentence\n",
    "        else   \n",
    "            look after the word for the same and follow the same pattern\n",
    "                else follow the rest of the pattern\n",
    "Count the number of male, female, and neutral pronouns\n",
    "\n",
    "*****Look to see if the sentence contains a proper noun and add the gender to the ocunt\n",
    "    I think this should be added to the preprocessing because we are already looking up the POS tags so it will use less bullshit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>female_count</th>\n",
       "      <th>male_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The heroin substitute methadone can be used as...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earlier this year a debate broke out in Scotla...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But a group of 40 specialists, including unive...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So what do recovering addicts think?</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris used methadone for five years to help we...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225660</th>\n",
       "      <td>Similar moves in Europe have sparked cries of ...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225661</th>\n",
       "      <td>The lead in the Daily Mail is a claim that cou...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225662</th>\n",
       "      <td>It says authorities are using the information ...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225663</th>\n",
       "      <td>The Daily Express leads with a warning from US...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225664</th>\n",
       "      <td>But the paper says cancer experts in the UK ha...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225665 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentences  article_id  year  \\\n",
       "0       The heroin substitute methadone can be used as...           0  2010   \n",
       "1       Earlier this year a debate broke out in Scotla...           0  2010   \n",
       "2       But a group of 40 specialists, including unive...           0  2010   \n",
       "3                    So what do recovering addicts think?           0  2010   \n",
       "4       Chris used methadone for five years to help we...           0  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "225660  Similar moves in Europe have sparked cries of ...       15824  2010   \n",
       "225661  The lead in the Daily Mail is a claim that cou...       15824  2010   \n",
       "225662  It says authorities are using the information ...       15824  2010   \n",
       "225663  The Daily Express leads with a warning from US...       15824  2010   \n",
       "225664  But the paper says cancer experts in the UK ha...       15824  2010   \n",
       "\n",
       "        female_count  male_count  \n",
       "0                  0           0  \n",
       "1                  0           0  \n",
       "2                  0           0  \n",
       "3                  0           0  \n",
       "4                  0           3  \n",
       "...              ...         ...  \n",
       "225660             0           0  \n",
       "225661             0           0  \n",
       "225662             0           0  \n",
       "225663             0           0  \n",
       "225664             0           0  \n",
       "\n",
       "[225665 rows x 5 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a variable applying the function of pronoun occurence\n",
    "sent = sentences_df['sentences'].apply(pronoun_occurances)\n",
    "# Create two new columns in sentences DF from the tuple output in \"sent\"\n",
    "sentences_df['female_count'] = [x[0] for x in sent]\n",
    "sentences_df['male_count']= [x[1] for x in sent]\n",
    "#sentences_df['neutral_count']= [x[2] for x in sent]\n",
    "#sentences_df['u_count']= [x[3] for x in sent]\n",
    "\n",
    "#Bug is fixed and now it counts properly\n",
    "sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>female_count</th>\n",
       "      <th>male_count</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The heroin substitute methadone can be used as...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earlier this year a debate broke out in Scotla...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But a group of 40 specialists, including unive...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So what do recovering addicts think?</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris used methadone for five years to help we...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225660</th>\n",
       "      <td>Similar moves in Europe have sparked cries of ...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225661</th>\n",
       "      <td>The lead in the Daily Mail is a claim that cou...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225662</th>\n",
       "      <td>It says authorities are using the information ...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225663</th>\n",
       "      <td>The Daily Express leads with a warning from US...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225664</th>\n",
       "      <td>But the paper says cancer experts in the UK ha...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225665 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentences  article_id  year  \\\n",
       "0       The heroin substitute methadone can be used as...           0  2010   \n",
       "1       Earlier this year a debate broke out in Scotla...           0  2010   \n",
       "2       But a group of 40 specialists, including unive...           0  2010   \n",
       "3                    So what do recovering addicts think?           0  2010   \n",
       "4       Chris used methadone for five years to help we...           0  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "225660  Similar moves in Europe have sparked cries of ...       15824  2010   \n",
       "225661  The lead in the Daily Mail is a claim that cou...       15824  2010   \n",
       "225662  It says authorities are using the information ...       15824  2010   \n",
       "225663  The Daily Express leads with a warning from US...       15824  2010   \n",
       "225664  But the paper says cancer experts in the UK ha...       15824  2010   \n",
       "\n",
       "        female_count  male_count col_type  \n",
       "0                  0           0     None  \n",
       "1                  0           0     None  \n",
       "2                  0           0     None  \n",
       "3                  0           0     None  \n",
       "4                  0           3        1  \n",
       "...              ...         ...      ...  \n",
       "225660             0           0     None  \n",
       "225661             0           0     None  \n",
       "225662             0           0     None  \n",
       "225663             0           0     None  \n",
       "225664             0           0     None  \n",
       "\n",
       "[225665 rows x 6 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_count(male_col, female_col): \n",
    "    \"\"\"This function compares the count of female to male pronouns. It will output \"1\" if male count bigger\n",
    "    than female count, \"neutral\" if the count is equal, and \"female\" if there is a higher female count. \n",
    "    The function returns strings because we need categorical variables for log reg to run\"\"\"\n",
    "    if female_col > male_col:\n",
    "        return \"0\"\n",
    "    elif male_col > female_col:\n",
    "        return \"1\"\n",
    "    else: \n",
    "        return None\n",
    "sentences_df['col_type'] = sentences_df.apply(lambda row: compare_count(row['male_count'], row['female_count']),axis=1)\n",
    "sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns with \"None\" in the col_type \n",
    "sentences_df = sentences_df[sentences_df[\"col_type\"].notnull()]\n",
    "#sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>female_count</th>\n",
       "      <th>male_count</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46585</th>\n",
       "      <td>\"She left her job, she left someone in her fla...</td>\n",
       "      <td>2967</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175442</th>\n",
       "      <td>Mrs Jones previously admitted failing to notif...</td>\n",
       "      <td>12116</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60832</th>\n",
       "      <td>She also said that she had cut her mother's na...</td>\n",
       "      <td>4004</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23016</th>\n",
       "      <td>In her appeal, she claimed she only pleaded gu...</td>\n",
       "      <td>1339</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9083</th>\n",
       "      <td>The charge alleges Mr McLeod failed to observe...</td>\n",
       "      <td>466</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77381</th>\n",
       "      <td>\"\"I, Shahram Amiri, a citizen of the Islamic R...</td>\n",
       "      <td>5146</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77382</th>\n",
       "      <td>I am free here and I assure everyone that I am...</td>\n",
       "      <td>5146</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77383</th>\n",
       "      <td>My purpose in today's conversation is to put a...</td>\n",
       "      <td>5146</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77384</th>\n",
       "      <td>I am Iranian and I have not taken any steps ag...</td>\n",
       "      <td>5146</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225664</th>\n",
       "      <td>But the paper says cancer experts in the UK ha...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225665 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentences  article_id  year  \\\n",
       "46585   \"She left her job, she left someone in her fla...        2967  2010   \n",
       "175442  Mrs Jones previously admitted failing to notif...       12116  2010   \n",
       "60832   She also said that she had cut her mother's na...        4004  2010   \n",
       "23016   In her appeal, she claimed she only pleaded gu...        1339  2010   \n",
       "9083    The charge alleges Mr McLeod failed to observe...         466  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "77381   \"\"I, Shahram Amiri, a citizen of the Islamic R...        5146  2010   \n",
       "77382   I am free here and I assure everyone that I am...        5146  2010   \n",
       "77383   My purpose in today's conversation is to put a...        5146  2010   \n",
       "77384   I am Iranian and I have not taken any steps ag...        5146  2010   \n",
       "225664  But the paper says cancer experts in the UK ha...       15824  2010   \n",
       "\n",
       "        female_count  male_count col_type  \n",
       "46585              7           1        0  \n",
       "175442             7           1        0  \n",
       "60832              7           0        0  \n",
       "23016              7           1        0  \n",
       "9083               6           0        0  \n",
       "...              ...         ...      ...  \n",
       "77381              0           0     None  \n",
       "77382              0           0     None  \n",
       "77383              0           0     None  \n",
       "77384              0           0     None  \n",
       "225664             0           0     None  \n",
       "\n",
       "[225665 rows x 6 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df.sort_values(\"female_count\", ascending = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 - female \n",
    "1 - male"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the Classifier**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistics Regression Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "from genderize import Genderize\n",
    "\n",
    "#Sentence Encoding\n",
    "def tidy_text(sentence, remove_stopwords = True):\n",
    "\n",
    "    sentence = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', sentence)\n",
    "    sentence = re.sub(r'\\<a href', ' ', sentence)\n",
    "    sentence = re.sub(r'&amp;', '', sentence) \n",
    "    sentence = re.sub(\"\\d+\", \"\", sentence)\n",
    "    \n",
    "    #changed the number detection code\n",
    "    sentence = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', sentence)\n",
    "    sentence = re.sub(r'<br />', ' ', sentence)\n",
    "    sentence = re.sub(r'\\'', ' ', sentence)\n",
    "\n",
    "    # Tokenize each word\n",
    "    sentence =  nltk.WordPunctTokenizer().tokenize(sentence)\n",
    "\n",
    "    #! I think this is where the gender words detection should go, because we can do it after tokenization and then it's more efficiant\n",
    "    #we also have a bit of a plural problem. we need to take care of. Also the words need to be removed--maybe at the end? \n",
    "    #so this function here will return a male, female count \n",
    "\n",
    "    nltk.tag.pos_tag(sentence)\n",
    "    tagged_sentence = nltk.tag.pos_tag(sentence)\n",
    "    lemma = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "    pn_tags = ('NNP', 'NNPS')\n",
    "    new_words = []\n",
    "\n",
    "    for word, tag in tagged_sentence: \n",
    "        if tag not in pn_tags: \n",
    "            if tag.startswith(\"V\"):\n",
    "                lemmas = lemma.lemmatize(word, \"v\")\n",
    "            else: \n",
    "                lemmas = lemma.lemmatize(word)\n",
    "            \n",
    "            new_words.append((lemmas))\n",
    "        #!# We need to add an else statement here to process PN words, there could be some trickyness here but it should be fine. \n",
    "        #else:\n",
    "            #gender = Genderize().get(word)\n",
    "            #reteurns 'male' and 'female' \n",
    "                #if gender = 'male'\n",
    "                 #   malelistcount add 1\n",
    "                #if gender = 'female'\n",
    "                 #   femalelistcount add 1\n",
    "\n",
    "\n",
    "    sentence = new_words\n",
    "\n",
    "    # Expand contractions\n",
    "    if True:\n",
    "        new_text = []\n",
    "        for word in sentence:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "    \n",
    "    \n",
    "    # remove stopwords\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        sentence = [w for w in sentence if not w in stops]\n",
    "\n",
    "    #!  here we check for words from the gender words and we ensure they are removed from the tokens. this will ensure we have 0 leakage\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "#text = \"I ate a sandwich and it was very tasty\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df['encoded_sentences'] = sentences_df['sentences'].apply(tidy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>female_count</th>\n",
       "      <th>male_count</th>\n",
       "      <th>col_type</th>\n",
       "      <th>encoded_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris used methadone for five years to help we...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[use, methadone, five, year, help, wean, heroi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"I heard about Ratho Hall, and it's given me t...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, hear, give, wake, call, I, need, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chris was prescribed methadone, a synthetic op...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[prescribe, methadone, synthetic, opiate, take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>In this, the Community Safety Minister, Fergus...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[In, explain, want, see, new, vision, drug, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chris, who started to use heroin when he was 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[start, use, heroin, talk, addiction, When, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225598</th>\n",
       "      <td>\"For Diego, it is good for him to see the norm...</td>\n",
       "      <td>15819</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[For, good, see, normal, rearing, process, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225601</th>\n",
       "      <td>The new monkey will stay at the zoo until he r...</td>\n",
       "      <td>15819</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, new, monkey, stay, zoo, reach, sexual, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225605</th>\n",
       "      <td>He died in hospital.</td>\n",
       "      <td>15820</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[He, die, hospital]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225645</th>\n",
       "      <td>He said: \"Local authorities need to recognise ...</td>\n",
       "      <td>15823</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[He, say, authority, need, recognise, regional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225652</th>\n",
       "      <td>For him, it is an attempt to redefine voluntar...</td>\n",
       "      <td>15824</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[For, attempt, redefine, voluntary, work, deep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49408 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentences  article_id  year  \\\n",
       "4       Chris used methadone for five years to help we...           0  2010   \n",
       "6       \"I heard about Ratho Hall, and it's given me t...           0  2010   \n",
       "7       Chris was prescribed methadone, a synthetic op...           0  2010   \n",
       "12      In this, the Community Safety Minister, Fergus...           0  2010   \n",
       "14      Chris, who started to use heroin when he was 1...           0  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "225598  \"For Diego, it is good for him to see the norm...       15819  2010   \n",
       "225601  The new monkey will stay at the zoo until he r...       15819  2010   \n",
       "225605                               He died in hospital.       15820  2010   \n",
       "225645  He said: \"Local authorities need to recognise ...       15823  2010   \n",
       "225652  For him, it is an attempt to redefine voluntar...       15824  2010   \n",
       "\n",
       "        female_count  male_count col_type  \\\n",
       "4                  0           3        1   \n",
       "6                  0           1        1   \n",
       "7                  0           2        1   \n",
       "12                 0           1        1   \n",
       "14                 0           2        1   \n",
       "...              ...         ...      ...   \n",
       "225598             0           2        1   \n",
       "225601             0           3        1   \n",
       "225605             0           1        1   \n",
       "225645             0           1        1   \n",
       "225652             0           1        1   \n",
       "\n",
       "                                        encoded_sentences  \n",
       "4       [use, methadone, five, year, help, wean, heroi...  \n",
       "6               [I, hear, give, wake, call, I, need, say]  \n",
       "7       [prescribe, methadone, synthetic, opiate, take...  \n",
       "12      [In, explain, want, see, new, vision, drug, tr...  \n",
       "14      [start, use, heroin, talk, addiction, When, he...  \n",
       "...                                                   ...  \n",
       "225598  [For, good, see, normal, rearing, process, wit...  \n",
       "225601  [The, new, monkey, stay, zoo, reach, sexual, m...  \n",
       "225605                                [He, die, hospital]  \n",
       "225645  [He, say, authority, need, recognise, regional...  \n",
       "225652  [For, attempt, redefine, voluntary, work, deep...  \n",
       "\n",
       "[49408 rows x 7 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.get_dummies(sentences_df.year)\n",
    "#rated_dummies = pd.get_dummies((sentences_df).year)\n",
    "#sentences_df = pd.concat([sentences_df, rated_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = sentences_df[['encoded_sentences', '2010', '2012']]\n",
    "#y = sentences_df[\"col_type\"]\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sentences_df['encoded_sentences']\n",
    "y = sentences_df['col_type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_t, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(max_features= 1000, lowercase=False, tokenizer=False)\n",
    "def fake(token):\n",
    "    return token\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=fake,\n",
    "    preprocessor=fake,\n",
    "    token_pattern=None)  \n",
    "\n",
    "X_t = tfidf.fit_transform(X)\n",
    "#X_train = tfidf.fit_transform(X_train)\n",
    "#X_test = tfidf.fit_transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary Logistics Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV Packages\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# parameter grid\n",
    "parameters = {\"penalty\": ['l1','l2'], \n",
    "              \"C\": np.logspace(-3,3,7),\n",
    "              \"solver\": ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV\n",
    "logreg = LogisticRegression()\n",
    "clf_logreg = GridSearchCV(logreg, \n",
    "                          param_grid = parameters, \n",
    "                          scoring = \"accuracy\", \n",
    "                          cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finetuned model with best hyperparameters \n",
    "logreg1 = LogisticRegression(C=0.1, penalty = \"l2\", solver = \"liblinear\", max_iter = 5000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression(C = 0.1, penalty = \"l2\", solver = \"liblinear\", max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, solver='liblinear')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_logreg = logreg1.fit(X_train, y_train)\n",
    "fitted_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = fitted_logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8582270795385549\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",fitted_logreg.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 is better to prevent overfitting than L1 because it punishes errors more (squares them as opposed to taking the absolute value). GridSearchCV said either L1 or L2 were equally as good though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest coefs\n",
      "('He', 15.727315039161565)\n",
      "('His', 7.467566777876769)\n",
      "('man', 4.3397941552226635)\n",
      "('wife', 3.8827756924014567)\n",
      "('soldier', 2.646811096063486)\n",
      "('shoot', 2.474074718318458)\n",
      "('general', 1.9728945249627372)\n",
      "('boy', 1.9528321539953917)\n",
      "('player', 1.9137759838719437)\n",
      "('football', 1.8083109516570461)\n",
      "lowest coefs\n",
      "('female', -2.9502895317018543)\n",
      "('boyfriend', -3.245074680432046)\n",
      "('mother', -3.4304259369500096)\n",
      "('daughter', -3.621111448681256)\n",
      "('actress', -4.277934839317325)\n",
      "('girl', -5.307364280267746)\n",
      "('husband', -6.295752606185669)\n",
      "('woman', -7.245390395868678)\n",
      "('Her', -9.577062358981655)\n",
      "('She', -18.650879417534796)\n"
     ]
    }
   ],
   "source": [
    "coefs = fitted_logreg.coef_[0]\n",
    "\n",
    "#male is 1 and female is 0\n",
    "\n",
    "sorted_coef = sorted((zip(tfidf.get_feature_names(), coefs)), key = lambda x: x[1], reverse=True)\n",
    "\n",
    "high_coef = sorted_coef[:10]\n",
    "low_coef = sorted_coef[-10:]\n",
    "\n",
    "print(\"highest coefs\")\n",
    "for i in high_coef: \n",
    "    print(i)\n",
    "\n",
    "print(\"lowest coefs\")\n",
    "for i in low_coef: \n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, male coefficient for neutral is higher than the female. Otherwise, as expected, the coefficients for female and male each are correspondingly high for each gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8582270795385549\n",
      "[[ 816 1312]\n",
      " [  89 7665]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.38      0.54      2128\n",
      "           1       0.85      0.99      0.92      7754\n",
      "\n",
      "    accuracy                           0.86      9882\n",
      "   macro avg       0.88      0.69      0.73      9882\n",
      "weighted avg       0.86      0.86      0.83      9882\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, prediction)) #accuracy \n",
    "print(metrics.confusion_matrix(y_test, prediction)) #confusion matrix\n",
    "print(metrics.classification_report(y_test, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
