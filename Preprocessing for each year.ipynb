{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('omw-1.4')\n",
    "#nltk.download('maxent_ne_chunker')\n",
    "#nltk.download('words')\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import treebank_chunk\n",
    "import re\n",
    "from genderize import Genderize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick a year, open the pickle and run everything\n",
    "\n",
    "year = \"2010\"\n",
    "file_name = \"2010_raw_data.pickle\"\n",
    "file_location = \"C:/Users/DanielleDuncan/Documents/Masters-Thesis/2010_raw_data.pickle\"\n",
    "\n",
    "raw_df = pd.read_pickle(file_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreProcessing (sentence):\n",
    "    Male_count = 0\n",
    "    Female_count = 0\n",
    "    APIcallfail= 0\n",
    "    PN_true = None\n",
    "\n",
    "#regex_cleanup\n",
    "    sentence = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', sentence)\n",
    "    sentence = re.sub(r'\\<a href', ' ', sentence)\n",
    "    sentence = re.sub(r'&amp;', '', sentence) \n",
    "    sentence = re.sub(\"\\d+\", \" \", sentence)\n",
    "    sentence = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', sentence)\n",
    "    sentence = re.sub(r'<br />', ' ', sentence)\n",
    "    sentence = re.sub(r\"\\b's\\b\", '', sentence)\n",
    "\n",
    "#tokenize\n",
    "    sentence =  nltk.TweetTokenizer().tokenize(sentence)\n",
    "#remove small words\n",
    "    sentence = [ x for x in sentence if len(x) >= 2 ]\n",
    "\n",
    "#tag_and_stem\n",
    "    tagged_sentence = nltk.tag.pos_tag(sentence)\n",
    "    lemma = nltk.stem.WordNetLemmatizer()\n",
    "    pn_tags = {'NNP', 'NNPS'}\n",
    "\n",
    "    new_words = []\n",
    "    proper_nouns = []\n",
    "    PN_list = []\n",
    "\n",
    "    for word, tag in tagged_sentence: \n",
    "        if tag not in pn_tags: \n",
    "            if tag.startswith(\"V\"):\n",
    "                lemmas = lemma.lemmatize(word, \"v\")\n",
    "            else: \n",
    "                lemmas = lemma.lemmatize(word)\n",
    "            new_words.append((lemmas))\n",
    "        else:\n",
    "            proper_nouns.append([word, tag])\n",
    "\n",
    "    sentence = new_words\n",
    "\n",
    "#name_gender\n",
    "    #nltk_results = ne_chunk(tagged_sentence)\n",
    "    nltk_results = ne_chunk(proper_nouns)\n",
    "\n",
    "    for nltk_result in nltk_results:\n",
    "        if type(nltk_result) == Tree:\n",
    "            name = ''\n",
    "            for nltk_result_leaf in nltk_result.leaves():\n",
    "                name += nltk_result_leaf[0] + ' '\n",
    "            if nltk_result.label() == \"PERSON\":\n",
    "                name = name.split(' ')[0]\n",
    "                PN_list.append(name)\n",
    "            else: \n",
    "                sentence.append(name.strip()) #add a tokenize\n",
    "    \n",
    "#Lower\n",
    "    sentence = [x.lower() for x in sentence]\n",
    "\n",
    "#contractions\n",
    "    new_text = []\n",
    "    for word in sentence:\n",
    "        contraction = contractions.get(word)\n",
    "        if contraction is None:\n",
    "            new_text.append(word)\n",
    "        else:\n",
    "            for word in contraction.split():\n",
    "                new_text.append(word)\n",
    "\n",
    "    sentence = new_text\n",
    "\n",
    "\n",
    "#gendered_count\n",
    "    for w in sentence:\n",
    "        if w in male_list:\n",
    "            Male_count += 1\n",
    "            print(w, \"counted male word\")\n",
    "        if w in female_list:\n",
    "            Female_count += 1\n",
    "\n",
    "\n",
    "#remove_stopwords\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    sentence = [x for x in sentence if not x in stops]\n",
    "\n",
    "#check for PN\n",
    "    if len(PN_list) > 1:\n",
    "        PN_true = True\n",
    "\n",
    "#remove_leakage\n",
    "    new_sent = [x for x in sentence if x not in male_list]\n",
    "    new_sent = [x for x in new_sent if x not in female_list]\n",
    "    sentence = new_sent\n",
    "\n",
    "    return sentence, Male_count, Female_count, PN_list, PN_true\n",
    "\n",
    "#if still having memory issues we needd to chunk the dataset \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REFERENCE LISTS--TO BE CHANGED\n",
    "#male_list= #{\"abbot\", \"abbots\", \"actor\", \"actors\", \"author\", \"authors\", \"bachelor\", \"bachelors\", \"baron\", \"barons\", \"boy\", \"boys\", \"bridegroom\", \"bridegrooms\", \"brother\", \"brothers\", \"buck\", \n",
    "            #\"bucks\", \"conductor\", \"conductors\", \"czar\", \"czars\", \"dad\", \"daddy\", \"daddys\", \"dads\", \"duke\", \"dukes\", \"emperor\", \"emperors\", \"enchanter\", \"enchanters\", \"father\", \"fathers\", \n",
    "            #\"gentleman\", \"gentlemans\", \"granddad\", \"granddads\", \"grandfather\", \"grandfathers\", \"grandpa\", \"he\", \"heir\", \"heirs\", \"hero\", \"heros\", \"hes\", \"him\", \"his\", \"host\", \"hosts\", \"hunter\", \n",
    "            #\"hunters\", \"husband\", \"husbands\", \"king\", \"kings\", \"landlord\", \"landlords\", \"lord\", \"lords\", \"man\", \"mans\", \"manservant\", \"manservants\", \"master\", \"masters\", \"men\", \"milkman\", \n",
    "            #\"milkmans\", \"mister\", \"monk\", \"monks\", \"mr\", \"nephew\", \"nephews\", \"patron\", \"patrons\", \"peacock\", \"peacocks\", \"peer\", \"peers\", \"poet\", \"poets\", \"policeman\", \"policemans\", \"policemen\", \n",
    "            #\"policemens\", \"priest\", \"priests\", \"prince\", \"princes\", \"prophet\", \"prophets\", \"shepherd\", \"shepherds\", \"signor\", \"signors\", \"sir\", \"sirs\", \"son\", \"songster\", \"songsters\", \"sons\", \n",
    "            #\"stag\", \"stags\", \"stallion\", \"stallions\", \"stepbrother\", \"stepbrothers\", \"stepdad\", \"stepdads\", \"stepfather\", \"stepfathers\", \"steward\", \"stewards\", \"sultan\", \"sultans\", \"traitor\", \n",
    "            #\"traitors\", \"uncle\", \"uncles\", \"viscount\", \"viscounts\", \"waiter\", \"waiters\", \"wizard\", \"wizards\"}\n",
    "\n",
    "#female_list ={#\"abbess\", \"abbesses\", \"actress\", \"actresses\", \"aunt\", \"aunts\", \"authoress\", \"authoresses\", \"baroness\", \"baronesses\", \"benefactress\", \"benefactresses\", \"bride\", \"brides\", \n",
    "              #\"conductress\", \"conductresses\", \"countess\", \"countesses\", \"czarina\", \"czarinas\", \"daughter\", \"daughters\", \"duchess\", \"duchesses\", \"empress\", \"empresses\", \"enchantress\", \n",
    "              #\"enchantresses\", \"giantess\", \"giantesses\", \"girl\", \"girls\", \"goddess\", \"goddesses\", \"grandma\", \"grandmas\", \"grandmother\", \"grandmothers\", \"heiress\", \"heiresses\", \"hen\", \n",
    "              #\"hens\", \"her\", \"heroine\", \"heroines\", \"hers\", \"hostess\", \"hostesses\", \"huntress\", \"huntresses\", \"ladies\", \"lady\", \"landladies\", \"landlady\", \"lioness\", \"lionesses\", \"madam\", \n",
    "              #\"madams\", \"maidservant\", \"maidservants\", \"milkmaid\", \"milkmaids\", \"misses\", \"missus\", \"mistress\", \"mistresses\", \"mom\", \"mommy\", \"mommys\", \"moms\", \"mother\", \"mothers\", \"mrs\", \"ms\",\n",
    "              #\"mum\", \"mummy\", \"mummys\", \"mums\", \"murderess\", \"murderesses\", \"niece\", \"nieces\", \"nun\", \"nuns\", \"patroness\", \"patronesses\", \"poetess\", \"poetesses\", \"policewoman\", \"policewomen\", \n",
    "              #\"priestess\", \"priestesses\", \"princess\", \"princesses\", \"prophetess\", \"prophetesses\", \"queen\", \"queens\", \"she\", \"shepherdess\", \"shepherdesses\", \"shes\", \"signora\", \"signoras\", \n",
    "                #\"sister\", \"sisters\", \"songstress\", \"songstresses\", \"spinster\", \"spinsters\", \"stepdaughter\", \"stepdaughters\", \"stepmom\", \"stepmoms\", \"stepmother\", \"stepmothers\", \"stewardess\", \n",
    "                #\"stewardesses\", \"sultana\", \"sultanas\", \"temptress\", \"temptresses\", \"tigress\", \"tigresses\", \"traitress\", \"traitresses\", \"viscountess\", \"viscountesses\", \"vixen\", \"vixens\", \n",
    "                #\"waitress\", \"waitresses\", \"wife\", \"witch\", \"witches\", \"wive\", \"woman\", \"women\"}\n",
    "\n",
    "male_list = {\"man\", \"boy\", \"he\", \"father\", \"son\", \"guy\", \"male\", \"his\", \"himself\", \"grandpa\", \"grandpas\", \"grandson\", \"grandsons\", \"uncle\", \"husband\", \"boy\", \"brother\", \"dad\", \"dude\", \"fella\", \"gentleman\", \"gentlemen\", \n",
    "             \"men\", \"nephew\", \"nephews\", \"sir\", \"sirs\", \"lord\", \"count\", \"duke\", \"lad\", \"mr\", \"viscount\", \"daddy\", \"boys\", \"guys\", \"sons\", \"uncles\", \"sons\", \"misters\", \"mister\", \"dukes\", \"daddies\", \"sons\", \"lords\", \n",
    "             \"fellas\", \"stepfather\", \"stepfathers\", \"dads\", \"emperor\", \"emperors\"}\n",
    "female_list = {\"woman\", \"girl\", \"she\", \"mother\", \"daughter\", \"gal\", \"gals\", \"female\", \"her\", \"hers\", \"herself\", \"grandma\", \"grandmas\", \"granddaughter\", \"aunt\", \"wife\", \"wives\", \"sister\", \"sisters\", \"mum\", \n",
    "               \"mums\", \"gal\", \"granny\", \"lady\", \"women\", \"niece\", \"nieces\", \"dame\", \"countess\", \"duchess\", \"ladies\", \"mrs\", \"ms\", \"viscountess\", \"mummy\", \"girls\", \"daughters\", \"aunts\", \"daughters\", \"misses\", \n",
    "               \"missus\", \"grannies\", \"dames\", \"mummies\", \"stepsister\", \"empress\", \"empresses\", \"sisters\", \"mummys\", \"stepmother\", \"stepmothers\"}\n",
    "\n",
    "#Bolukbasi et al repo with words: https://github.com/tolga-b/debiaswe/blob/master/data/gender_specific_full.json\n",
    "\n",
    "#should all gendered words be counted as a gendered thing???\n",
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['encoded_sentences'] = raw_df['sentences'].apply(PreProcessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df_split = pd.DataFrame(raw_df[\"encoded_sentences\"].to_list(), columns=['pre_processed_sent','male_count','female_count','Proper_noun_list', 'pn exists'])\n",
    "result = pd.concat([raw_df_split, (raw_df.reset_index(drop=True))], axis=1)\n",
    "result = result.drop(\"encoded_sentences\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_count(male_col, female_col): \n",
    "    \"\"\"This function compares the count of female to male pronouns. It will output \"1\" if male count bigger\n",
    "    than female count, \"neutral\" if the count is equal, and \"female\" if there is a higher female count. \n",
    "    The function returns strings because we need categorical variables for log reg to run\"\"\"\n",
    "    if female_col > male_col:\n",
    "        return \"1\"\n",
    "    elif male_col > female_col:\n",
    "        return \"0\"\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['col_type'] = result.apply(lambda row: compare_count(row['male_count'], row['female_count']),axis=1)\n",
    "#lol mistake here\n",
    "result = result[result[\"col_type\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the df\n",
    "new_file_name = year + \"_text_wo_names.pickle\"\n",
    "\n",
    "with open(new_file_name, 'wb') as handle:\n",
    "    pickle.dump(result, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
