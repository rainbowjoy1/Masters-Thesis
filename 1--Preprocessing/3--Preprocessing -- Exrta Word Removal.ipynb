{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PP Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words to manually remove\n",
    "weird_words = [\"radioâ\", \"wouldnâ\", \"yearâ\", \"ofâ \", \"doesnâ\", \"heâ\", \"stryder\", \"differentâ\", \n",
    "        \"fiancã\", \"holdall\", \"hui\", \"norgrove \", \"iii\", \"shalifea\", \"xhosa\", \"kaaben\", \"hs\", \n",
    "        \"suah\", \"qeii\", \"rey\", \"ramanya\", \"omooba\", \"shekau\",\"female\", \"granddaughter\", \"guy\", \"spokeswoman\", \"women\", \"businessman\", \n",
    "        \"lad\", \"chairman\", \"businessman\", \"chairman\", \"lewis\", \"alexandra\", \"ellie\", \"george\", \"griffin\", \"jade\", \"beyoncé\", \n",
    "        \"heidi\", \"keisha\", \"gerry\", \"florence\", \"neil\", \"liam\", \"simon\", \"mcchrystal\", \n",
    "        \"fifa\", \"megrahi\", \"josh\", \"isabella\", \"helen\", \"nadine\", \"raytheon\", \"cheryl\", \n",
    "        \"laura\", \"eileen\", \"amanda\", \"jacqueline\", \"wolstencroft\", \"gagarin\", \"swinney\", \n",
    "        \"coulson\", \"lonergan\", \"werritty\", \"sandusky\", \"lyle\", \"bale\", \"jong\", \"romney\", \n",
    "        \"maxwell\", \"olly\", \"zuckerbeg\", \"terence\", \"elbaradei\", \"jonathan\", \"adele\", \n",
    "        \"sophie\", \"dorrian\", \"jessie\", \"zhai\", \"tymoshenko\", \"leila\", \"sturgeon\", \n",
    "        \"jessica\", \"julia\", \"malala\", \"lily\", \"amelia\", \"merkel\", \"kirsty\", \"frances\", \n",
    "        \"emma\", \"ben\", \"duncan\", \"carolina\", \"ben\", \"ian\", \"thatcher\", \"ruth\", \"katy\", \n",
    "        \"jayalalitha\", \"gwen\", \"nadia\", \"iris\", \"adina\", \"louie\", \"kerry\", \"gervais\", \n",
    "        \"grande\", \"scherzinger\", \"warren\", \"ormond\", \"randy\", \"giuliani\", \"evie\", \n",
    "        \"priti\", \"valerie\", \"serena\", \"lorde\", \"ivanka\", \"rachel\", \"manning\", \"ariana\", \n",
    "        \"josephine\", \"caroline\", \"christine\", \"mccomb\", \"jodie\", \"marie\", \"elle\", \n",
    "        \"dorian\", \"amina\", \"amelia\", \"nelly\", \"tara\", \"denise\", \"mina\", \"amy\", \"aretha\", \n",
    "        \"lula\", \"alfie\", \"joel\", \"jon\", \"arthur\", \"henry\", \"butina\", \"priya\", \"willie\", \n",
    "        \"yousef\", \"malcolm\", \"spacey\", \"jared\", \"karanbir\", \"paddy\", \"cardi\", \n",
    "        \"therese\", \"carolyn\", \"kristina\", \"tamara\", \"jeni\", \"yvonne\", \"canela\", \n",
    "        \"olga\", \"claire\", \"audie\", \"natasha\", \"sturgess\", \"madonna\", \"diaz\", \"tania\", \n",
    "        \"anita\", \"braun\", \"mackinnon\", \"ethan\", \"greg\", \"dicaprio\", \"oliver\", \"matthew\", \n",
    "        \"musk\", \"mohamed\", \"anthony\", \"eddie\", \"dylan\", \"adil\", \"mckeigue\", \"sebastian\", \n",
    "        \"greensill\", \"nigel\", \"iain\", \"limbaugh\", \"wjec\", \"noah\", \"mcconnell\", \n",
    "        \"sorokin\", \"loretta\", \"ruby\", \"lucy\", \"dorothy\", \"luisa\", \"carrie\", \"ella\", \n",
    "        \"eilidh\", \"halima\", \"jess\", \"michaela\", \"almeida\", \"mcdormand\", \"bea\", \"xia\",\n",
    "        \"jill\", \"stuart\", \"tï\", \"djokovic\", \"keir\", \"sheeran\", \"dave\", \"jamie\", \n",
    "        \"chris\", \"zara\", \"mcgarry\", \"kate\", \"cressida\", \"chloe\", \"eilish\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = ['2016', '2017', '2018', '2019', '2020', '2021', '2022']\n",
    "file_path = \"C:/Users/danie/Desktop/Masters Thesis/New Preprocessing/\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_remove(sent):\n",
    "    sent = [x for x in sent if x not in weird_words]\n",
    "    string_rnn = ' '.join(sent)\n",
    "    return sent, string_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in year_list:\n",
    "\n",
    "    raw_df = pd.read_pickle(file_path + year + \"_text_wo_names.pickle\")\n",
    "\n",
    "    raw_df['new_sents'] = raw_df['pre_processed_sent'].apply(word_remove)\n",
    "\n",
    "    raw_df = raw_df.drop(columns=\"pre_processed_sent\")\n",
    "    raw_df_split = pd.DataFrame(raw_df[\"new_sents\"].to_list(), columns=['pre_processed_sent','string_rnn'])\n",
    "    result = pd.concat([raw_df_split, (raw_df.reset_index(drop=True))], axis=1)\n",
    "    result = result.drop(\"new_sents\", axis=1)\n",
    "\n",
    "    new_file_name = \"C:/Users/danie/Desktop/Masters Thesis/New Clean Data for Log Reg/\" + year + \"_final_rnn.pickle\"\n",
    "\n",
    "    with open(new_file_name, 'wb') as handle:\n",
    "        pickle.dump(result, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
