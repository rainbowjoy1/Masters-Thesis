{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#warnings \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#for RNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "\n",
    "import pickle\n",
    "\n",
    "import ast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Sentences for testing RNNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2022\"\n",
    "path = \"C:/Users/DanielleDuncan/Desktop/THESIS/pickled_years/RNN_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.read_pickle(\"pos_tag_word_list\")\n",
    "sent_df = pd.read_csv(\"sample sent idea.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_string(sents):\n",
    "    list_of_strings = []\n",
    "\n",
    "    for word_list in sents:\n",
    "        list_of_strings.append(' '.join(word_list))\n",
    "    return list_of_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df['list'] = sent_df['list'].apply(ast.literal_eval)\n",
    "benchmark_sentences = sent_df['list'].tolist()\n",
    "all_benchmarks = benchmark_string(benchmark_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(path+year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "X_b = all_benchmarks\n",
    "x_arrayb = np.asarray(X_b)\n",
    "y_predb = loaded_model.predict(X_b)\n",
    "Yb = pd.DataFrame(y_predb)\n",
    "Yb.reset_index(inplace=True, drop=True)\n",
    "Yb.set_axis(['0 Class Benchamark', '1 Class Benchmark'], axis='columns', inplace=True)\n",
    "sent_df = pd.concat([sent_df, Yb], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test RNN model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NOUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df['replacement string'] = sent_df['replacement string'].apply(ast.literal_eval)\n",
    "\n",
    "\n",
    "noun_list = word_df[(word_df.pos_tag_short == \"N\")][\"feature\"].values.tolist()\n",
    "verb_list = word_df[(word_df.pos_tag_short == \"V\")][\"feature\"].values.tolist()\n",
    "adverb_list = word_df[(word_df.pos_tag_short == \"R\")][\"feature\"].values.tolist()\n",
    "adjective_list = word_df[(word_df.pos_tag_short == \"J\")][\"feature\"].values.tolist()\n",
    "\n",
    "noun_sent = sent_df[(sent_df['POS tag'] == \"Noun\")][\"replacement string\"].values.tolist()\n",
    "verb_sent = sent_df[(sent_df['POS tag'] == \"Verb\")][\"replacement string\"].values.tolist()\n",
    "adjective_sent = sent_df[(sent_df['POS tag'] == \"Adjective\")][\"replacement string\"].values.tolist()\n",
    "adverb_sent = sent_df[(sent_df['POS tag'] == \"Adverb\")][\"replacement string\"].values.tolist()\n",
    "\n",
    "adverb_len = len(adverb_sent)\n",
    "adjective_len = len(adjective_sent)\n",
    "noun_len = len(noun_sent)\n",
    "verb_len = len(verb_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_list(sublist, sentences):\n",
    "    output=[]\n",
    "    for sentence in sentences:\n",
    "        index=sentence.index('UNK')\n",
    "        sentence_copy = sentence.copy()\n",
    "        for sub in sublist:\n",
    "            sentence_copy[index]=sub\n",
    "            output.append([' '.join(sentence_copy.copy()),sentence])\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "sent_n = pd.DataFrame(word_list(noun_list, noun_sent))\n",
    "sent_j = pd.DataFrame(word_list(adjective_list, adjective_sent))\n",
    "sent_a = pd.DataFrame(word_list(adverb_list, adverb_sent))\n",
    "sent_v = pd.DataFrame(word_list(verb_list, verb_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1503/1503 [==============================] - 9s 6ms/step\n",
      "26/26 [==============================] - 0s 6ms/step\n",
      "82/82 [==============================] - 1s 7ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "x_array_n = np.asarray(sent_n[0])\n",
    "x_array_j = np.asarray(sent_j[0])\n",
    "x_array_v = np.asarray(sent_v[0])\n",
    "x_array_a = np.asarray(sent_a[0])\n",
    "\n",
    "\n",
    "y_pred_n = loaded_model.predict(x_array_n)\n",
    "y_pred_j = loaded_model.predict(x_array_j)\n",
    "y_pred_v = loaded_model.predict(x_array_v)\n",
    "y_pred_a = loaded_model.predict(x_array_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You need to change the num_repititons to the number of sentences in the function\n",
    "\n",
    "def labels(word_list, word_len):\n",
    "    num_repetitions = word_len\n",
    "    repeated_words = []\n",
    "    repeated_words = np.tile(word_list, word_len)\n",
    "    return repeated_words\n",
    "\n",
    "noun_labels = pd.DataFrame(labels(noun_list, noun_len))\n",
    "adjective_labels = pd.DataFrame(labels(adjective_list, adjective_len))\n",
    "verb_labels = pd.DataFrame(labels(verb_list, verb_len))\n",
    "adverb_labels = pd.DataFrame(labels(adverb_list, adverb_len))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_n = pd.DataFrame(y_pred_n)\n",
    "Y_j = pd.DataFrame(y_pred_j)\n",
    "Y_v = pd.DataFrame(y_pred_v)\n",
    "Y_a = pd.DataFrame(y_pred_a)\n",
    "\n",
    "result_n = pd.concat([noun_labels, Y_n,sent_n], axis=1)\n",
    "result_j = pd.concat([adjective_labels, Y_j,sent_j], axis=1)\n",
    "result_v = pd.concat([verb_labels, Y_v,sent_v], axis=1)\n",
    "result_a = pd.concat([adverb_labels, Y_a, sent_a], axis=1)\n",
    "\n",
    "result_n.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "result_j.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "result_v.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "result_a.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([result_a, result_v, result_j, result_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_with_source = pd.merge(result, word_df, on='feature', how='left')\n",
    "#verb problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_with_source = result_with_source.dropna()\n",
    "result_with_source['replacement string'] = result_with_source['replacement string'].apply(tuple)\n",
    "sent_df['replacement string'] = sent_df['replacement string'].apply(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(result_with_source, sent_df, on='replacement string', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class 0 Differential'] = df['0 Class'] - df['0 Class Benchamark']\n",
    "df['Class 1 Differential'] = df['1 Class'] - df['1 Class Benchmark']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>0 Class</th>\n",
       "      <th>1 Class</th>\n",
       "      <th>RNN Sentences</th>\n",
       "      <th>replacement string</th>\n",
       "      <th>source</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>pos_tag_short</th>\n",
       "      <th>snet id</th>\n",
       "      <th>list</th>\n",
       "      <th>sent</th>\n",
       "      <th>POS tag</th>\n",
       "      <th>word num</th>\n",
       "      <th>identified word</th>\n",
       "      <th>0 Class Benchamark</th>\n",
       "      <th>1 Class Benchmark</th>\n",
       "      <th>Class 0 Differential</th>\n",
       "      <th>Class 1 Differential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>friendly</td>\n",
       "      <td>0.907610</td>\n",
       "      <td>-0.673413</td>\n",
       "      <td>say guy hear sing think moyles year friendly</td>\n",
       "      <td>(say, guy, hear, sing, think, moyles, year, UNK)</td>\n",
       "      <td>communality</td>\n",
       "      <td>RB</td>\n",
       "      <td>R</td>\n",
       "      <td>7551</td>\n",
       "      <td>[say, guy, hear, sing, think, moyles, year, ago]</td>\n",
       "      <td>He said: \"Some guys heard me singing Tom Jones...</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>7</td>\n",
       "      <td>ago</td>\n",
       "      <td>0.335596</td>\n",
       "      <td>-0.137244</td>\n",
       "      <td>0.572014</td>\n",
       "      <td>-0.536169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just</td>\n",
       "      <td>0.961739</td>\n",
       "      <td>-0.663940</td>\n",
       "      <td>say guy hear sing think moyles year just</td>\n",
       "      <td>(say, guy, hear, sing, think, moyles, year, UNK)</td>\n",
       "      <td>communality</td>\n",
       "      <td>RB</td>\n",
       "      <td>R</td>\n",
       "      <td>7551</td>\n",
       "      <td>[say, guy, hear, sing, think, moyles, year, ago]</td>\n",
       "      <td>He said: \"Some guys heard me singing Tom Jones...</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>7</td>\n",
       "      <td>ago</td>\n",
       "      <td>0.335596</td>\n",
       "      <td>-0.137244</td>\n",
       "      <td>0.626143</td>\n",
       "      <td>-0.526696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sincere</td>\n",
       "      <td>1.484565</td>\n",
       "      <td>-1.164161</td>\n",
       "      <td>say guy hear sing think moyles year sincere</td>\n",
       "      <td>(say, guy, hear, sing, think, moyles, year, UNK)</td>\n",
       "      <td>communality</td>\n",
       "      <td>RB</td>\n",
       "      <td>R</td>\n",
       "      <td>7551</td>\n",
       "      <td>[say, guy, hear, sing, think, moyles, year, ago]</td>\n",
       "      <td>He said: \"Some guys heard me singing Tom Jones...</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>7</td>\n",
       "      <td>ago</td>\n",
       "      <td>0.335596</td>\n",
       "      <td>-0.137244</td>\n",
       "      <td>1.148968</td>\n",
       "      <td>-1.026917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cyberbully</td>\n",
       "      <td>0.467781</td>\n",
       "      <td>-0.247669</td>\n",
       "      <td>say guy hear sing think moyles year cyberbully</td>\n",
       "      <td>(say, guy, hear, sing, think, moyles, year, UNK)</td>\n",
       "      <td>Violence</td>\n",
       "      <td>RB</td>\n",
       "      <td>R</td>\n",
       "      <td>7551</td>\n",
       "      <td>[say, guy, hear, sing, think, moyles, year, ago]</td>\n",
       "      <td>He said: \"Some guys heard me singing Tom Jones...</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>7</td>\n",
       "      <td>ago</td>\n",
       "      <td>0.335596</td>\n",
       "      <td>-0.137244</td>\n",
       "      <td>0.132185</td>\n",
       "      <td>-0.110425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unruly</td>\n",
       "      <td>0.515528</td>\n",
       "      <td>-0.305455</td>\n",
       "      <td>say guy hear sing think moyles year unruly</td>\n",
       "      <td>(say, guy, hear, sing, think, moyles, year, UNK)</td>\n",
       "      <td>Violence</td>\n",
       "      <td>RB</td>\n",
       "      <td>R</td>\n",
       "      <td>7551</td>\n",
       "      <td>[say, guy, hear, sing, think, moyles, year, ago]</td>\n",
       "      <td>He said: \"Some guys heard me singing Tom Jones...</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>7</td>\n",
       "      <td>ago</td>\n",
       "      <td>0.335596</td>\n",
       "      <td>-0.137244</td>\n",
       "      <td>0.179932</td>\n",
       "      <td>-0.168211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54335</th>\n",
       "      <td>slender</td>\n",
       "      <td>2.762344</td>\n",
       "      <td>-2.257229</td>\n",
       "      <td>terrify slender play well together also score ...</td>\n",
       "      <td>(terrify, UNK, play, well, together, also, sco...</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9512</td>\n",
       "      <td>[terrify, pace, play, well, together, also, sc...</td>\n",
       "      <td>Aaron Lennon terrified the Croats with his pac...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1</td>\n",
       "      <td>pace</td>\n",
       "      <td>2.646646</td>\n",
       "      <td>-2.167005</td>\n",
       "      <td>0.115697</td>\n",
       "      <td>-0.090224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54336</th>\n",
       "      <td>handsome</td>\n",
       "      <td>4.153363</td>\n",
       "      <td>-3.414166</td>\n",
       "      <td>terrify handsome play well together also score...</td>\n",
       "      <td>(terrify, UNK, play, well, together, also, sco...</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9512</td>\n",
       "      <td>[terrify, pace, play, well, together, also, sc...</td>\n",
       "      <td>Aaron Lennon terrified the Croats with his pac...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1</td>\n",
       "      <td>pace</td>\n",
       "      <td>2.646646</td>\n",
       "      <td>-2.167005</td>\n",
       "      <td>1.506717</td>\n",
       "      <td>-1.247161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54337</th>\n",
       "      <td>fat</td>\n",
       "      <td>2.424461</td>\n",
       "      <td>-1.987079</td>\n",
       "      <td>terrify fat play well together also score twic...</td>\n",
       "      <td>(terrify, UNK, play, well, together, also, sco...</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9512</td>\n",
       "      <td>[terrify, pace, play, well, together, also, sc...</td>\n",
       "      <td>Aaron Lennon terrified the Croats with his pac...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1</td>\n",
       "      <td>pace</td>\n",
       "      <td>2.646646</td>\n",
       "      <td>-2.167005</td>\n",
       "      <td>-0.222185</td>\n",
       "      <td>0.179926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54338</th>\n",
       "      <td>thin</td>\n",
       "      <td>2.104884</td>\n",
       "      <td>-1.733965</td>\n",
       "      <td>terrify thin play well together also score twi...</td>\n",
       "      <td>(terrify, UNK, play, well, together, also, sco...</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9512</td>\n",
       "      <td>[terrify, pace, play, well, together, also, sc...</td>\n",
       "      <td>Aaron Lennon terrified the Croats with his pac...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1</td>\n",
       "      <td>pace</td>\n",
       "      <td>2.646646</td>\n",
       "      <td>-2.167005</td>\n",
       "      <td>-0.541762</td>\n",
       "      <td>0.433039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54339</th>\n",
       "      <td>beautiful</td>\n",
       "      <td>2.277546</td>\n",
       "      <td>-1.864667</td>\n",
       "      <td>terrify beautiful play well together also scor...</td>\n",
       "      <td>(terrify, UNK, play, well, together, also, sco...</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9512</td>\n",
       "      <td>[terrify, pace, play, well, together, also, sc...</td>\n",
       "      <td>Aaron Lennon terrified the Croats with his pac...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1</td>\n",
       "      <td>pace</td>\n",
       "      <td>2.646646</td>\n",
       "      <td>-2.167005</td>\n",
       "      <td>-0.369100</td>\n",
       "      <td>0.302338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54340 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature   0 Class   1 Class  \\\n",
       "0        friendly  0.907610 -0.673413   \n",
       "1            just  0.961739 -0.663940   \n",
       "2         sincere  1.484565 -1.164161   \n",
       "3      cyberbully  0.467781 -0.247669   \n",
       "4          unruly  0.515528 -0.305455   \n",
       "...           ...       ...       ...   \n",
       "54335     slender  2.762344 -2.257229   \n",
       "54336    handsome  4.153363 -3.414166   \n",
       "54337         fat  2.424461 -1.987079   \n",
       "54338        thin  2.104884 -1.733965   \n",
       "54339   beautiful  2.277546 -1.864667   \n",
       "\n",
       "                                           RNN Sentences  \\\n",
       "0           say guy hear sing think moyles year friendly   \n",
       "1               say guy hear sing think moyles year just   \n",
       "2            say guy hear sing think moyles year sincere   \n",
       "3         say guy hear sing think moyles year cyberbully   \n",
       "4             say guy hear sing think moyles year unruly   \n",
       "...                                                  ...   \n",
       "54335  terrify slender play well together also score ...   \n",
       "54336  terrify handsome play well together also score...   \n",
       "54337  terrify fat play well together also score twic...   \n",
       "54338  terrify thin play well together also score twi...   \n",
       "54339  terrify beautiful play well together also scor...   \n",
       "\n",
       "                                      replacement string       source pos_tag  \\\n",
       "0       (say, guy, hear, sing, think, moyles, year, UNK)  communality      RB   \n",
       "1       (say, guy, hear, sing, think, moyles, year, UNK)  communality      RB   \n",
       "2       (say, guy, hear, sing, think, moyles, year, UNK)  communality      RB   \n",
       "3       (say, guy, hear, sing, think, moyles, year, UNK)     Violence      RB   \n",
       "4       (say, guy, hear, sing, think, moyles, year, UNK)     Violence      RB   \n",
       "...                                                  ...          ...     ...   \n",
       "54335  (terrify, UNK, play, well, together, also, sco...    Apperance      NN   \n",
       "54336  (terrify, UNK, play, well, together, also, sco...    Apperance      NN   \n",
       "54337  (terrify, UNK, play, well, together, also, sco...    Apperance      NN   \n",
       "54338  (terrify, UNK, play, well, together, also, sco...    Apperance      NN   \n",
       "54339  (terrify, UNK, play, well, together, also, sco...    Apperance      NN   \n",
       "\n",
       "      pos_tag_short  snet id  \\\n",
       "0                 R     7551   \n",
       "1                 R     7551   \n",
       "2                 R     7551   \n",
       "3                 R     7551   \n",
       "4                 R     7551   \n",
       "...             ...      ...   \n",
       "54335             N     9512   \n",
       "54336             N     9512   \n",
       "54337             N     9512   \n",
       "54338             N     9512   \n",
       "54339             N     9512   \n",
       "\n",
       "                                                    list  \\\n",
       "0       [say, guy, hear, sing, think, moyles, year, ago]   \n",
       "1       [say, guy, hear, sing, think, moyles, year, ago]   \n",
       "2       [say, guy, hear, sing, think, moyles, year, ago]   \n",
       "3       [say, guy, hear, sing, think, moyles, year, ago]   \n",
       "4       [say, guy, hear, sing, think, moyles, year, ago]   \n",
       "...                                                  ...   \n",
       "54335  [terrify, pace, play, well, together, also, sc...   \n",
       "54336  [terrify, pace, play, well, together, also, sc...   \n",
       "54337  [terrify, pace, play, well, together, also, sc...   \n",
       "54338  [terrify, pace, play, well, together, also, sc...   \n",
       "54339  [terrify, pace, play, well, together, also, sc...   \n",
       "\n",
       "                                                    sent POS tag  word num  \\\n",
       "0      He said: \"Some guys heard me singing Tom Jones...  Adverb         7   \n",
       "1      He said: \"Some guys heard me singing Tom Jones...  Adverb         7   \n",
       "2      He said: \"Some guys heard me singing Tom Jones...  Adverb         7   \n",
       "3      He said: \"Some guys heard me singing Tom Jones...  Adverb         7   \n",
       "4      He said: \"Some guys heard me singing Tom Jones...  Adverb         7   \n",
       "...                                                  ...     ...       ...   \n",
       "54335  Aaron Lennon terrified the Croats with his pac...    Noun         1   \n",
       "54336  Aaron Lennon terrified the Croats with his pac...    Noun         1   \n",
       "54337  Aaron Lennon terrified the Croats with his pac...    Noun         1   \n",
       "54338  Aaron Lennon terrified the Croats with his pac...    Noun         1   \n",
       "54339  Aaron Lennon terrified the Croats with his pac...    Noun         1   \n",
       "\n",
       "      identified word  0 Class Benchamark  1 Class Benchmark  \\\n",
       "0                 ago            0.335596          -0.137244   \n",
       "1                 ago            0.335596          -0.137244   \n",
       "2                 ago            0.335596          -0.137244   \n",
       "3                 ago            0.335596          -0.137244   \n",
       "4                 ago            0.335596          -0.137244   \n",
       "...               ...                 ...                ...   \n",
       "54335            pace            2.646646          -2.167005   \n",
       "54336            pace            2.646646          -2.167005   \n",
       "54337            pace            2.646646          -2.167005   \n",
       "54338            pace            2.646646          -2.167005   \n",
       "54339            pace            2.646646          -2.167005   \n",
       "\n",
       "       Class 0 Differential  Class 1 Differential  \n",
       "0                  0.572014             -0.536169  \n",
       "1                  0.626143             -0.526696  \n",
       "2                  1.148968             -1.026917  \n",
       "3                  0.132185             -0.110425  \n",
       "4                  0.179932             -0.168211  \n",
       "...                     ...                   ...  \n",
       "54335              0.115697             -0.090224  \n",
       "54336              1.506717             -1.247161  \n",
       "54337             -0.222185              0.179926  \n",
       "54338             -0.541762              0.433039  \n",
       "54339             -0.369100              0.302338  \n",
       "\n",
       "[54340 rows x 18 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"RNN_Test_Sentences_\"+year\n",
    "\n",
    "with open(file_name, 'wb') as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"test_2022.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a section that labels the columns for the year and drops the uneeded oned. \n",
    "df = df.drop(['list','sent','pos_tag','pos_tag_short','RNN Sentences','replacement string', 'word num','identified word'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>2022_0_class</th>\n",
       "      <th>2022_1_Class</th>\n",
       "      <th>source</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>POS tag</th>\n",
       "      <th>2022_0_Class_Benchamark</th>\n",
       "      <th>2022_1_Class_Benchmark</th>\n",
       "      <th>2022_Class_0_Differential</th>\n",
       "      <th>2022_Class_1_Differential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>friendly</td>\n",
       "      <td>0.907610</td>\n",
       "      <td>-0.673413</td>\n",
       "      <td>communality</td>\n",
       "      <td>7551</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>0.335596</td>\n",
       "      <td>-0.137244</td>\n",
       "      <td>0.572014</td>\n",
       "      <td>-0.536169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just</td>\n",
       "      <td>0.961739</td>\n",
       "      <td>-0.663940</td>\n",
       "      <td>communality</td>\n",
       "      <td>7551</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>0.335596</td>\n",
       "      <td>-0.137244</td>\n",
       "      <td>0.626143</td>\n",
       "      <td>-0.526696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sincere</td>\n",
       "      <td>1.484565</td>\n",
       "      <td>-1.164161</td>\n",
       "      <td>communality</td>\n",
       "      <td>7551</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>0.335596</td>\n",
       "      <td>-0.137244</td>\n",
       "      <td>1.148968</td>\n",
       "      <td>-1.026917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cyberbully</td>\n",
       "      <td>0.467781</td>\n",
       "      <td>-0.247669</td>\n",
       "      <td>Violence</td>\n",
       "      <td>7551</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>0.335596</td>\n",
       "      <td>-0.137244</td>\n",
       "      <td>0.132185</td>\n",
       "      <td>-0.110425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unruly</td>\n",
       "      <td>0.515528</td>\n",
       "      <td>-0.305455</td>\n",
       "      <td>Violence</td>\n",
       "      <td>7551</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>0.335596</td>\n",
       "      <td>-0.137244</td>\n",
       "      <td>0.179932</td>\n",
       "      <td>-0.168211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54335</th>\n",
       "      <td>slender</td>\n",
       "      <td>2.762344</td>\n",
       "      <td>-2.257229</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>9512</td>\n",
       "      <td>Noun</td>\n",
       "      <td>2.646646</td>\n",
       "      <td>-2.167005</td>\n",
       "      <td>0.115697</td>\n",
       "      <td>-0.090224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54336</th>\n",
       "      <td>handsome</td>\n",
       "      <td>4.153363</td>\n",
       "      <td>-3.414166</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>9512</td>\n",
       "      <td>Noun</td>\n",
       "      <td>2.646646</td>\n",
       "      <td>-2.167005</td>\n",
       "      <td>1.506717</td>\n",
       "      <td>-1.247161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54337</th>\n",
       "      <td>fat</td>\n",
       "      <td>2.424461</td>\n",
       "      <td>-1.987079</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>9512</td>\n",
       "      <td>Noun</td>\n",
       "      <td>2.646646</td>\n",
       "      <td>-2.167005</td>\n",
       "      <td>-0.222185</td>\n",
       "      <td>0.179926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54338</th>\n",
       "      <td>thin</td>\n",
       "      <td>2.104884</td>\n",
       "      <td>-1.733965</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>9512</td>\n",
       "      <td>Noun</td>\n",
       "      <td>2.646646</td>\n",
       "      <td>-2.167005</td>\n",
       "      <td>-0.541762</td>\n",
       "      <td>0.433039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54339</th>\n",
       "      <td>beautiful</td>\n",
       "      <td>2.277546</td>\n",
       "      <td>-1.864667</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>9512</td>\n",
       "      <td>Noun</td>\n",
       "      <td>2.646646</td>\n",
       "      <td>-2.167005</td>\n",
       "      <td>-0.369100</td>\n",
       "      <td>0.302338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54340 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  2022_0_class  2022_1_Class       source  sent_id POS tag  \\\n",
       "0        friendly      0.907610     -0.673413  communality     7551  Adverb   \n",
       "1            just      0.961739     -0.663940  communality     7551  Adverb   \n",
       "2         sincere      1.484565     -1.164161  communality     7551  Adverb   \n",
       "3      cyberbully      0.467781     -0.247669     Violence     7551  Adverb   \n",
       "4          unruly      0.515528     -0.305455     Violence     7551  Adverb   \n",
       "...           ...           ...           ...          ...      ...     ...   \n",
       "54335     slender      2.762344     -2.257229    Apperance     9512    Noun   \n",
       "54336    handsome      4.153363     -3.414166    Apperance     9512    Noun   \n",
       "54337         fat      2.424461     -1.987079    Apperance     9512    Noun   \n",
       "54338        thin      2.104884     -1.733965    Apperance     9512    Noun   \n",
       "54339   beautiful      2.277546     -1.864667    Apperance     9512    Noun   \n",
       "\n",
       "       2022_0_Class_Benchamark  2022_1_Class_Benchmark  \\\n",
       "0                     0.335596               -0.137244   \n",
       "1                     0.335596               -0.137244   \n",
       "2                     0.335596               -0.137244   \n",
       "3                     0.335596               -0.137244   \n",
       "4                     0.335596               -0.137244   \n",
       "...                        ...                     ...   \n",
       "54335                 2.646646               -2.167005   \n",
       "54336                 2.646646               -2.167005   \n",
       "54337                 2.646646               -2.167005   \n",
       "54338                 2.646646               -2.167005   \n",
       "54339                 2.646646               -2.167005   \n",
       "\n",
       "       2022_Class_0_Differential  2022_Class_1_Differential  \n",
       "0                       0.572014                  -0.536169  \n",
       "1                       0.626143                  -0.526696  \n",
       "2                       1.148968                  -1.026917  \n",
       "3                       0.132185                  -0.110425  \n",
       "4                       0.179932                  -0.168211  \n",
       "...                          ...                        ...  \n",
       "54335                   0.115697                  -0.090224  \n",
       "54336                   1.506717                  -1.247161  \n",
       "54337                  -0.222185                   0.179926  \n",
       "54338                  -0.541762                   0.433039  \n",
       "54339                  -0.369100                   0.302338  \n",
       "\n",
       "[54340 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_axis( ['feature',year + '_0_class', year + '_1_Class','source', 'sent_id','POS tag', year + '_0_Class_Benchamark',year + '_1_Class_Benchmark', year + '_Class_0_Differential', year + '_Class_1_Differential'], axis = 'columns')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
