{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#warnings \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#for RNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "\n",
    "import ast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Sentences for testing RNNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.read_pickle(\"pos_tag_word_list\")\n",
    "sent_df = pd.read_csv(\"sample sent idea.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_string(sents):\n",
    "    list_of_strings = []\n",
    "\n",
    "    for word_list in sents:\n",
    "        list_of_strings.append(' '.join(word_list))\n",
    "    return list_of_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df['list'] = sent_df['list'].apply(ast.literal_eval)\n",
    "benchmark_sentences = sent_df['list'].tolist()\n",
    "all_benchmarks = benchmark_string(benchmark_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"C:/Users/danie/Desktop/RNN_2012\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 6s 50ms/step\n"
     ]
    }
   ],
   "source": [
    "X_b = all_benchmarks\n",
    "x_arrayb = np.asarray(X_b)\n",
    "y_predb = loaded_model.predict(X_b)\n",
    "Yb = pd.DataFrame(y_predb)\n",
    "Yb.reset_index(inplace=True, drop=True)\n",
    "Yb.set_axis(['0 Class Benchamark', '1 Class Benchmark'], axis='columns', inplace=True)\n",
    "sent_df = pd.concat([sent_df, Yb], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test RNN model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NOUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_list = word_df[(word_df.pos_tag_short == \"N\")][\"feature\"].values.tolist()\n",
    "verb_list = word_df[(word_df.pos_tag_short == \"V\")][\"feature\"].values.tolist()\n",
    "adverb_list = word_df[(word_df.pos_tag_short == \"R\")][\"feature\"].values.tolist()\n",
    "adjective_list = word_df[(word_df.pos_tag_short == \"J\")][\"feature\"].values.tolist()\n",
    "\n",
    "noun_sent = sent_df[(sent_df['POS tag'] == \"Noun\")][\"replacement string\"].values.tolist()\n",
    "verb_sent = sent_df[(sent_df['POS tag'] == \"Verb\")][\"replacement string\"].values.tolist()\n",
    "adjective_sent = sent_df[(sent_df['POS tag'] == \"Adjective\")][\"replacement string\"].values.tolist()\n",
    "adverb_sent = sent_df[(sent_df['POS tag'] == \"Adverb\")][\"replacement string\"].values.tolist()\n",
    "\n",
    "adverb_len = len(adverb_sent)\n",
    "verb_len = len(verb_sent)\n",
    "noun_len = len(noun_sent)\n",
    "verb_len = len(verb_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_list(words, sents):\n",
    "    new_token_sents = []\n",
    "    for word in words:\n",
    "        temp_sents = []\n",
    "        temp_sent_2 = []\n",
    "        for sent in sents:\n",
    "            new_sent = ' '.join([word if w == 'UNK' else w for w in sent])\n",
    "            temp_sents.append([new_sent, sent])\n",
    "        new_token_sents.extend(temp_sents)\n",
    "    return new_token_sents\n",
    "\n",
    "sent_n = pd.DataFrame(word_list(noun_list, noun_sent))\n",
    "sent_j = pd.DataFrame(word_list(adjective_list, adjective_sent))\n",
    "sent_a = pd.DataFrame(word_list(adverb_list, adverb_sent))\n",
    "sent_v = pd.DataFrame(word_list(verb_list, verb_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1545/1545 [==============================] - 358s 232ms/step\n",
      "26/26 [==============================] - 5s 172ms/step\n",
      "82/82 [==============================] - 25s 306ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n"
     ]
    }
   ],
   "source": [
    "x_array_n = np.asarray(sent_n[0])\n",
    "x_array_j = np.asarray(sent_j[0])\n",
    "x_array_v = np.asarray(sent_v[0])\n",
    "x_array_a = np.asarray(sent_a[0])\n",
    "\n",
    "\n",
    "y_pred_n = loaded_model.predict(x_array_n)\n",
    "y_pred_j = loaded_model.predict(x_array_j)\n",
    "y_pred_v = loaded_model.predict(x_array_v)\n",
    "y_pred_a = loaded_model.predict(x_array_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You need to change the num_repititons to the number of sentences in the function\n",
    "\n",
    "def labels(word_list, word_len):\n",
    "    num_repetitions = word_len\n",
    "    repeated_words = []\n",
    "    for word in word_list:\n",
    "        for _ in range(num_repetitions):\n",
    "            repeated_words.append(word)\n",
    "    return repeated_words\n",
    "\n",
    "noun_labels = pd.DataFrame(labels(noun_list, noun_len))\n",
    "adjective_labels = pd.DataFrame(labels(adjective_list, noun_len))\n",
    "verb_labels = pd.DataFrame(labels(verb_list, noun_len))\n",
    "adverb_labels = pd.DataFrame(labels(adverb_list, noun_len))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_n = pd.DataFrame(y_pred_n)\n",
    "Y_j = pd.DataFrame(y_pred_j)\n",
    "Y_v = pd.DataFrame(y_pred_v)\n",
    "Y_a = pd.DataFrame(y_pred_a)\n",
    "\n",
    "result_n = pd.concat([noun_labels, Y_n,sent_n], axis=1)\n",
    "result_j = pd.concat([adjective_labels, Y_j,sent_j], axis=1)\n",
    "result_v = pd.concat([verb_labels, Y_v,sent_v], axis=1)\n",
    "result_a = pd.concat([adverb_labels, Y_a, sent_a], axis=1)\n",
    "\n",
    "result_n.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "result_j.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "result_v.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "result_a.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([result_a, result_v, result_j, result_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_with_source = pd.merge(result, word_df, on='feature', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(result_with_source, sent_df, on='replacement string', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class 0 Differential'] = df['0 Class'] - df['0 Class Benchamark']\n",
    "df['Class 1 Differential'] = df['1 Class'] - df['1 Class Benchmark']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>0 Class</th>\n",
       "      <th>1 Class</th>\n",
       "      <th>RNN Sentences</th>\n",
       "      <th>replacement string</th>\n",
       "      <th>source</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>pos_tag_short</th>\n",
       "      <th>snet id</th>\n",
       "      <th>list</th>\n",
       "      <th>sent</th>\n",
       "      <th>POS tag</th>\n",
       "      <th>word num</th>\n",
       "      <th>identified word</th>\n",
       "      <th>0 Class Benchamark</th>\n",
       "      <th>1 Class Benchmark</th>\n",
       "      <th>Class 0 Differential</th>\n",
       "      <th>Class 1 Differential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>friendly</td>\n",
       "      <td>-1.310452</td>\n",
       "      <td>1.817012</td>\n",
       "      <td>[ ' s a y ' ,   ' g u y ' ,   ' h e a r ' ,   ...</td>\n",
       "      <td>['say', 'guy', 'hear', 'sing', 'think', 'moyle...</td>\n",
       "      <td>communality</td>\n",
       "      <td>RB</td>\n",
       "      <td>R</td>\n",
       "      <td>7551</td>\n",
       "      <td>[say, guy, hear, sing, think, moyles, year, ago]</td>\n",
       "      <td>He said: \"Some guys heard me singing Tom Jones...</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ago</td>\n",
       "      <td>-0.034972</td>\n",
       "      <td>0.058603</td>\n",
       "      <td>-1.275480</td>\n",
       "      <td>1.758409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>friendly</td>\n",
       "      <td>-1.310452</td>\n",
       "      <td>1.817012</td>\n",
       "      <td>[ ' s a y ' ,   ' g u y ' ,   ' h e a r ' ,   ...</td>\n",
       "      <td>['say', 'guy', 'hear', 'sing', 'think', 'moyle...</td>\n",
       "      <td>communality</td>\n",
       "      <td>RB</td>\n",
       "      <td>R</td>\n",
       "      <td>7551</td>\n",
       "      <td>[say, guy, hear, sing, think, moyles, year, ago]</td>\n",
       "      <td>He said: \"Some guys heard me singing Tom Jones...</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ago</td>\n",
       "      <td>-0.034972</td>\n",
       "      <td>0.058603</td>\n",
       "      <td>-1.275480</td>\n",
       "      <td>1.758409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>friendly</td>\n",
       "      <td>-1.310452</td>\n",
       "      <td>1.817012</td>\n",
       "      <td>[ ' s a y ' ,   ' g u y ' ,   ' h e a r ' ,   ...</td>\n",
       "      <td>['say', 'guy', 'hear', 'sing', 'think', 'moyle...</td>\n",
       "      <td>communality</td>\n",
       "      <td>RB</td>\n",
       "      <td>R</td>\n",
       "      <td>7551</td>\n",
       "      <td>[say, guy, hear, sing, think, moyles, year, ago]</td>\n",
       "      <td>He said: \"Some guys heard me singing Tom Jones...</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ago</td>\n",
       "      <td>-0.034972</td>\n",
       "      <td>0.058603</td>\n",
       "      <td>-1.275480</td>\n",
       "      <td>1.758409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>friendly</td>\n",
       "      <td>-1.310452</td>\n",
       "      <td>1.817012</td>\n",
       "      <td>[ ' s a y ' ,   ' g u y ' ,   ' h e a r ' ,   ...</td>\n",
       "      <td>['say', 'guy', 'hear', 'sing', 'think', 'moyle...</td>\n",
       "      <td>communality</td>\n",
       "      <td>RB</td>\n",
       "      <td>R</td>\n",
       "      <td>7551</td>\n",
       "      <td>[say, guy, hear, sing, think, moyles, year, ago]</td>\n",
       "      <td>He said: \"Some guys heard me singing Tom Jones...</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ago</td>\n",
       "      <td>-0.034972</td>\n",
       "      <td>0.058603</td>\n",
       "      <td>-1.275480</td>\n",
       "      <td>1.758409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>friendly</td>\n",
       "      <td>-1.310452</td>\n",
       "      <td>1.817012</td>\n",
       "      <td>[ ' s a y ' ,   ' g u y ' ,   ' h e a r ' ,   ...</td>\n",
       "      <td>['say', 'guy', 'hear', 'sing', 'think', 'moyle...</td>\n",
       "      <td>communality</td>\n",
       "      <td>RB</td>\n",
       "      <td>R</td>\n",
       "      <td>7551</td>\n",
       "      <td>[say, guy, hear, sing, think, moyles, year, ago]</td>\n",
       "      <td>He said: \"Some guys heard me singing Tom Jones...</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ago</td>\n",
       "      <td>-0.034972</td>\n",
       "      <td>0.058603</td>\n",
       "      <td>-1.275480</td>\n",
       "      <td>1.758409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55467</th>\n",
       "      <td>slender</td>\n",
       "      <td>-2.492111</td>\n",
       "      <td>3.155214</td>\n",
       "      <td>[ ' t e r r i f y ' ,   ' U N K ' ,   ' p l a ...</td>\n",
       "      <td>['terrify', 'UNK', 'play', 'well', 'together',...</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9512</td>\n",
       "      <td>[terrify, pace, play, well, together, also, sc...</td>\n",
       "      <td>Aaron Lennon terrified the Croats with his pac...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pace</td>\n",
       "      <td>2.273282</td>\n",
       "      <td>-2.246118</td>\n",
       "      <td>-4.765393</td>\n",
       "      <td>5.401331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55468</th>\n",
       "      <td>handsome</td>\n",
       "      <td>-2.492111</td>\n",
       "      <td>3.155214</td>\n",
       "      <td>[ ' t e r r i f y ' ,   ' U N K ' ,   ' p l a ...</td>\n",
       "      <td>['terrify', 'UNK', 'play', 'well', 'together',...</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9512</td>\n",
       "      <td>[terrify, pace, play, well, together, also, sc...</td>\n",
       "      <td>Aaron Lennon terrified the Croats with his pac...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pace</td>\n",
       "      <td>2.273282</td>\n",
       "      <td>-2.246118</td>\n",
       "      <td>-4.765393</td>\n",
       "      <td>5.401331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55469</th>\n",
       "      <td>fat</td>\n",
       "      <td>-2.492111</td>\n",
       "      <td>3.155214</td>\n",
       "      <td>[ ' t e r r i f y ' ,   ' U N K ' ,   ' p l a ...</td>\n",
       "      <td>['terrify', 'UNK', 'play', 'well', 'together',...</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9512</td>\n",
       "      <td>[terrify, pace, play, well, together, also, sc...</td>\n",
       "      <td>Aaron Lennon terrified the Croats with his pac...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pace</td>\n",
       "      <td>2.273282</td>\n",
       "      <td>-2.246118</td>\n",
       "      <td>-4.765393</td>\n",
       "      <td>5.401331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55470</th>\n",
       "      <td>thin</td>\n",
       "      <td>-2.492111</td>\n",
       "      <td>3.155214</td>\n",
       "      <td>[ ' t e r r i f y ' ,   ' U N K ' ,   ' p l a ...</td>\n",
       "      <td>['terrify', 'UNK', 'play', 'well', 'together',...</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9512</td>\n",
       "      <td>[terrify, pace, play, well, together, also, sc...</td>\n",
       "      <td>Aaron Lennon terrified the Croats with his pac...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pace</td>\n",
       "      <td>2.273282</td>\n",
       "      <td>-2.246118</td>\n",
       "      <td>-4.765393</td>\n",
       "      <td>5.401331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55471</th>\n",
       "      <td>beautiful</td>\n",
       "      <td>-2.492111</td>\n",
       "      <td>3.155214</td>\n",
       "      <td>[ ' t e r r i f y ' ,   ' U N K ' ,   ' p l a ...</td>\n",
       "      <td>['terrify', 'UNK', 'play', 'well', 'together',...</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9512</td>\n",
       "      <td>[terrify, pace, play, well, together, also, sc...</td>\n",
       "      <td>Aaron Lennon terrified the Croats with his pac...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pace</td>\n",
       "      <td>2.273282</td>\n",
       "      <td>-2.246118</td>\n",
       "      <td>-4.765393</td>\n",
       "      <td>5.401331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55472 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature   0 Class   1 Class  \\\n",
       "0       friendly -1.310452  1.817012   \n",
       "1       friendly -1.310452  1.817012   \n",
       "2       friendly -1.310452  1.817012   \n",
       "3       friendly -1.310452  1.817012   \n",
       "4       friendly -1.310452  1.817012   \n",
       "...          ...       ...       ...   \n",
       "55467    slender -2.492111  3.155214   \n",
       "55468   handsome -2.492111  3.155214   \n",
       "55469        fat -2.492111  3.155214   \n",
       "55470       thin -2.492111  3.155214   \n",
       "55471  beautiful -2.492111  3.155214   \n",
       "\n",
       "                                           RNN Sentences  \\\n",
       "0      [ ' s a y ' ,   ' g u y ' ,   ' h e a r ' ,   ...   \n",
       "1      [ ' s a y ' ,   ' g u y ' ,   ' h e a r ' ,   ...   \n",
       "2      [ ' s a y ' ,   ' g u y ' ,   ' h e a r ' ,   ...   \n",
       "3      [ ' s a y ' ,   ' g u y ' ,   ' h e a r ' ,   ...   \n",
       "4      [ ' s a y ' ,   ' g u y ' ,   ' h e a r ' ,   ...   \n",
       "...                                                  ...   \n",
       "55467  [ ' t e r r i f y ' ,   ' U N K ' ,   ' p l a ...   \n",
       "55468  [ ' t e r r i f y ' ,   ' U N K ' ,   ' p l a ...   \n",
       "55469  [ ' t e r r i f y ' ,   ' U N K ' ,   ' p l a ...   \n",
       "55470  [ ' t e r r i f y ' ,   ' U N K ' ,   ' p l a ...   \n",
       "55471  [ ' t e r r i f y ' ,   ' U N K ' ,   ' p l a ...   \n",
       "\n",
       "                                      replacement string       source pos_tag  \\\n",
       "0      ['say', 'guy', 'hear', 'sing', 'think', 'moyle...  communality      RB   \n",
       "1      ['say', 'guy', 'hear', 'sing', 'think', 'moyle...  communality      RB   \n",
       "2      ['say', 'guy', 'hear', 'sing', 'think', 'moyle...  communality      RB   \n",
       "3      ['say', 'guy', 'hear', 'sing', 'think', 'moyle...  communality      RB   \n",
       "4      ['say', 'guy', 'hear', 'sing', 'think', 'moyle...  communality      RB   \n",
       "...                                                  ...          ...     ...   \n",
       "55467  ['terrify', 'UNK', 'play', 'well', 'together',...    Apperance      NN   \n",
       "55468  ['terrify', 'UNK', 'play', 'well', 'together',...    Apperance      NN   \n",
       "55469  ['terrify', 'UNK', 'play', 'well', 'together',...    Apperance      NN   \n",
       "55470  ['terrify', 'UNK', 'play', 'well', 'together',...    Apperance      NN   \n",
       "55471  ['terrify', 'UNK', 'play', 'well', 'together',...    Apperance      NN   \n",
       "\n",
       "      pos_tag_short  snet id  \\\n",
       "0                 R     7551   \n",
       "1                 R     7551   \n",
       "2                 R     7551   \n",
       "3                 R     7551   \n",
       "4                 R     7551   \n",
       "...             ...      ...   \n",
       "55467             N     9512   \n",
       "55468             N     9512   \n",
       "55469             N     9512   \n",
       "55470             N     9512   \n",
       "55471             N     9512   \n",
       "\n",
       "                                                    list  \\\n",
       "0       [say, guy, hear, sing, think, moyles, year, ago]   \n",
       "1       [say, guy, hear, sing, think, moyles, year, ago]   \n",
       "2       [say, guy, hear, sing, think, moyles, year, ago]   \n",
       "3       [say, guy, hear, sing, think, moyles, year, ago]   \n",
       "4       [say, guy, hear, sing, think, moyles, year, ago]   \n",
       "...                                                  ...   \n",
       "55467  [terrify, pace, play, well, together, also, sc...   \n",
       "55468  [terrify, pace, play, well, together, also, sc...   \n",
       "55469  [terrify, pace, play, well, together, also, sc...   \n",
       "55470  [terrify, pace, play, well, together, also, sc...   \n",
       "55471  [terrify, pace, play, well, together, also, sc...   \n",
       "\n",
       "                                                    sent POS tag  word num  \\\n",
       "0      He said: \"Some guys heard me singing Tom Jones...  Adverb       7.0   \n",
       "1      He said: \"Some guys heard me singing Tom Jones...  Adverb       7.0   \n",
       "2      He said: \"Some guys heard me singing Tom Jones...  Adverb       7.0   \n",
       "3      He said: \"Some guys heard me singing Tom Jones...  Adverb       7.0   \n",
       "4      He said: \"Some guys heard me singing Tom Jones...  Adverb       7.0   \n",
       "...                                                  ...     ...       ...   \n",
       "55467  Aaron Lennon terrified the Croats with his pac...    Noun       1.0   \n",
       "55468  Aaron Lennon terrified the Croats with his pac...    Noun       1.0   \n",
       "55469  Aaron Lennon terrified the Croats with his pac...    Noun       1.0   \n",
       "55470  Aaron Lennon terrified the Croats with his pac...    Noun       1.0   \n",
       "55471  Aaron Lennon terrified the Croats with his pac...    Noun       1.0   \n",
       "\n",
       "      identified word  0 Class Benchamark  1 Class Benchmark  \\\n",
       "0                 ago           -0.034972           0.058603   \n",
       "1                 ago           -0.034972           0.058603   \n",
       "2                 ago           -0.034972           0.058603   \n",
       "3                 ago           -0.034972           0.058603   \n",
       "4                 ago           -0.034972           0.058603   \n",
       "...               ...                 ...                ...   \n",
       "55467            pace            2.273282          -2.246118   \n",
       "55468            pace            2.273282          -2.246118   \n",
       "55469            pace            2.273282          -2.246118   \n",
       "55470            pace            2.273282          -2.246118   \n",
       "55471            pace            2.273282          -2.246118   \n",
       "\n",
       "       Class 0 Differential  Class 1 Differential  \n",
       "0                 -1.275480              1.758409  \n",
       "1                 -1.275480              1.758409  \n",
       "2                 -1.275480              1.758409  \n",
       "3                 -1.275480              1.758409  \n",
       "4                 -1.275480              1.758409  \n",
       "...                     ...                   ...  \n",
       "55467             -4.765393              5.401331  \n",
       "55468             -4.765393              5.401331  \n",
       "55469             -4.765393              5.401331  \n",
       "55470             -4.765393              5.401331  \n",
       "55471             -4.765393              5.401331  \n",
       "\n",
       "[55472 rows x 18 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0 Class</th>\n",
       "      <th>1 Class</th>\n",
       "      <th>snet id</th>\n",
       "      <th>word num</th>\n",
       "      <th>0 Class Benchamark</th>\n",
       "      <th>1 Class Benchmark</th>\n",
       "      <th>Class 0 Differential</th>\n",
       "      <th>Class 1 Differential</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Apperance</th>\n",
       "      <td>-0.263607</td>\n",
       "      <td>0.666855</td>\n",
       "      <td>9109.920000</td>\n",
       "      <td>2.054795</td>\n",
       "      <td>0.725785</td>\n",
       "      <td>-0.631067</td>\n",
       "      <td>-0.989392</td>\n",
       "      <td>1.297922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Violence</th>\n",
       "      <td>-0.262859</td>\n",
       "      <td>0.666209</td>\n",
       "      <td>9113.810778</td>\n",
       "      <td>2.066480</td>\n",
       "      <td>0.725125</td>\n",
       "      <td>-0.630511</td>\n",
       "      <td>-0.987984</td>\n",
       "      <td>1.296719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agency</th>\n",
       "      <td>-0.260481</td>\n",
       "      <td>0.664143</td>\n",
       "      <td>9126.247119</td>\n",
       "      <td>2.108044</td>\n",
       "      <td>0.725425</td>\n",
       "      <td>-0.631493</td>\n",
       "      <td>-0.985907</td>\n",
       "      <td>1.295637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communality</th>\n",
       "      <td>-0.242605</td>\n",
       "      <td>0.640061</td>\n",
       "      <td>8795.695730</td>\n",
       "      <td>2.401367</td>\n",
       "      <td>0.751181</td>\n",
       "      <td>-0.664689</td>\n",
       "      <td>-0.993787</td>\n",
       "      <td>1.304750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <td>-0.263783</td>\n",
       "      <td>0.667356</td>\n",
       "      <td>9114.352916</td>\n",
       "      <td>2.067544</td>\n",
       "      <td>0.724620</td>\n",
       "      <td>-0.629988</td>\n",
       "      <td>-0.988404</td>\n",
       "      <td>1.297344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0 Class   1 Class      snet id  word num  0 Class Benchamark  \\\n",
       "source                                                                       \n",
       "Apperance   -0.263607  0.666855  9109.920000  2.054795            0.725785   \n",
       "Violence    -0.262859  0.666209  9113.810778  2.066480            0.725125   \n",
       "agency      -0.260481  0.664143  9126.247119  2.108044            0.725425   \n",
       "communality -0.242605  0.640061  8795.695730  2.401367            0.751181   \n",
       "power       -0.263783  0.667356  9114.352916  2.067544            0.724620   \n",
       "\n",
       "             1 Class Benchmark  Class 0 Differential  Class 1 Differential  \n",
       "source                                                                      \n",
       "Apperance            -0.631067             -0.989392              1.297922  \n",
       "Violence             -0.630511             -0.987984              1.296719  \n",
       "agency               -0.631493             -0.985907              1.295637  \n",
       "communality          -0.664689             -0.993787              1.304750  \n",
       "power                -0.629988             -0.988404              1.297344  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by=['source']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
