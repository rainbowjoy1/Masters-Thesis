{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "#pip install textblob\n",
    "#pip install keras\n",
    "#pip install tensorflow\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.optimizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_09= pd.read_pickle(r\"C:\\Users\\danie\\Documents\\GitHub\\Masters-Thesis\\2009_preprocessed_date.pickle\") \n",
    "df_09= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/2009_text_wo_names.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_processed_sent</th>\n",
       "      <th>male_count</th>\n",
       "      <th>female_count</th>\n",
       "      <th>Proper_noun_list</th>\n",
       "      <th>pn exists</th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[leave, band, follow, bust, say, simply, could...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[Noel, Gallagher]</td>\n",
       "      <td>True</td>\n",
       "      <td>Noel Gallagher left the Manchester band follow...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[launch, clothing, line, earlier, year, admit,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Liam]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Liam launched his clothing line Pretty Green ...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[thinking, next, step, musically, mind, say]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"I'm thinking of what the next step is musical...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[people, able, buy, record]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"People will be able to buy his records.</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[come, back, hang, fellow, cast, member, mitch...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Sam]</td>\n",
       "      <td>None</td>\n",
       "      <td>She's coming back as Sam Mitchell and was hang...</td>\n",
       "      <td>8981</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19327</th>\n",
       "      <td>[report, speculate, mime, part, track, want, p...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>Some reports have speculated that she mimed pa...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19328</th>\n",
       "      <td>[know, dance, lot]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"I know she was dancing a lot.</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19329</th>\n",
       "      <td>[know, mime, think, really, great, performance...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>I don't know if she was miming or not but I th...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19330</th>\n",
       "      <td>[legend, make, comeback, show, rendition, new,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Pop, Robbie]</td>\n",
       "      <td>True</td>\n",
       "      <td>Pop legend Robbie Williams made his comeback o...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19333</th>\n",
       "      <td>[year, factor, run, night, series, performance...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Houston]</td>\n",
       "      <td>None</td>\n",
       "      <td>This year's X Factor, which runs on both Satur...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5342 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      pre_processed_sent  male_count  \\\n",
       "9      [leave, band, follow, bust, say, simply, could...           3   \n",
       "10     [launch, clothing, line, earlier, year, admit,...           2   \n",
       "11          [thinking, next, step, musically, mind, say]           1   \n",
       "13                           [people, able, buy, record]           1   \n",
       "33     [come, back, hang, fellow, cast, member, mitch...           0   \n",
       "...                                                  ...         ...   \n",
       "19327  [report, speculate, mime, part, track, want, p...           0   \n",
       "19328                                 [know, dance, lot]           0   \n",
       "19329  [know, mime, think, really, great, performance...           0   \n",
       "19330  [legend, make, comeback, show, rendition, new,...           2   \n",
       "19333  [year, factor, run, night, series, performance...           1   \n",
       "\n",
       "       female_count   Proper_noun_list pn exists  \\\n",
       "9                 0  [Noel, Gallagher]      True   \n",
       "10                0             [Liam]      None   \n",
       "11                0                 []      None   \n",
       "13                0                 []      None   \n",
       "33                2              [Sam]      None   \n",
       "...             ...                ...       ...   \n",
       "19327             2                 []      None   \n",
       "19328             1                 []      None   \n",
       "19329             2                 []      None   \n",
       "19330             0      [Pop, Robbie]      True   \n",
       "19333             0          [Houston]      None   \n",
       "\n",
       "                                               sentences  article_id  year  \\\n",
       "9      Noel Gallagher left the Manchester band follow...        5048  2009   \n",
       "10     \"Liam launched his clothing line Pretty Green ...        5048  2009   \n",
       "11     \"I'm thinking of what the next step is musical...        5048  2009   \n",
       "13              \"People will be able to buy his records.        5048  2009   \n",
       "33     She's coming back as Sam Mitchell and was hang...        8981  2009   \n",
       "...                                                  ...         ...   ...   \n",
       "19327  Some reports have speculated that she mimed pa...     2157826  2009   \n",
       "19328                     \"I know she was dancing a lot.     2157826  2009   \n",
       "19329  I don't know if she was miming or not but I th...     2157826  2009   \n",
       "19330  Pop legend Robbie Williams made his comeback o...     2157826  2009   \n",
       "19333  This year's X Factor, which runs on both Satur...     2157826  2009   \n",
       "\n",
       "       col_type  \n",
       "9           0.0  \n",
       "10          0.0  \n",
       "11          0.0  \n",
       "13          0.0  \n",
       "33          1.0  \n",
       "...         ...  \n",
       "19327       1.0  \n",
       "19328       1.0  \n",
       "19329       1.0  \n",
       "19330       0.0  \n",
       "19333       0.0  \n",
       "\n",
       "[5342 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def absolute_count(male_col, female_col):\n",
    "    if female_col > male_col and male_col == 0:\n",
    "        return 1\n",
    "    elif male_col> female_col and female_col ==0: \n",
    "        return 0\n",
    "    else: \n",
    "        return None\n",
    "\n",
    "#PP Data\n",
    "df_09['col_type'] = df_09.apply(lambda row: absolute_count(row['male_count'], row['female_count']),axis=1)\n",
    "df_09= df_09[df_09[\"col_type\"].notnull()]\n",
    "df_09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity(sentence):\n",
    "    subjectivity = \"\"\n",
    "\n",
    "    subjectivity = TextBlob(sentence).sentiment.subjectivity\n",
    "\n",
    "    return subjectivity\n",
    "\n",
    "def polarity(sentence):\n",
    "    polarity = \"\"\n",
    "\n",
    "    polarity = TextBlob(sentence).sentiment.polarity\n",
    "\n",
    "    return polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_09['subjectivity'] = df_09['sentences'].apply(subjectivity)\n",
    "df_09['polarity'] = df_09['sentences'].apply(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5342.000000\n",
       "mean        0.357059\n",
       "std         0.302850\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.350000\n",
       "75%         0.550000\n",
       "max         1.000000\n",
       "Name: subjectivity, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_09[\"subjectivity\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0    4188\n",
       " 1.0     923\n",
       "-1.0     231\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a 3 point criteria from -1 to 1 (range of polarity)\n",
    "def map_sentiment(value):\n",
    "    if value <= -0.33: \n",
    "        return -1\n",
    "    elif value >= 0.33:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "df_09['sentiment'] = df_09['polarity'].apply(map_sentiment)\n",
    "df_09['sentiment'] = df_09[\"sentiment\"].astype(float)\n",
    "df_09[\"sentiment\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN LSTM Model for Sentiment Analysis** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_lstm(df, sentences_col, sentiment_col):\n",
    "    #start timer \n",
    "    start_time = time.time()\n",
    "\n",
    "    X = df[sentences_col]\n",
    "    y = df[sentiment_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state = 42)\n",
    "    \n",
    "    # Tokenize the data\n",
    "    tokenizer = Tokenizer(num_words=1000)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    \n",
    "    # Convert the texts to sequences\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "    \n",
    "    # Pad the sequences to ensure equal length\n",
    "    maxlen = 100\n",
    "    X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "    X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "    \n",
    "    # Define the LSTM model\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(Embedding(input_dim=1000, output_dim=64, input_length=maxlen))\n",
    "    model_lstm.add(LSTM(64))\n",
    "    model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "    model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', \"mean_squared_error\"])\n",
    "    \n",
    "    # Train the model\n",
    "    model_lstm.fit(X_train, y_train, epochs=1, batch_size=32, validation_data=(X_test, y_test))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    score = model_lstm.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    #add early stopping \n",
    "    earlystop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "    # Make predictions on the padded sequences\n",
    "    y_pred = model_lstm.predict(X_test)\n",
    "    \n",
    "    #end timer \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nExecution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    # print the average sentiment for a word based on the words found in the corpus of the model\n",
    "    #(add code here)\n",
    "    return X_test, y_pred\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 28ms/step - loss: 0.4726 - accuracy: 0.8214 - mean_squared_error: 0.1480 - val_loss: 0.4599 - val_accuracy: 0.8279 - val_mean_squared_error: 0.1427\n",
      "Test loss: 0.4599429666996002\n",
      "Test accuracy: 0.8278765082359314\n",
      "34/34 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[  5,   9,   1, ...,   0,   0,   0],\n",
       "        [ 74,   8,  54, ...,   0,   0,   0],\n",
       "        [  8, 256, 714, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [ 15, 474,  12, ...,   0,   0,   0],\n",
       "        [123,   2,  27, ...,   0,   0,   0],\n",
       "        [  1,  36,  77, ...,   0,   0,   0]], dtype=int32),\n",
       " array([[0.84174556],\n",
       "        [0.8417457 ],\n",
       "        [0.8417453 ],\n",
       "        ...,\n",
       "        [0.84174544],\n",
       "        [0.8417454 ],\n",
       "        [0.84174514]], dtype=float32))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_lstm(df_09, \"sentences\", \"sentiment\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN Model for Sentiment Analysis (WE WILL NOT USE, SIMPLY FOR REFERENCE TO ANSWER DEFENSEN QUESTIONS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.3705 - accuracy: 0.7897 - mean_squared_error: 0.1881 - val_loss: 0.1815 - val_accuracy: 0.8178 - val_mean_squared_error: 0.1498\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.0476 - accuracy: 0.8565 - mean_squared_error: 0.1157 - val_loss: -0.1903 - val_accuracy: 0.8610 - val_mean_squared_error: 0.1179\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 2s 16ms/step - loss: -0.6916 - accuracy: 0.9017 - mean_squared_error: 0.0882 - val_loss: -1.5509 - val_accuracy: 0.8513 - val_mean_squared_error: 0.1405\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 2s 17ms/step - loss: -4.1102 - accuracy: 0.9149 - mean_squared_error: 0.0809 - val_loss: -7.9977 - val_accuracy: 0.8621 - val_mean_squared_error: 0.1353\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 2s 17ms/step - loss: -14.8273 - accuracy: 0.9171 - mean_squared_error: 0.0810 - val_loss: -23.6370 - val_accuracy: 0.8631 - val_mean_squared_error: 0.1356\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 2s 17ms/step - loss: -36.6127 - accuracy: 0.9189 - mean_squared_error: 0.0798 - val_loss: -51.5136 - val_accuracy: 0.8652 - val_mean_squared_error: 0.1343\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 2s 16ms/step - loss: -72.6850 - accuracy: 0.9185 - mean_squared_error: 0.0811 - val_loss: -95.8967 - val_accuracy: 0.8652 - val_mean_squared_error: 0.1342\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 2s 17ms/step - loss: -126.1227 - accuracy: 0.9234 - mean_squared_error: 0.0760 - val_loss: -156.0093 - val_accuracy: 0.8641 - val_mean_squared_error: 0.1355\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 2s 17ms/step - loss: -197.8985 - accuracy: 0.9246 - mean_squared_error: 0.0750 - val_loss: -233.1326 - val_accuracy: 0.8595 - val_mean_squared_error: 0.1400\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 2s 16ms/step - loss: -291.3333 - accuracy: 0.9241 - mean_squared_error: 0.0756 - val_loss: -334.3151 - val_accuracy: 0.8662 - val_mean_squared_error: 0.1339\n",
      "Test loss: -334.3150634765625\n",
      "Test accuracy: 0.8661863207817078\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define X and y\n",
    "X = df_09['sentences']\n",
    "y = df_09['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert the texts to sequences\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences to ensure equal length\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128, input_length=maxlen))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', \"mean_squared_error\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table Comparing Model Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Accuracy  Mean Squared Error  Test loss\n",
      "                                             \n",
      "LSTM     0.795              0.1930     0.3425\n",
      "CNN      0.866              0.1339  -334.3150\n"
     ]
    }
   ],
   "source": [
    "results = {' ': ['LSTM', 'CNN'],\n",
    "           'Accuracy': [0.795, 0.866],\n",
    "           'Mean Squared Error': [0.193, 0.1339],\n",
    "           'Test loss': [0.3425, -334.315]}\n",
    "\n",
    "# Create a pandas dataframe from the dictionary\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Set the index of the dataframe to the Kernel column\n",
    "df.set_index(' ', inplace=True)\n",
    "\n",
    "# Display the dataframe\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
