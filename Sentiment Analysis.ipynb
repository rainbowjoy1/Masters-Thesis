{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 11:21:05.836251: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "#pip install textblob\n",
    "#pip install keras\n",
    "#pip install tensorflow\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "#for CNN \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2010\"\n",
    "file_path = \"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/\"\n",
    "file_path_2 = \"_final_rnn.pickle\"\n",
    "\n",
    "df_10= pd.read_pickle(file_path + year + file_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_count(male_col, female_col):\n",
    "    if female_col > male_col and male_col == 0:\n",
    "        return 1\n",
    "    elif male_col> female_col and female_col ==0: \n",
    "        return 0\n",
    "    else: \n",
    "        return None\n",
    "\n",
    "#PP Data\n",
    "df_10['col_type'] = df_10.apply(lambda row: absolute_count(row['male_count'], row['female_count']),axis=1)\n",
    "df_10 = df_10[df_10[\"col_type\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity(sentence):\n",
    "    subjectivity = \"\"\n",
    "\n",
    "    subjectivity = TextBlob(sentence).sentiment.subjectivity\n",
    "\n",
    "    return subjectivity\n",
    "\n",
    "def polarity(sentence):\n",
    "    polarity = \"\"\n",
    "    polarity = TextBlob(sentence).sentiment.polarity\n",
    "    return polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10['subjectivity'] = df_10['string_rnn'].apply(subjectivity)\n",
    "df_10['polarity'] = df_10['string_rnn'].apply(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_processed_sent</th>\n",
       "      <th>string_rnn</th>\n",
       "      <th>male_count</th>\n",
       "      <th>female_count</th>\n",
       "      <th>Proper_noun_list</th>\n",
       "      <th>pn exists</th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>col_type</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[say, delight, restored, bridge, back, use]</td>\n",
       "      <td>say delight restored bridge back use</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Southease]</td>\n",
       "      <td>None</td>\n",
       "      <td>Chairman of Southease Parish, Neville Harrison...</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[family, year, old, kill, house, fire, pay, tr...</td>\n",
       "      <td>family year old kill house fire pay tribute br...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>The family of a 34-year-old mother from Bristo...</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[truly, tragic, love, family, everything, give...</td>\n",
       "      <td>truly tragic love family everything give famil...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[Sara]</td>\n",
       "      <td>None</td>\n",
       "      <td>'Truly tragic'\"Sara loved her family above eve...</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[everybody, know, love, miss, always]</td>\n",
       "      <td>everybody know love miss always</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Everybody who knew her will love her and miss...</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[truly, tragic, event, keen, determine, exactl...</td>\n",
       "      <td>truly tragic event keen determine exactly lead...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"This was a truly tragic event and we are very...</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>-0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514542</th>\n",
       "      <td>[contrast, news, conference, sound, guard, eve...</td>\n",
       "      <td>contrast news conference sound guard even slig...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Fabio]</td>\n",
       "      <td>None</td>\n",
       "      <td>Compare and contrast - Fabio Capello's news co...</td>\n",
       "      <td>2175804</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368889</td>\n",
       "      <td>0.131111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514543</th>\n",
       "      <td>[goal, one, chosen, five, could, take, spot, k...</td>\n",
       "      <td>goal one chosen five could take spot kick need</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Nelson, Mandela]</td>\n",
       "      <td>True</td>\n",
       "      <td>And after his goal at the Nelson Mandela Bay S...</td>\n",
       "      <td>2175804</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514544</th>\n",
       "      <td>[everyone, practise, say]</td>\n",
       "      <td>everyone practise say</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Everyone has been practising them,\" he said.</td>\n",
       "      <td>2175804</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514545</th>\n",
       "      <td>[look, relax, hair, back, cornrows, mobile, tu...</td>\n",
       "      <td>look relax hair back cornrows mobile tuck righ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>He looked relaxed, his hair back in cornrows, ...</td>\n",
       "      <td>2175804</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514546</th>\n",
       "      <td>[another, game, bother, rivalry, two, country]</td>\n",
       "      <td>another game bother rivalry two country</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>For him, it is \"just another game\", he's not t...</td>\n",
       "      <td>2175804</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492346 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       pre_processed_sent  \\\n",
       "0             [say, delight, restored, bridge, back, use]   \n",
       "1       [family, year, old, kill, house, fire, pay, tr...   \n",
       "3       [truly, tragic, love, family, everything, give...   \n",
       "4                   [everybody, know, love, miss, always]   \n",
       "5       [truly, tragic, event, keen, determine, exactl...   \n",
       "...                                                   ...   \n",
       "514542  [contrast, news, conference, sound, guard, eve...   \n",
       "514543  [goal, one, chosen, five, could, take, spot, k...   \n",
       "514544                          [everyone, practise, say]   \n",
       "514545  [look, relax, hair, back, cornrows, mobile, tu...   \n",
       "514546     [another, game, bother, rivalry, two, country]   \n",
       "\n",
       "                                               string_rnn  male_count  \\\n",
       "0                    say delight restored bridge back use           1   \n",
       "1       family year old kill house fire pay tribute br...           0   \n",
       "3       truly tragic love family everything give famil...           0   \n",
       "4                         everybody know love miss always           0   \n",
       "5       truly tragic event keen determine exactly lead...           0   \n",
       "...                                                   ...         ...   \n",
       "514542  contrast news conference sound guard even slig...           2   \n",
       "514543     goal one chosen five could take spot kick need           2   \n",
       "514544                              everyone practise say           1   \n",
       "514545  look relax hair back cornrows mobile tuck righ...           4   \n",
       "514546            another game bother rivalry two country           2   \n",
       "\n",
       "        female_count   Proper_noun_list pn exists  \\\n",
       "0                  0        [Southease]      None   \n",
       "1                  2                 []      None   \n",
       "3                  4             [Sara]      None   \n",
       "4                  3                 []      None   \n",
       "5                  1                 []      None   \n",
       "...              ...                ...       ...   \n",
       "514542             0            [Fabio]      None   \n",
       "514543             0  [Nelson, Mandela]      True   \n",
       "514544             0                 []      None   \n",
       "514545             0                 []      None   \n",
       "514546             0                 []      None   \n",
       "\n",
       "                                                sentences  article_id  year  \\\n",
       "0       Chairman of Southease Parish, Neville Harrison...           1  2010   \n",
       "1       The family of a 34-year-old mother from Bristo...          21  2010   \n",
       "3       'Truly tragic'\"Sara loved her family above eve...          21  2010   \n",
       "4       \"Everybody who knew her will love her and miss...          21  2010   \n",
       "5       \"This was a truly tragic event and we are very...          21  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "514542  Compare and contrast - Fabio Capello's news co...     2175804  2010   \n",
       "514543  And after his goal at the Nelson Mandela Bay S...     2175804  2010   \n",
       "514544      \"Everyone has been practising them,\" he said.     2175804  2010   \n",
       "514545  He looked relaxed, his hair back in cornrows, ...     2175804  2010   \n",
       "514546  For him, it is \"just another game\", he's not t...     2175804  2010   \n",
       "\n",
       "        col_type  subjectivity  polarity  \n",
       "0            0.0      0.000000  0.000000  \n",
       "1            1.0      0.200000  0.100000  \n",
       "3            1.0      0.650000  0.083333  \n",
       "4            1.0      0.600000  0.500000  \n",
       "5            1.0      0.466667 -0.133333  \n",
       "...          ...           ...       ...  \n",
       "514542       0.0      0.368889  0.131111  \n",
       "514543       0.0      0.000000  0.000000  \n",
       "514544       0.0      0.000000  0.000000  \n",
       "514545       0.0      0.345238  0.095238  \n",
       "514546       0.0      0.400000 -0.400000  \n",
       "\n",
       "[492346 rows x 12 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(df, col): \n",
    "    sub = []\n",
    "    pol = []\n",
    "    count = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row[col] > 1: \n",
    "            sub.append(row[\"subjectivity\"])\n",
    "            pol.append(row[\"polarity\"])\n",
    "        count +=1\n",
    "    return ((sum(sub))/count), ((sum(pol))/count)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results** \n",
    "\n",
    "*Subjectivity* - how subjective or objective a piece of text is. 0.0 is most objective and 1.0 is more subjective. 0.5 is a neutral score. \n",
    "\n",
    "*Polarity* - how positive or negative a piece of text is. -1 is most negative and 1 most positive. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0602\n",
      "0.0105\n"
     ]
    }
   ],
   "source": [
    "#scores MEN \n",
    "scores_sent_m = scores(df_10, 'male_count')\n",
    "subjectivity_m = round(scores_sent_m[0], 4) #subjectivity\n",
    "polarity_m = round(scores_sent_m[1], 4) #polarity\n",
    "print(subjectivity_m)\n",
    "print(polarity_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0196\n",
      "0.0036\n"
     ]
    }
   ],
   "source": [
    "#scores for women\n",
    "scores_sent_f = scores(df_10, 'female_count')\n",
    "subjectivity_f = round(scores_sent_f[0], 4) #subjectivity\n",
    "polarity_f = round(scores_sent_f[1], 4) #polarity\n",
    "print(subjectivity_f)\n",
    "print(polarity_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Subjectivity (M)</th>\n",
       "      <th>Polarity (M)</th>\n",
       "      <th>Subjectivity (F)</th>\n",
       "      <th>Polarity (F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.0058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.0059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.0573</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021</td>\n",
       "      <td>0.0566</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.0065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.0075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Subjectivity (M)  Polarity (M)  Subjectivity (F)  Polarity (F)\n",
       "0   2010            0.0602        0.0105            0.0196        0.0036\n",
       "1   2011            0.0585        0.0101            0.0200        0.0037\n",
       "2   2012            0.0605        0.0109            0.0196        0.0042\n",
       "3   2013            0.0605        0.0105            0.0209        0.0041\n",
       "4   2014            0.0608        0.0112            0.0222        0.0041\n",
       "5   2015            0.0621        0.0111            0.0236        0.0048\n",
       "6   2016            0.0613        0.0117            0.0275        0.0058\n",
       "7   2017            0.0586        0.0098            0.0295        0.0059\n",
       "8   2018            0.0583        0.0096            0.0320        0.0061\n",
       "9   2019            0.0588        0.0090            0.0317        0.0059\n",
       "10  2020            0.0573        0.0102            0.0310        0.0061\n",
       "11  2021            0.0566        0.0102            0.0340        0.0065\n",
       "12  2022            0.0567        0.0096            0.0354        0.0075"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#polarity and sentiment scores for F and M by year\n",
    "years = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "sub_male = [0.0602, 0.0585, 0.0605, 0.0605, 0.0608, 0.0621, 0.0613, 0.0586, 0.0583, 0.0588, 0.0573, 0.0566, 0.0567]\n",
    "pol_male = [0.0105, 0.0101, 0.0109, 0.0105, 0.0112, 0.0111, 0.0117, 0.0098, 0.0096, 0.009, 0.0102, 0.0102, 0.0096]\n",
    "sub_female = [0.0196, 0.02, 0.0196, 0.0209, 0.0222, 0.0236, 0.0275, 0.0295, 0.032, 0.0317, 0.031, 0.034, 0.0354]\n",
    "pol_female = [0.0036, 0.0037, 0.0042, 0.0041, 0.0041, 0.0048, 0.0058, 0.0059, 0.0061, 0.0059, 0.0061, 0.0065, 0.0075]\n",
    "\n",
    "sent_data = {'Year': years, \n",
    "             'Subjectivity (M)': sub_male,\n",
    "             'Polarity (M)': pol_male, \n",
    "             'Subjectivity (F)': sub_female, \n",
    "             'Polarity (F)': pol_female}\n",
    "\n",
    "sent_data = pd.DataFrame(sent_data)\n",
    "sent_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               2022\n",
      "                   \n",
      "Subjectivity  0.638\n",
      "Polarity      0.926\n"
     ]
    }
   ],
   "source": [
    "results = {' ': ['Subjectivity (M)', 'Polarity (M)', 'Subjectivity (F)', 'Polarity (F)'],\n",
    "           '2022': [0.638, 0.926]\n",
    "           }\n",
    "\n",
    "# Create a pandas dataframe from the dictionary\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Set the index of the dataframe to the Kernel column\n",
    "df.set_index(' ', inplace=True)\n",
    "\n",
    "# Display the dataframe\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This CNN loads a dataset of sentences within documents labeled as positive or negative, tokenizes the text, and uses a CNN to classify the sentiment of the text. It trains the model, evaluates it on a test set, and makes predictions. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decade Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all = pd.concat([df_10, df_11, df_12, df_13, df_14, df_15, df_16, df_17, df_18, df_19, df_20, df_21, df_22])\n",
    "#df_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table Comparing Model Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {' ': ['LSTM', 'CNN'],\n",
    "           'Accuracy': [0.638, 0.926],\n",
    "           'Mean Squared Error': [0.193, 0.0605],\n",
    "           'Test loss': [0.65, 0.223]}\n",
    "\n",
    "# Create a pandas dataframe from the dictionary\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Set the index of the dataframe to the Kernel column\n",
    "df.set_index(' ', inplace=True)\n",
    "\n",
    "# Display the dataframe\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
