{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "#pip install textblob\n",
    "#pip install keras\n",
    "#pip install tensorflow\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_09= pd.read_pickle(r\"C:\\Users\\danie\\Documents\\GitHub\\Masters-Thesis\\2009_preprocessed_date.pickle\") \n",
    "df_09= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis/2009_preprocessed_date.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity(sentence):\n",
    "    subjectivity = \"\"\n",
    "\n",
    "    subjectivity = TextBlob(sentence).sentiment.subjectivity\n",
    "\n",
    "    return subjectivity\n",
    "\n",
    "def polarity(sentence):\n",
    "    polarity = \"\"\n",
    "\n",
    "    polarity = TextBlob(sentence).sentiment.polarity\n",
    "\n",
    "    return polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_09['subjectivity'] = df_09['sentences'].apply(subjectivity)\n",
    "df_09['polarity'] = df_09['sentences'].apply(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>encoded_sentences</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91571</th>\n",
       "      <td>Liam Gallagher has broken the silence surround...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>([break, silence, surround, ', break, say, ban...</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91572</th>\n",
       "      <td>However, in an interview with The Times Liam G...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>([however, interview, the, say, longer], 2, 0, 0)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91573</th>\n",
       "      <td>I think we all know that.</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>([i, think, know], 0, 0, 0)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91574</th>\n",
       "      <td>So that's done.</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>([so], 0, 0, 0)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91575</th>\n",
       "      <td>\"\"It's a shame, but that's life.</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>([shame, life], 0, 0, 0)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentences  article_id  year  \\\n",
       "91571  Liam Gallagher has broken the silence surround...        5048  2009   \n",
       "91572  However, in an interview with The Times Liam G...        5048  2009   \n",
       "91573                          I think we all know that.        5048  2009   \n",
       "91574                                    So that's done.        5048  2009   \n",
       "91575                   \"\"It's a shame, but that's life.        5048  2009   \n",
       "\n",
       "                                       encoded_sentences  subjectivity  \\\n",
       "91571  ([break, silence, surround, ', break, say, ban...          0.35   \n",
       "91572  ([however, interview, the, say, longer], 2, 0, 0)          0.00   \n",
       "91573                        ([i, think, know], 0, 0, 0)          0.00   \n",
       "91574                                    ([so], 0, 0, 0)          0.00   \n",
       "91575                           ([shame, life], 0, 0, 0)          0.00   \n",
       "\n",
       "       polarity  \n",
       "91571      -0.2  \n",
       "91572       0.0  \n",
       "91573       0.0  \n",
       "91574       0.0  \n",
       "91575       0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_09.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0    7802\n",
       " 1.0    1516\n",
       "-1.0     394\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a 3 point criteria from -1 to 1 (range of polarity)\n",
    "def map_sentiment(value):\n",
    "    if value <= -0.33:\n",
    "        return -1\n",
    "    elif value >= 0.33:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "df_09['sentiment'] = df_09['polarity'].apply(map_sentiment)\n",
    "df_09['sentiment'] = df_09[\"sentiment\"].astype(float)\n",
    "df_09[\"sentiment\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN LSTM Model for Sentiment Analysis** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "243/243 [==============================] - 8s 28ms/step - loss: 0.3800 - accuracy: 0.8005 - mean_squared_error: 0.1878 - val_loss: 0.3501 - val_accuracy: 0.7952 - val_mean_squared_error: 0.1949\n",
      "Epoch 2/10\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.3643 - accuracy: 0.8054 - mean_squared_error: 0.1814 - val_loss: 0.3438 - val_accuracy: 0.7952 - val_mean_squared_error: 0.1934\n",
      "Epoch 3/10\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 0.3628 - accuracy: 0.8054 - mean_squared_error: 0.1811 - val_loss: 0.3429 - val_accuracy: 0.7952 - val_mean_squared_error: 0.1932\n",
      "Epoch 4/10\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 0.3630 - accuracy: 0.8054 - mean_squared_error: 0.1811 - val_loss: 0.3440 - val_accuracy: 0.7952 - val_mean_squared_error: 0.1935\n",
      "Epoch 5/10\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 0.3629 - accuracy: 0.8054 - mean_squared_error: 0.1811 - val_loss: 0.3460 - val_accuracy: 0.7952 - val_mean_squared_error: 0.1939\n",
      "Epoch 6/10\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 0.3640 - accuracy: 0.8054 - mean_squared_error: 0.1813 - val_loss: 0.3447 - val_accuracy: 0.7952 - val_mean_squared_error: 0.1936\n",
      "Epoch 7/10\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.3624 - accuracy: 0.8054 - mean_squared_error: 0.1810 - val_loss: 0.3441 - val_accuracy: 0.7952 - val_mean_squared_error: 0.1935\n",
      "Epoch 8/10\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 0.3625 - accuracy: 0.8054 - mean_squared_error: 0.1810 - val_loss: 0.3438 - val_accuracy: 0.7952 - val_mean_squared_error: 0.1934\n",
      "Epoch 9/10\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 0.3626 - accuracy: 0.8054 - mean_squared_error: 0.1810 - val_loss: 0.3425 - val_accuracy: 0.7952 - val_mean_squared_error: 0.1932\n",
      "Epoch 10/10\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.3623 - accuracy: 0.8054 - mean_squared_error: 0.1810 - val_loss: 0.3425 - val_accuracy: 0.7952 - val_mean_squared_error: 0.1932\n",
      "Test loss: 0.3425159454345703\n",
      "Test accuracy: 0.7951621413230896\n"
     ]
    }
   ],
   "source": [
    "#define X and y \n",
    "X = df_09['sentences']\n",
    "y = df_09['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state = 42)\n",
    "\n",
    "# Tokenize the data\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert the texts to sequences\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences to ensure equal length\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=1000, output_dim=64, input_length=maxlen))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', \"mean_squared_error\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN Model for Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.3705 - accuracy: 0.7897 - mean_squared_error: 0.1881 - val_loss: 0.1815 - val_accuracy: 0.8178 - val_mean_squared_error: 0.1498\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.0476 - accuracy: 0.8565 - mean_squared_error: 0.1157 - val_loss: -0.1903 - val_accuracy: 0.8610 - val_mean_squared_error: 0.1179\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 2s 16ms/step - loss: -0.6916 - accuracy: 0.9017 - mean_squared_error: 0.0882 - val_loss: -1.5509 - val_accuracy: 0.8513 - val_mean_squared_error: 0.1405\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 2s 17ms/step - loss: -4.1102 - accuracy: 0.9149 - mean_squared_error: 0.0809 - val_loss: -7.9977 - val_accuracy: 0.8621 - val_mean_squared_error: 0.1353\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 2s 17ms/step - loss: -14.8273 - accuracy: 0.9171 - mean_squared_error: 0.0810 - val_loss: -23.6370 - val_accuracy: 0.8631 - val_mean_squared_error: 0.1356\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 2s 17ms/step - loss: -36.6127 - accuracy: 0.9189 - mean_squared_error: 0.0798 - val_loss: -51.5136 - val_accuracy: 0.8652 - val_mean_squared_error: 0.1343\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 2s 16ms/step - loss: -72.6850 - accuracy: 0.9185 - mean_squared_error: 0.0811 - val_loss: -95.8967 - val_accuracy: 0.8652 - val_mean_squared_error: 0.1342\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 2s 17ms/step - loss: -126.1227 - accuracy: 0.9234 - mean_squared_error: 0.0760 - val_loss: -156.0093 - val_accuracy: 0.8641 - val_mean_squared_error: 0.1355\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 2s 17ms/step - loss: -197.8985 - accuracy: 0.9246 - mean_squared_error: 0.0750 - val_loss: -233.1326 - val_accuracy: 0.8595 - val_mean_squared_error: 0.1400\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 2s 16ms/step - loss: -291.3333 - accuracy: 0.9241 - mean_squared_error: 0.0756 - val_loss: -334.3151 - val_accuracy: 0.8662 - val_mean_squared_error: 0.1339\n",
      "Test loss: -334.3150634765625\n",
      "Test accuracy: 0.8661863207817078\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define X and y\n",
    "X = df_09['sentences']\n",
    "y = df_09['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert the texts to sequences\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences to ensure equal length\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128, input_length=maxlen))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', \"mean_squared_error\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table Comparing Model Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Accuracy  Mean Squared Error  Test loss\n",
      "                                             \n",
      "LSTM     0.795              0.1930     0.3425\n",
      "CNN      0.866              0.1339  -334.3150\n"
     ]
    }
   ],
   "source": [
    "results = {' ': ['LSTM', 'CNN'],\n",
    "           'Accuracy': [0.795, 0.866],\n",
    "           'Mean Squared Error': [0.193, 0.1339],\n",
    "           'Test loss': [0.3425, -334.315]}\n",
    "\n",
    "# Create a pandas dataframe from the dictionary\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Set the index of the dataframe to the Kernel column\n",
    "df.set_index(' ', inplace=True)\n",
    "\n",
    "# Display the dataframe\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
