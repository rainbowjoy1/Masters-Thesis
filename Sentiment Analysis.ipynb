{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_09= pd.read_pickle(r\"C:\\Users\\danie\\Documents\\GitHub\\Masters-Thesis\\2009_preprocessed_date.pickle\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity(sentence):\n",
    "    subjectivity = \"\"\n",
    "\n",
    "    subjectivity = TextBlob(sentence).sentiment.subjectivity\n",
    "\n",
    "    return subjectivity\n",
    "\n",
    "def polarity(sentence):\n",
    "    polarity = \"\"\n",
    "\n",
    "    polarity = TextBlob(sentence).sentiment.polarity\n",
    "\n",
    "    return polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_09['subjectivity'] = df_09['sentences'].apply(subjectivity)\n",
    "df_09['polarity'] = df_09['sentences'].apply(polarity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>encoded_sentences</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91571</th>\n",
       "      <td>Liam Gallagher has broken the silence surround...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>([break, silence, surround, ', break, say, ban...</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91572</th>\n",
       "      <td>However, in an interview with The Times Liam G...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>([however, interview, the, say, longer], 2, 0, 0)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91573</th>\n",
       "      <td>I think we all know that.</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>([i, think, know], 0, 0, 0)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91574</th>\n",
       "      <td>So that's done.</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>([so], 0, 0, 0)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91575</th>\n",
       "      <td>\"\"It's a shame, but that's life.</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>([shame, life], 0, 0, 0)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentences  article_id  year  \\\n",
       "91571  Liam Gallagher has broken the silence surround...        5048  2009   \n",
       "91572  However, in an interview with The Times Liam G...        5048  2009   \n",
       "91573                          I think we all know that.        5048  2009   \n",
       "91574                                    So that's done.        5048  2009   \n",
       "91575                   \"\"It's a shame, but that's life.        5048  2009   \n",
       "\n",
       "                                       encoded_sentences  subjectivity  \\\n",
       "91571  ([break, silence, surround, ', break, say, ban...          0.35   \n",
       "91572  ([however, interview, the, say, longer], 2, 0, 0)          0.00   \n",
       "91573                        ([i, think, know], 0, 0, 0)          0.00   \n",
       "91574                                    ([so], 0, 0, 0)          0.00   \n",
       "91575                           ([shame, life], 0, 0, 0)          0.00   \n",
       "\n",
       "       polarity  \n",
       "91571      -0.2  \n",
       "91572       0.0  \n",
       "91573       0.0  \n",
       "91574       0.0  \n",
       "91575       0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_09.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "243/243 [==============================] - 16s 53ms/step - loss: 0.6470 - accuracy: 0.2847 - val_loss: 0.6444 - val_accuracy: 0.2851\n",
      "Epoch 2/10\n",
      "243/243 [==============================] - 10s 40ms/step - loss: 0.6456 - accuracy: 0.2859 - val_loss: 0.6418 - val_accuracy: 0.2851\n",
      "Epoch 3/10\n",
      "243/243 [==============================] - 10s 42ms/step - loss: 0.6449 - accuracy: 0.2859 - val_loss: 0.6417 - val_accuracy: 0.2851\n",
      "Epoch 4/10\n",
      "243/243 [==============================] - 10s 42ms/step - loss: 0.6450 - accuracy: 0.2859 - val_loss: 0.6427 - val_accuracy: 0.2851\n",
      "Epoch 5/10\n",
      "243/243 [==============================] - 10s 42ms/step - loss: 0.6456 - accuracy: 0.2859 - val_loss: 0.6425 - val_accuracy: 0.2851\n",
      "Epoch 6/10\n",
      "243/243 [==============================] - 10s 41ms/step - loss: 0.6450 - accuracy: 0.2859 - val_loss: 0.6417 - val_accuracy: 0.2851\n",
      "Epoch 7/10\n",
      "243/243 [==============================] - 10s 40ms/step - loss: 0.6452 - accuracy: 0.2859 - val_loss: 0.6421 - val_accuracy: 0.2851\n",
      "Epoch 8/10\n",
      "243/243 [==============================] - 10s 42ms/step - loss: 0.6449 - accuracy: 0.2859 - val_loss: 0.6417 - val_accuracy: 0.2851\n",
      "Epoch 9/10\n",
      "243/243 [==============================] - 10s 41ms/step - loss: 0.6451 - accuracy: 0.2859 - val_loss: 0.6425 - val_accuracy: 0.2851\n",
      "Epoch 10/10\n",
      "243/243 [==============================] - 10s 42ms/step - loss: 0.6449 - accuracy: 0.2859 - val_loss: 0.6421 - val_accuracy: 0.2851\n",
      "Test loss: 0.6421465277671814\n",
      "Test accuracy: 0.28512609004974365\n"
     ]
    }
   ],
   "source": [
    "#LSTM Sentiemnt Analysis \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_09['sentences']\n",
    "y = df_09['subjectivity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state = 42)\n",
    "\n",
    "# Tokenize the data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert the texts to sequences\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences to ensure equal length\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=64, input_length=maxlen))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
