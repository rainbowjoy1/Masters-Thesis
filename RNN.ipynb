{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#warnings \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#for RNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "#for performance evaluation \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pretty_confusion_matrix import pp_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "#for visualization \n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Versions of Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Scikit-learn version:\", sklearn_version)\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "#unable to find the version for pretty_conf_matrix, but maybe only one of us runs it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pre-processed data from pickle \n",
    "year = \"2015\"\n",
    "file_path = \"C:/Users/danie/Downloads/\"\n",
    "file_path_2 = \"_final_rnn.pickle\"\n",
    "\n",
    "df_10 = pd.read_pickle(file_path + year + file_path_2)\n",
    "#df_09= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2009_text_wo_names.pickle\")\n",
    "#df_11= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2011_text_wo_names.pickle\")\n",
    "#df_12= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2012_text_wo_names.pickle\")\n",
    "#df_13= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2013_text_wo_names.pickle\")\n",
    "#df_14= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2014_text_wo_names.pickle\")\n",
    "#df_15= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2015_text_wo_names.pickle\")\n",
    "#df_16= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2016_text_wo_names.pickle\")\n",
    "#df_17= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2017_text_wo_names.pickle\")\n",
    "#df_18= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2018_text_wo_names.pickle\")\n",
    "#df_19 = pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2019_text_wo_names.pickle\")\n",
    "#df_20 = pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2020_text_wo_names.pickle\")\n",
    "#df_21 = pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2021_text_wo_names.pickle\")\n",
    "#df_22 = pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2022_text_wo_names_(1).pickle\")\n",
    "df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_count(male_col, female_col):\n",
    "    if female_col > male_col and male_col == 0:\n",
    "        return 1\n",
    "    elif male_col> female_col and female_col ==0: \n",
    "        return 0\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply function to only get rows with an absolute count \n",
    "df_10['col_type'] = df_10.apply(lambda row: absolute_count(row['male_count'], row['female_count']),axis=1)\n",
    "\n",
    "#remove nulls \n",
    "df_10 = df_10[df_10[\"col_type\"].notnull()]\n",
    "\n",
    "#DOC: number of male and female columns\n",
    "df_10[\"col_type\"].value_counts()  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the DF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the df by the preprocessed \n",
    "x_train, x_test, y_train, y_test = train_test_split(df_10[\"pre_processed_sent\"], \n",
    "                                                    df_10[\"col_type\"], \n",
    "                                                    stratify = df_10[\"col_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(df_10[\"string_rnn\"],\n",
    "                                                df_10[\"col_type\"], \n",
    "                                                stratify = df_10[\"col_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((xTrain, yTrain)) #string_rnn here \n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((xTest, yTest)) #clean text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example, gen_label in train_dataset.take(7):\n",
    "  print('text: ', example.numpy())\n",
    "  print('label: ', gen_label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 50000 \n",
    "batch_size = 64 # best practice\n",
    "train_dataset = train_dataset.shuffle(buffer_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map text features to integer sequences for all of the vocabulary\n",
    "vocab_size = 60000 #this is 1/12 of all the words in the english language \n",
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=vocab_size)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_vocab = np.array(encoder.get_vocabulary())\n",
    "vocab_dict = dict(enumerate(encoded_vocab))\n",
    "#vocab_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN/LSTM Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newmodel\n",
    "rnn1 = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 256, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newmodel - BEST ONE SO FAR!!\n",
    "rnn2 = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 256, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new2\n",
    "rnn3 = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 1024, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "fitted_model = rnn2.fit(train_dataset, epochs=8,\n",
    "                    validation_data=test_dataset, \n",
    "                    callbacks = [early_stop])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving & Loading the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model \n",
    "#model_path = \"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/models/\"\n",
    "model_path = \"C:/Users/danie/Desktop/RNN_\"+year\n",
    "rnn2.save(model_path) #comment this out "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(fitted_model, metric):\n",
    "  plt.plot(fitted_model.history[metric])\n",
    "  plt.plot(fitted_model.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(fitted_model, 'accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(fitted_model, 'loss')\n",
    "plt.ylim(0, None)\n",
    "plt.title(\"Loss\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_true and y_pred to numpy arrays\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_dataset], axis=0)\n",
    "y_pred = np.concatenate([rnn2.predict(x).argmax(axis=-1) for x, _ in test_dataset], axis=0)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "#define the positive class as the female class \n",
    "positive_class =1 \n",
    "\n",
    "#define counts for each element of confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels = [0, positive_class]).ravel()\n",
    "results_cm = {' ': ['True Negative', 'False Positive', 'False Negative', 'True Positive'],\n",
    "           'Counts': [tn, fp, fn, tp]}\n",
    "\n",
    "df_cm = pd.DataFrame(results_cm)\n",
    "df_cm.set_index(' ', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, pos_label=1)\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 score:', f1_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation** we prove our HP that the model is worse in all evaluation performance metrics in predicting the first class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a cute confusion matrix \n",
    "data = pd.DataFrame(cm)\n",
    "cmap = 'copper' #to change palette, look up cmap palettes\n",
    "pp_matrix(data, cmap=cmap)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coefficient Analysis**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***For all layers***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature weights\n",
    "weights = rnn2.layers[1].get_weights()[0] #1 is what we have been using so farfor layers\n",
    "\n",
    "# Sort the feature weights\n",
    "sorted_weights = np.sort(weights, axis=0)[::-1]\n",
    "\n",
    "# Select the top 1000 features\n",
    "top_features = sorted_weights[:5000]\n",
    "\n",
    "# Select the bottom 1000 features\n",
    "bottom_features = sorted_weights[-5000:]\n",
    "\n",
    "vocab_dict = dict(enumerate(encoded_vocab))\n",
    "\n",
    "# Map the features back to words\n",
    "top_words = encoded_vocab[np.argsort(weights[:,::-1])[:5000]]\n",
    "bottom_words = encoded_vocab[np.argsort(weights)][:5000]\n",
    "\n",
    "\n",
    "# top\n",
    "s1h = pd.Series(top_words.ravel(), name='words') #ravel() to flatten \n",
    "s2h= pd.Series(top_features.ravel(), name='weights')\n",
    "df_high = pd.concat([s1h, s2h], axis = 1)\n",
    "#df_high\n",
    "\n",
    "#bottom\n",
    "#print(\"Bottom features:\")#, top_words, type(top_features))\n",
    "s1l = pd.Series(bottom_words.ravel(), name='words') #ravel() to flatten \n",
    "s2l= pd.Series(bottom_features.ravel(), name='weights')\n",
    "df_low = pd.concat([s1l, s2l], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df, column_name):\n",
    "    unique_values = df[column_name].unique()\n",
    "    rows_to_remove = []\n",
    "    for value in unique_values:\n",
    "        rows_with_value = df[df[column_name] == value]\n",
    "        if len(rows_with_value) > 1:\n",
    "            rows_to_remove += list(rows_with_value.iloc[1:].index)\n",
    "    df = df.drop(rows_to_remove)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df_h = remove_duplicates(df_high, 'words')\n",
    "df_l = remove_duplicates(df_low, 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_single_character_rows(df, column_name):\n",
    "    mask = df[column_name].str.len() <= 2\n",
    "    df_filtered = df[~mask]\n",
    "    return df_filtered\n",
    "\n",
    "df_h = remove_single_character_rows(df_h, 'words')\n",
    "df_l = remove_single_character_rows(df_l, 'words')\n",
    "df_l.sort_values(by = \"weights\", ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort highest\n",
    "#df_sorted_h = df_high.sort_values(by = \"weights\", ascending=False)\n",
    "#df_sorted_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort lowest\n",
    "#df_sorted_l = df_low.sort_values(by = \"weights\", ascending=True)\n",
    "#df_sorted_l.head(50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Cloud**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format according to which list \n",
    "text = ' '.join(df_h['words'])\n",
    "\n",
    "# Create the word cloud\n",
    "wordcloud = WordCloud(width=800, height=800, background_color='white').generate(text)\n",
    "\n",
    "# Plot the word cloud\n",
    "plt.figure(figsize=(8,8), facecolor=None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code with Attention Mechanism**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
