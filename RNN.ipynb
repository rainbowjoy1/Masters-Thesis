{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#warnings \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#for RNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "#for performance evaluation \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pretty_confusion_matrix import pp_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "#for visualization \n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Versions of Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Pandas version:\", pd.__version__)\n",
    "#print(\"Scikit-learn version:\", sklearn_version)\n",
    "#print(\"NumPy version:\", np.__version__)\n",
    "#print(\"TensorFlow version:\", tf.__version__)\n",
    "#unable to find the version for pretty_conf_matrix, but maybe only one of us runs it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_processed_sent</th>\n",
       "      <th>string_rnn</th>\n",
       "      <th>male_count</th>\n",
       "      <th>female_count</th>\n",
       "      <th>Proper_noun_list</th>\n",
       "      <th>pn exists</th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[say, delight, restored, bridge, back, use]</td>\n",
       "      <td>say delight restored bridge back use</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Southease]</td>\n",
       "      <td>None</td>\n",
       "      <td>Chairman of Southease Parish, Neville Harrison...</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[family, year, old, kill, house, fire, pay, tr...</td>\n",
       "      <td>family year old kill house fire pay tribute br...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>The family of a 34-year-old mother from Bristo...</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[family, say, kind, totally, dedicated]</td>\n",
       "      <td>family say kind totally dedicated</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>Her family said she was kind and a totally ded...</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[truly, tragic, love, family, everything, give...</td>\n",
       "      <td>truly tragic love family everything give famil...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[Sara]</td>\n",
       "      <td>None</td>\n",
       "      <td>'Truly tragic'\"Sara loved her family above eve...</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[everybody, know, love, miss, always]</td>\n",
       "      <td>everybody know love miss always</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Everybody who knew her will love her and miss...</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514542</th>\n",
       "      <td>[contrast, news, conference, sound, guard, eve...</td>\n",
       "      <td>contrast news conference sound guard even slig...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Fabio]</td>\n",
       "      <td>None</td>\n",
       "      <td>Compare and contrast - Fabio Capello's news co...</td>\n",
       "      <td>2175804</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514543</th>\n",
       "      <td>[goal, one, chosen, five, could, take, spot, k...</td>\n",
       "      <td>goal one chosen five could take spot kick need</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Nelson, Mandela]</td>\n",
       "      <td>True</td>\n",
       "      <td>And after his goal at the Nelson Mandela Bay S...</td>\n",
       "      <td>2175804</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514544</th>\n",
       "      <td>[everyone, practise, say]</td>\n",
       "      <td>everyone practise say</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Everyone has been practising them,\" he said.</td>\n",
       "      <td>2175804</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514545</th>\n",
       "      <td>[look, relax, hair, back, cornrows, mobile, tu...</td>\n",
       "      <td>look relax hair back cornrows mobile tuck righ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>He looked relaxed, his hair back in cornrows, ...</td>\n",
       "      <td>2175804</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514546</th>\n",
       "      <td>[another, game, bother, rivalry, two, country]</td>\n",
       "      <td>another game bother rivalry two country</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>For him, it is \"just another game\", he's not t...</td>\n",
       "      <td>2175804</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>514547 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       pre_processed_sent  \\\n",
       "0             [say, delight, restored, bridge, back, use]   \n",
       "1       [family, year, old, kill, house, fire, pay, tr...   \n",
       "2                 [family, say, kind, totally, dedicated]   \n",
       "3       [truly, tragic, love, family, everything, give...   \n",
       "4                   [everybody, know, love, miss, always]   \n",
       "...                                                   ...   \n",
       "514542  [contrast, news, conference, sound, guard, eve...   \n",
       "514543  [goal, one, chosen, five, could, take, spot, k...   \n",
       "514544                          [everyone, practise, say]   \n",
       "514545  [look, relax, hair, back, cornrows, mobile, tu...   \n",
       "514546     [another, game, bother, rivalry, two, country]   \n",
       "\n",
       "                                               string_rnn  male_count  \\\n",
       "0                    say delight restored bridge back use           1   \n",
       "1       family year old kill house fire pay tribute br...           0   \n",
       "2                       family say kind totally dedicated           1   \n",
       "3       truly tragic love family everything give famil...           0   \n",
       "4                         everybody know love miss always           0   \n",
       "...                                                   ...         ...   \n",
       "514542  contrast news conference sound guard even slig...           2   \n",
       "514543     goal one chosen five could take spot kick need           2   \n",
       "514544                              everyone practise say           1   \n",
       "514545  look relax hair back cornrows mobile tuck righ...           4   \n",
       "514546            another game bother rivalry two country           2   \n",
       "\n",
       "        female_count   Proper_noun_list pn exists  \\\n",
       "0                  0        [Southease]      None   \n",
       "1                  2                 []      None   \n",
       "2                  4                 []      None   \n",
       "3                  4             [Sara]      None   \n",
       "4                  3                 []      None   \n",
       "...              ...                ...       ...   \n",
       "514542             0            [Fabio]      None   \n",
       "514543             0  [Nelson, Mandela]      True   \n",
       "514544             0                 []      None   \n",
       "514545             0                 []      None   \n",
       "514546             0                 []      None   \n",
       "\n",
       "                                                sentences  article_id  year  \\\n",
       "0       Chairman of Southease Parish, Neville Harrison...           1  2010   \n",
       "1       The family of a 34-year-old mother from Bristo...          21  2010   \n",
       "2       Her family said she was kind and a totally ded...          21  2010   \n",
       "3       'Truly tragic'\"Sara loved her family above eve...          21  2010   \n",
       "4       \"Everybody who knew her will love her and miss...          21  2010   \n",
       "...                                                   ...         ...   ...   \n",
       "514542  Compare and contrast - Fabio Capello's news co...     2175804  2010   \n",
       "514543  And after his goal at the Nelson Mandela Bay S...     2175804  2010   \n",
       "514544      \"Everyone has been practising them,\" he said.     2175804  2010   \n",
       "514545  He looked relaxed, his hair back in cornrows, ...     2175804  2010   \n",
       "514546  For him, it is \"just another game\", he's not t...     2175804  2010   \n",
       "\n",
       "       col_type  \n",
       "0             0  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "...         ...  \n",
       "514542        0  \n",
       "514543        0  \n",
       "514544        0  \n",
       "514545        0  \n",
       "514546        0  \n",
       "\n",
       "[514547 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pre-processed data from pickle \n",
    "year = \"2010\"\n",
    "file_path = \"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/\"\n",
    "file_path_2 = \"_final_rnn.pickle\"\n",
    "\n",
    "df_10 = pd.read_pickle(file_path + year + file_path_2)\n",
    "#df_09= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2009_text_wo_names.pickle\")\n",
    "#df_11= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2011_text_wo_names.pickle\")\n",
    "#df_12= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2012_text_wo_names.pickle\")\n",
    "#df_13= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2013_text_wo_names.pickle\")\n",
    "#df_14= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2014_text_wo_names.pickle\")\n",
    "#df_15= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2015_text_wo_names.pickle\")\n",
    "#df_16= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2016_text_wo_names.pickle\")\n",
    "#df_17= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2017_text_wo_names.pickle\")\n",
    "#df_18= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2018_text_wo_names.pickle\")\n",
    "#df_19 = pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2019_text_wo_names.pickle\")\n",
    "#df_20 = pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2020_text_wo_names.pickle\")\n",
    "#df_21 = pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2021_text_wo_names.pickle\")\n",
    "#df_22 = pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/2022_text_wo_names_(1).pickle\")\n",
    "df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_count(male_col, female_col):\n",
    "    if female_col > male_col and male_col == 0:\n",
    "        return 1\n",
    "    elif male_col> female_col and female_col ==0: \n",
    "        return 0\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    378476\n",
       "1.0    113870\n",
       "Name: col_type, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply function to only get rows with an absolute count \n",
    "df_10['col_type'] = df_10.apply(lambda row: absolute_count(row['male_count'], row['female_count']),axis=1)\n",
    "\n",
    "#remove nulls \n",
    "df_10 = df_10[df_10[\"col_type\"].notnull()]\n",
    "\n",
    "#DOC: number of male and female columns\n",
    "df_10[\"col_type\"].value_counts()  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the DF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the df by the preprocessed \n",
    "x_train, x_test, y_train, y_test = train_test_split(df_10[\"pre_processed_sent\"], \n",
    "                                                    df_10[\"col_type\"], \n",
    "                                                    stratify = df_10[\"col_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(df_10[\"string_rnn\"],\n",
    "                                                df_10[\"col_type\"], \n",
    "                                                stratify = df_10[\"col_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((xTrain, yTrain)) #string_rnn here \n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((xTest, yTest)) #clean text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  b'biggest oversight would job ensure financing retirement pension today tomorrow add'\n",
      "label:  0.0\n",
      "text:  b'say always'\n",
      "label:  0.0\n",
      "text:  b'way solve problem use video allude device team develop'\n",
      "label:  1.0\n",
      "text:  b'people love really special evening'\n",
      "label:  0.0\n",
      "text:  b'hold various role recently work investigation death four firefighter'\n",
      "label:  1.0\n",
      "text:  b'medical unit bst seven day week end school holiday period west pier'\n",
      "label:  0.0\n",
      "text:  b'say repair control pod would mean temporarily stop drill work rig time cost day operate rig'\n",
      "label:  0.0\n"
     ]
    }
   ],
   "source": [
    "for example, gen_label in train_dataset.take(7):\n",
    "  print('text: ', example.numpy())\n",
    "  print('label: ', gen_label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 50000 \n",
    "batch_size = 64 # best practice\n",
    "train_dataset = train_dataset.shuffle(buffer_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map text features to integer sequences for all of the vocabulary\n",
    "vocab_size = 60000 #this is 1/12 of all the words in the english language \n",
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=vocab_size)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_vocab = np.array(encoder.get_vocabulary())\n",
    "vocab_dict = dict(enumerate(encoded_vocab))\n",
    "#vocab_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN/LSTM Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newmodel\n",
    "rnn1 = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 256, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newmodel - BEST ONE SO FAR!!\n",
    "rnn2 = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 256, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new2\n",
    "rnn3 = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 1024, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn3.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "fitted_model = rnn3.fit(train_dataset, epochs=3,\n",
    "                    validation_data=test_dataset, \n",
    "                    callbacks = [early_stop])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving & Loading the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model \n",
    "model_path = \"/Users/yolandaferreirofranchi/Desktop/ThesisDatasets/models\"\n",
    "rnn3.save(model_path) #comment this out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:39:23.876685: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:24.636427: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:24.645837: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:24.886487: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:25.111472: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:25.120244: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:25.672607: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:25.947158: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:25.956549: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:26.443486: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:26.452280: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:27.183797: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:27.234511: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:27.243548: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:27.283090: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:27.291392: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:27.394404: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:27.403108: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:27.419946: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:27.786324: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:27.829188: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:27.907392: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:28.644752: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:28.881489: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:28.890960: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:29.420396: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:29.451392: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:29.460547: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:29.470296: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:29.479372: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:29.536257: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:29.544722: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:29.666419: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:29.675777: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:29.705573: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:29.713964: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:30.222818: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:30.232064: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:30.257814: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:31.025215: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:31.057289: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:31.128704: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:31.532300: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:31.542267: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:31.676039: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:31.725299: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:31.734017: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:31.762265: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:31.979277: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:31.988885: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:31.999902: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:32.008333: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:32.133599: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:32.178243: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:32.326845: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 16:39:32.335859: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "pred score of word ['beautiful'] for the negative class is: -0.366656094789505\n",
      "pred score of word ['beautiful'] for the positive class is: 0.4479595422744751\n"
     ]
    }
   ],
   "source": [
    "#load saved model \n",
    "loaded_model = load_model(model_path)\n",
    "\n",
    "#make predictions based on model \n",
    "X_new = ['beautiful'] #add word/list of words that we want to predict scores for \n",
    "y_pred = loaded_model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred score of word ['beautiful'] for the negative class is: -0.366656094789505\n",
      "pred score of word ['beautiful'] for the positive class is: 0.4479595422744751\n"
     ]
    }
   ],
   "source": [
    "#print the predictions\n",
    "print(\"pred score of word {} for the negative class is: {}\".format(X_new, y_pred[0, 0]))\n",
    "print(\"pred score of word {} for the positive class is: {}\".format(X_new, y_pred[0, 1]))  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(fitted_model, metric):\n",
    "  plt.plot(fitted_model.history[metric])\n",
    "  plt.plot(fitted_model.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "   1/5770 [..............................] - ETA: 10:03:30 - loss: 0.2865 - accuracy: 0.8750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g0/r571pkwj6973dlq1m_v76wp40000gn/T/ipykernel_6336/3813306180.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m plot_graphs(loaded_model.fit(train_dataset, epochs=3,\n\u001b[0m\u001b[1;32m      4\u001b[0m                     validation_data=test_dataset), 'accuracy')\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1562\u001b[0m                         ):\n\u001b[1;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1565\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2494\u001b[0m       (graph_function,\n\u001b[1;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1861\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(fitted_model, 'accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(fitted_model, 'loss')\n",
    "plt.ylim(0, None)\n",
    "plt.title(\"Loss\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_true and y_pred to numpy arrays\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_dataset], axis=0)\n",
    "y_pred = np.concatenate([rnn3.predict(x).argmax(axis=-1) for x, _ in test_dataset], axis=0)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "#define the positive class as the female class \n",
    "positive_class =1 \n",
    "\n",
    "#define counts for each element of confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels = [0, positive_class]).ravel()\n",
    "results_cm = {' ': ['True Negative', 'False Positive', 'False Negative', 'True Positive'],\n",
    "           'Counts': [tn, fp, fn, tp]}\n",
    "\n",
    "df_cm = pd.DataFrame(results_cm)\n",
    "df_cm.set_index(' ', inplace=True)\n",
    "print(df_cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, pos_label=1)\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 score:', f1_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation** we prove our HP that the model is worse in all evaluation performance metrics in predicting the first class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a cute confusion matrix \n",
    "data = pd.DataFrame(cm)\n",
    "cmap = 'copper' #to change palette, look up cmap palettes\n",
    "pp_matrix(data, cmap=cmap)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coefficient Analysis**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***For all layers***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature weights\n",
    "weights = rnn3.layers[1].get_weights()[0] #1 is what we have been using so farfor layers\n",
    "\n",
    "# Sort the feature weights\n",
    "sorted_weights = np.sort(weights, axis=0)[::-1]\n",
    "\n",
    "# Select the top 1000 features\n",
    "top_features = sorted_weights[:5000]\n",
    "\n",
    "# Select the bottom 1000 features\n",
    "bottom_features = sorted_weights[-5000:]\n",
    "\n",
    "vocab_dict = dict(enumerate(encoded_vocab))\n",
    "\n",
    "# Map the features back to words\n",
    "top_words = encoded_vocab[np.argsort(weights[:,::-1])[:5000]]\n",
    "bottom_words = encoded_vocab[np.argsort(weights)][:5000]\n",
    "\n",
    "\n",
    "# top\n",
    "s1h = pd.Series(top_words.ravel(), name='words') #ravel() to flatten \n",
    "s2h= pd.Series(top_features.ravel(), name='weights')\n",
    "df_high = pd.concat([s1h, s2h], axis = 1)\n",
    "#df_high\n",
    "\n",
    "#bottom\n",
    "#print(\"Bottom features:\")#, top_words, type(top_features))\n",
    "s1l = pd.Series(bottom_words.ravel(), name='words') #ravel() to flatten \n",
    "s2l= pd.Series(bottom_features.ravel(), name='weights')\n",
    "df_low = pd.concat([s1l, s2l], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df, column_name):\n",
    "    unique_values = df[column_name].unique()\n",
    "    rows_to_remove = []\n",
    "    for value in unique_values:\n",
    "        rows_with_value = df[df[column_name] == value]\n",
    "        if len(rows_with_value) > 1:\n",
    "            rows_to_remove += list(rows_with_value.iloc[1:].index)\n",
    "    df = df.drop(rows_to_remove)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df_h = remove_duplicates(df_high, 'words')\n",
    "df_l = remove_duplicates(df_low, 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_single_character_rows(df, column_name):\n",
    "    mask = df[column_name].str.len() <= 2\n",
    "    df_filtered = df[~mask]\n",
    "    return df_filtered\n",
    "\n",
    "df_h = remove_single_character_rows(df_h, 'words')\n",
    "df_l = remove_single_character_rows(df_l, 'words')\n",
    "df_l.sort_values(by = \"weights\", ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort highest\n",
    "#df_sorted_h = df_high.sort_values(by = \"weights\", ascending=False)\n",
    "#df_sorted_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort lowest\n",
    "#df_sorted_l = df_low.sort_values(by = \"weights\", ascending=True)\n",
    "#df_sorted_l.head(50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Cloud**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format according to which list \n",
    "text = ' '.join(df_h['words'])\n",
    "\n",
    "# Create the word cloud\n",
    "wordcloud = WordCloud(width=800, height=800, background_color='white').generate(text)\n",
    "\n",
    "# Plot the word cloud\n",
    "plt.figure(figsize=(8,8), facecolor=None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code with Attention Mechanism**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
